{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"OPENAI_API_KEY_MA\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\n",
    "        \"API key not found. Please set the OPENAI_API_KEY environment variable.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_client = OpenAI(api_key=api_key)\n",
    "gpt_model = \"gpt-4o-mini-2024-07-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answers(question, answer, reference_answers, client, model):\n",
    "    reference_answers_formatted = \"\\n\".join(reference_answers)\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=model,\n",
    "            input=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are a fact-checking evaluator. You decide whether an answer contains the same specific factual content \"\n",
    "                        \"as one of a set of reference answers. You focus only on the core factual entity mentioned â€” such as a number, name, or place.\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "        You will be given a question, a generated answer, and a list of reference answers.\n",
    "\n",
    "        Determine whether the answer correctly contains the **same factual answer** (e.g., a number, name, location, etc.) as one of the references.\n",
    "\n",
    "        ### Accept the answer if:\n",
    "        - The correct fact is **clearly present**, even if the answer adds irrelevant or incorrect background.\n",
    "        - The answer uses different words or phrasing to convey the same meaning.\n",
    "\n",
    "        ### Reject the answer if:\n",
    "        - It states a different fact or contradicts the correct one.\n",
    "        - It introduces confusion or falsehood **that changes the meaning of the core fact**.\n",
    "\n",
    "        ---\n",
    "\n",
    "        **Question**: {question}  \n",
    "        **Generated Answer**: {answer}  \n",
    "        **Reference Answers**: {reference_answers_formatted}\n",
    "\n",
    "        Respond only in JSON:\n",
    "        {{\"is_correct\": true}} or {{\"is_correct\": false}}\n",
    "        \"\"\",\n",
    "                },\n",
    "            ],\n",
    "            text={\n",
    "                \"format\": {\n",
    "                    \"type\": \"json_schema\",\n",
    "                    \"name\": \"answer_verification\",\n",
    "                    \"strict\": True,\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"is_correct\": {\n",
    "                                \"type\": \"boolean\",\n",
    "                                \"description\": \"True if the core factual answer (e.g., number or name) is included and not contradicted.\",\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\"is_correct\"],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "        try:\n",
    "            # Attempt to parse the response as JSON\n",
    "            event = json.loads(response.output_text)\n",
    "            return event\n",
    "        except json.JSONDecodeError as json_error:\n",
    "            # Handle JSON parsing errors\n",
    "            print(f\"JSONDecodeError: {json_error}\")\n",
    "            return {\"error\": \"Invalid JSON response from API\"}\n",
    "    except openai.BadRequestError as e:\n",
    "        error_message = str(e)  # Extract the error message as a string\n",
    "        print(f\"Error: {error_message}\")\n",
    "        return {\"error\": error_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"'Quinsy' is a term for an abscess on which part of the body?\"\n",
    "a = \"The term 'quinsy' is an old-fashioned term for an abscess on the brain. It is derived from the Latin word 'quinsyus,' which means 'swollen' or 'inflamed.' Quinsy was a common term used in the 18th and 19th centuries to describe an abscess on the brain, particularly\"\n",
    "a_correct = \"The term 'quinsy' is an old-fashioned term for an abscess on the tonsils. It is derived from the Latin word 'quinsyus,' which means 'swollen' or 'inflamed.' Quinsy was a common term used in the 18th and 19th centuries to describe an abscess on the tonsils, particularly\"\n",
    "a_ambiguous = \"The term 'quinsy' is an old-fashioned term for an abscess on the brain. It is derived from the Latin word 'quinsyus,' which means 'swollen' or 'inflamed.' Quinsy was a common term used in the 18th and 19th centuries to describe an abscess on the tonsils, particularly\"\n",
    "r_a = [\"Tonsil\", \"Tonsills\", \"Tonsils\", \"Tonsels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluate_answers(q, a, r_a, oai_client, gpt_model)\n",
    "eval_correct = evaluate_answers(q, a_correct, r_a, oai_client, gpt_model)\n",
    "eval_ambiguous = evaluate_answers(q, a_ambiguous, r_a, oai_client, gpt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_correct': False}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation[\"is_correct\"], eval_correct[\"is_correct\"], eval_ambiguous[\"is_correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_correct': True}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_answers(\n",
    "    \"What number in Bingo is sometimes referred to as Heinz varieties?\",\n",
    "    \"Answer: In Bingo, \\\"Heinz 57\\\" refers to a specific pattern, also known as \\\"Household Bingo,\\\" which consists of 57 numbers.\",\n",
    "    [\"57\", \"fifty-seven\"],\n",
    "    oai_client, gpt_model\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
