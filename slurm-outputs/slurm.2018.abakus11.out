slurmstepd-abakus11: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus11: error: Setting TMPDIR to /tmp
Running job with commit: 145e74fa1d48cc2289865178c9e0bd23d2a91fe6
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 2018
Dataset: commoncorpus
Model: llama-awq
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Sample size: 0
Mode: full
Quantization bits: None (full precision)
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: rephrase
Number of perturbations: 3
You have loaded an AWQ model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Using slow tokenizer implementation for polylm-1.7b
Repo card metadata block was not found. Setting CardData to empty.
Processing sample 1/600 (dataset index: 0)
Processing sample 1 (dataset index 0) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 316.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 1 (dataset index 0): CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 316.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 2/600 (dataset index: 1)
Processing sample 2 (dataset index 1) with language 'en'
Sample 2 (dataset index 1) processed successfully with 3 rephrasings.
Processing sample 3/600 (dataset index: 2)
Processing sample 3 (dataset index 2) with language 'en'
Sample 3 (dataset index 2) processed successfully with 3 rephrasings.
Processing sample 4/600 (dataset index: 3)
Processing sample 4 (dataset index 3) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 77.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.90 GiB is allocated by PyTorch, and 352.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 4 (dataset index 3): CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 77.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.90 GiB is allocated by PyTorch, and 352.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 5/600 (dataset index: 4)
Processing sample 5 (dataset index 4) with language 'en'
Sample 5 (dataset index 4) processed successfully with 3 rephrasings.
Processing sample 6/600 (dataset index: 5)
Processing sample 6 (dataset index 5) with language 'en'
Sample 6 (dataset index 5) processed successfully with 3 rephrasings.
Processing sample 7/600 (dataset index: 6)
Processing sample 7 (dataset index 6) with language 'en'
Sample 7 (dataset index 6) processed successfully with 1 rephrasings.
Processing sample 8/600 (dataset index: 7)
Processing sample 8 (dataset index 7) with language 'en'
Sample 8 (dataset index 7) processed successfully with 3 rephrasings.
Processing sample 9/600 (dataset index: 8)
Processing sample 9 (dataset index 8) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.00 GiB is allocated by PyTorch, and 313.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 9 (dataset index 8): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.00 GiB is allocated by PyTorch, and 313.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 10/600 (dataset index: 9)
Processing sample 10 (dataset index 9) with language 'en'
Sample 10 (dataset index 9) processed successfully with 3 rephrasings.
Processing sample 11/600 (dataset index: 10)
Processing sample 11 (dataset index 10) with language 'en'
Sample 11 (dataset index 10) processed successfully with 3 rephrasings.
Processing sample 12/600 (dataset index: 11)
Processing sample 12 (dataset index 11) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 41.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 445.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 12 (dataset index 11): CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 41.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 445.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 13/600 (dataset index: 12)
Processing sample 13 (dataset index 12) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 37.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 474.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 13 (dataset index 12): CUDA out of memory. Tried to allocate 178.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 37.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 474.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 14/600 (dataset index: 13)
Processing sample 14 (dataset index 13) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 45.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 413.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 14 (dataset index 13): CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 45.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 413.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 15/600 (dataset index: 14)
Processing sample 15 (dataset index 14) with language 'en'
Sample 15 (dataset index 14) processed successfully with 3 rephrasings.
Processing sample 16/600 (dataset index: 15)
Processing sample 16 (dataset index 15) with language 'en'
Sample 16 (dataset index 15) processed successfully with 3 rephrasings.
Processing sample 17/600 (dataset index: 16)
Processing sample 17 (dataset index 16) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 75.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 420.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 17 (dataset index 16): CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 75.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 420.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 18/600 (dataset index: 17)
Processing sample 18 (dataset index 17) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 61.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 372.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 18 (dataset index 17): CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 61.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 372.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 19/600 (dataset index: 18)
Processing sample 19 (dataset index 18) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 18.36 GiB is allocated by PyTorch, and 952.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 19 (dataset index 18): CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 18.36 GiB is allocated by PyTorch, and 952.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 20/600 (dataset index: 19)
Processing sample 20 (dataset index 19) with language 'en'
Sample 20 (dataset index 19) processed successfully with 3 rephrasings.
Processing sample 21/600 (dataset index: 20)
Processing sample 21 (dataset index 20) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 33.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 447.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 21 (dataset index 20): CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 33.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 447.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 22/600 (dataset index: 21)
Processing sample 22 (dataset index 21) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 65.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 17.74 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 22 (dataset index 21): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 65.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 17.74 GiB is allocated by PyTorch, and 1.51 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 23/600 (dataset index: 22)
Processing sample 23 (dataset index 22) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 43.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 460.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 23 (dataset index 22): CUDA out of memory. Tried to allocate 78.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 43.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 460.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 24/600 (dataset index: 23)
Processing sample 24 (dataset index 23) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 197.06 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 283.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 24 (dataset index 23): CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 197.06 MiB is free. Including non-PyTorch memory, this process has 19.35 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 283.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 25/600 (dataset index: 24)
Processing sample 25 (dataset index 24) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 57.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 17.64 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 25 (dataset index 24): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 57.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 17.64 GiB is allocated by PyTorch, and 1.62 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 26/600 (dataset index: 25)
Processing sample 26 (dataset index 25) with language 'en'
Sample 26 (dataset index 25) processed successfully with 3 rephrasings.
Processing sample 27/600 (dataset index: 26)
Processing sample 27 (dataset index 26) with language 'en'
Sample 27 (dataset index 26) processed successfully with 3 rephrasings.
Processing sample 28/600 (dataset index: 27)
Processing sample 28 (dataset index 27) with language 'en'
Sample 28 (dataset index 27) processed successfully with 3 rephrasings.
Processing sample 29/600 (dataset index: 28)
Processing sample 29 (dataset index 28) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 436.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 407.06 MiB is free. Including non-PyTorch memory, this process has 19.15 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 272.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 29 (dataset index 28): CUDA out of memory. Tried to allocate 436.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 407.06 MiB is free. Including non-PyTorch memory, this process has 19.15 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 272.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 30/600 (dataset index: 29)
Processing sample 30 (dataset index 29) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 135.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 528.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 30 (dataset index 29): CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 135.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 528.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 31/600 (dataset index: 30)
Processing sample 31 (dataset index 30) with language 'en'
Sample 31 (dataset index 30) processed successfully with 3 rephrasings.
Processing sample 32/600 (dataset index: 31)
Processing sample 32 (dataset index 31) with language 'en'
Sample 32 (dataset index 31) processed successfully with 3 rephrasings.
Processing sample 33/600 (dataset index: 32)
Processing sample 33 (dataset index 32) with language 'en'
Sample 33 (dataset index 32) processed successfully with 3 rephrasings.
Processing sample 34/600 (dataset index: 33)
Processing sample 34 (dataset index 33) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 67.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.20 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 34 (dataset index 33): CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 67.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.20 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 35/600 (dataset index: 34)
Processing sample 35 (dataset index 34) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 63.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 418.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 35 (dataset index 34): CUDA out of memory. Tried to allocate 122.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 63.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 418.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 36/600 (dataset index: 35)
Processing sample 36 (dataset index 35) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 165.06 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 389.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 36 (dataset index 35): CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 165.06 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 389.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 37/600 (dataset index: 36)
Processing sample 37 (dataset index 36) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 251.06 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 404.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 37 (dataset index 36): CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 251.06 MiB is free. Including non-PyTorch memory, this process has 19.30 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 404.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 38/600 (dataset index: 37)
Processing sample 38 (dataset index 37) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 18.42 GiB is allocated by PyTorch, and 896.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 38 (dataset index 37): CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 18.42 GiB is allocated by PyTorch, and 896.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 39/600 (dataset index: 38)
Processing sample 39 (dataset index 38) with language 'en'
Sample 39 (dataset index 38) processed successfully with 3 rephrasings.
Processing sample 40/600 (dataset index: 39)
Processing sample 40 (dataset index 39) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 31.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 625.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 40 (dataset index 39): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 31.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.67 GiB is allocated by PyTorch, and 625.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 41/600 (dataset index: 40)
Processing sample 41 (dataset index 40) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 95.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 461.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 41 (dataset index 40): CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 95.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 461.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 42/600 (dataset index: 41)
Processing sample 42 (dataset index 41) with language 'en'
Sample 42 (dataset index 41) processed successfully with 3 rephrasings.
Processing sample 43/600 (dataset index: 42)
Processing sample 43 (dataset index 42) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 63.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 418.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 43 (dataset index 42): CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 63.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.84 GiB is allocated by PyTorch, and 418.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 44/600 (dataset index: 43)
Processing sample 44 (dataset index 43) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 89.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 304.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 44 (dataset index 43): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 89.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 304.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 45/600 (dataset index: 44)
Processing sample 45 (dataset index 44) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 135.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 261.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 45 (dataset index 44): CUDA out of memory. Tried to allocate 300.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 135.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 261.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 46/600 (dataset index: 45)
Processing sample 46 (dataset index 45) with language 'en'
Sample 46 (dataset index 45) processed successfully with 3 rephrasings.
Processing sample 47/600 (dataset index: 46)
Processing sample 47 (dataset index 46) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 503.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 47 (dataset index 46): CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 503.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 48/600 (dataset index: 47)
Processing sample 48 (dataset index 47) with language 'en'
Sample 48 (dataset index 47) processed successfully with 3 rephrasings.
Processing sample 49/600 (dataset index: 48)
Processing sample 49 (dataset index 48) with language 'en'
Sample 49 (dataset index 48) processed successfully with 3 rephrasings.
Processing sample 50/600 (dataset index: 49)
Processing sample 50 (dataset index 49) with language 'en'
Sample 50 (dataset index 49) processed successfully with 3 rephrasings.
Processing sample 51/600 (dataset index: 50)
Processing sample 51 (dataset index 50) with language 'en'
Sample 51 (dataset index 50) processed successfully with 3 rephrasings.
Processing sample 52/600 (dataset index: 51)
Processing sample 52 (dataset index 51) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 149.06 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 263.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 52 (dataset index 51): CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 149.06 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 263.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 53/600 (dataset index: 52)
Processing sample 53 (dataset index 52) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 18.40 GiB is allocated by PyTorch, and 913.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 53 (dataset index 52): CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 18.40 GiB is allocated by PyTorch, and 913.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 54/600 (dataset index: 53)
Processing sample 54 (dataset index 53) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 53.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 397.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 54 (dataset index 53): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 53.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 397.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 55/600 (dataset index: 54)
Processing sample 55 (dataset index 54) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 101.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.94 GiB is allocated by PyTorch, and 284.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 55 (dataset index 54): CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 101.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.94 GiB is allocated by PyTorch, and 284.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 56/600 (dataset index: 55)
Processing sample 56 (dataset index 55) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 67.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 553.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 56 (dataset index 55): CUDA out of memory. Tried to allocate 106.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 67.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 553.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 57/600 (dataset index: 56)
Processing sample 57 (dataset index 56) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 69.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 753.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 57 (dataset index 56): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 69.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.51 GiB is allocated by PyTorch, and 753.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 58/600 (dataset index: 57)
Processing sample 58 (dataset index 57) with language 'en'
Sample 58 (dataset index 57) processed successfully with 3 rephrasings.
Processing sample 59/600 (dataset index: 58)
Processing sample 59 (dataset index 58) with language 'en'
Sample 59 (dataset index 58) processed successfully with 3 rephrasings.
Processing sample 60/600 (dataset index: 59)
Processing sample 60 (dataset index 59) with language 'en'
Sample 60 (dataset index 59) processed successfully with 3 rephrasings.
Processing sample 61/600 (dataset index: 60)
Processing sample 61 (dataset index 60) with language 'en'
Sample 61 (dataset index 60) processed successfully with 3 rephrasings.
Processing sample 62/600 (dataset index: 61)
Processing sample 62 (dataset index 61) with language 'en'
Sample 62 (dataset index 61) processed successfully with 3 rephrasings.
Processing sample 63/600 (dataset index: 62)
Processing sample 63 (dataset index 62) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 394.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 63 (dataset index 62): CUDA out of memory. Tried to allocate 162.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 18.91 GiB is allocated by PyTorch, and 394.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 64/600 (dataset index: 63)
Processing sample 64 (dataset index 63) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 105.06 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 329.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 64 (dataset index 63): CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 105.06 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 329.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 65/600 (dataset index: 64)
Processing sample 65 (dataset index 64) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 165.06 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 448.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 65 (dataset index 64): CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 165.06 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 448.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 66/600 (dataset index: 65)
Processing sample 66 (dataset index 65) with language 'en'
Sample 66 (dataset index 65) processed successfully with 3 rephrasings.
Processing sample 67/600 (dataset index: 66)
Processing sample 67 (dataset index 66) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.10 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 67 (dataset index 66): CUDA out of memory. Tried to allocate 62.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.10 GiB is allocated by PyTorch, and 1.16 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 68/600 (dataset index: 67)
Processing sample 68 (dataset index 67) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 17.99 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 68 (dataset index 67): CUDA out of memory. Tried to allocate 30.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 17.99 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 69/600 (dataset index: 68)
Processing sample 69 (dataset index 68) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 41.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 316.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 69 (dataset index 68): CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 41.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 316.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 70/600 (dataset index: 69)
Processing sample 70 (dataset index 69) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 45.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 405.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 70 (dataset index 69): CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 45.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 405.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 71/600 (dataset index: 70)
Processing sample 71 (dataset index 70) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 89.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 303.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 71 (dataset index 70): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 89.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.93 GiB is allocated by PyTorch, and 303.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 72/600 (dataset index: 71)
Processing sample 72 (dataset index 71) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 77.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 354.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 72 (dataset index 71): CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 77.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.89 GiB is allocated by PyTorch, and 354.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 73/600 (dataset index: 72)
Processing sample 73 (dataset index 72) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 165.06 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.74 GiB is allocated by PyTorch, and 422.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 73 (dataset index 72): CUDA out of memory. Tried to allocate 174.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 165.06 MiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Of the allocated memory 18.74 GiB is allocated by PyTorch, and 422.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 74/600 (dataset index: 73)
Processing sample 74 (dataset index 73) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 397.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 74 (dataset index 73): CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 397.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 75/600 (dataset index: 74)
Processing sample 75 (dataset index 74) with language 'en'
Sample 75 (dataset index 74) processed successfully with 3 rephrasings.
Processing sample 76/600 (dataset index: 75)
Processing sample 76 (dataset index 75) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 7.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 527.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 76 (dataset index 75): CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 7.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.79 GiB is allocated by PyTorch, and 527.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 77/600 (dataset index: 76)
Processing sample 77 (dataset index 76) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 55.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 17.62 GiB is allocated by PyTorch, and 1.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 77 (dataset index 76): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 55.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 17.62 GiB is allocated by PyTorch, and 1.64 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 78/600 (dataset index: 77)
Processing sample 78 (dataset index 77) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 213.06 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 471.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 78 (dataset index 77): CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 213.06 MiB is free. Including non-PyTorch memory, this process has 19.34 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 471.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 79/600 (dataset index: 78)
Processing sample 79 (dataset index 78) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 95.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 377.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 79 (dataset index 78): CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 95.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 377.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 80/600 (dataset index: 79)
Processing sample 80 (dataset index 79) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 55.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 17.43 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 80 (dataset index 79): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 55.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 17.43 GiB is allocated by PyTorch, and 1.83 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 81/600 (dataset index: 80)
Processing sample 81 (dataset index 80) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 39.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.56 GiB is allocated by PyTorch, and 731.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 81 (dataset index 80): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 39.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.56 GiB is allocated by PyTorch, and 731.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 82/600 (dataset index: 81)
Processing sample 82 (dataset index 81) with language 'en'
Sample 82 (dataset index 81) processed successfully with 3 rephrasings.
Processing sample 83/600 (dataset index: 82)
Processing sample 83 (dataset index 82) with language 'en'
Sample 83 (dataset index 82) processed successfully with 3 rephrasings.
Processing sample 84/600 (dataset index: 83)
Processing sample 84 (dataset index 83) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 63.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 410.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 84 (dataset index 83): CUDA out of memory. Tried to allocate 126.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 63.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 410.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 85/600 (dataset index: 84)
Processing sample 85 (dataset index 84) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 191.06 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 324.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 85 (dataset index 84): CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 191.06 MiB is free. Including non-PyTorch memory, this process has 19.36 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 324.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 86/600 (dataset index: 85)
Processing sample 86 (dataset index 85) with language 'en'
Sample 86 (dataset index 85) processed successfully with 3 rephrasings.
Processing sample 87/600 (dataset index: 86)
Processing sample 87 (dataset index 86) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 75.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 380.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 87 (dataset index 86): CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 75.06 MiB is free. Including non-PyTorch memory, this process has 19.47 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 380.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 88/600 (dataset index: 87)
Processing sample 88 (dataset index 87) with language 'en'
Sample 88 (dataset index 87) processed successfully with 1 rephrasings.
Processing sample 89/600 (dataset index: 88)
Processing sample 89 (dataset index 88) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 17.39 GiB is allocated by PyTorch, and 1.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 89 (dataset index 88): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 47.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 17.39 GiB is allocated by PyTorch, and 1.88 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 90/600 (dataset index: 89)
Processing sample 90 (dataset index 89) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 59.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 383.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 90 (dataset index 89): CUDA out of memory. Tried to allocate 104.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 59.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.88 GiB is allocated by PyTorch, and 383.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 91/600 (dataset index: 90)
Processing sample 91 (dataset index 90) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 83.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 469.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 91 (dataset index 90): CUDA out of memory. Tried to allocate 144.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 83.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.77 GiB is allocated by PyTorch, and 469.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 92/600 (dataset index: 91)
Processing sample 92 (dataset index 91) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 131.06 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.70 GiB is allocated by PyTorch, and 501.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 92 (dataset index 91): CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 131.06 MiB is free. Including non-PyTorch memory, this process has 19.42 GiB memory in use. Of the allocated memory 18.70 GiB is allocated by PyTorch, and 501.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 93/600 (dataset index: 92)
Processing sample 93 (dataset index 92) with language 'en'
Sample 93 (dataset index 92) processed successfully with 3 rephrasings.
Processing sample 94/600 (dataset index: 93)
Processing sample 94 (dataset index 93) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 43.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 525.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 94 (dataset index 93): CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 43.06 MiB is free. Including non-PyTorch memory, this process has 19.50 GiB memory in use. Of the allocated memory 18.76 GiB is allocated by PyTorch, and 525.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 95/600 (dataset index: 94)
Processing sample 95 (dataset index 94) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.47 GiB is allocated by PyTorch, and 857.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 95 (dataset index 94): CUDA out of memory. Tried to allocate 34.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.47 GiB is allocated by PyTorch, and 857.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 96/600 (dataset index: 95)
Processing sample 96 (dataset index 95) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 155.06 MiB is free. Including non-PyTorch memory, this process has 19.39 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 343.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 96 (dataset index 95): CUDA out of memory. Tried to allocate 160.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 155.06 MiB is free. Including non-PyTorch memory, this process has 19.39 GiB memory in use. Of the allocated memory 18.83 GiB is allocated by PyTorch, and 343.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 97/600 (dataset index: 96)
Processing sample 97 (dataset index 96) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 103.06 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.74 GiB is allocated by PyTorch, and 481.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 97 (dataset index 96): CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 103.06 MiB is free. Including non-PyTorch memory, this process has 19.44 GiB memory in use. Of the allocated memory 18.74 GiB is allocated by PyTorch, and 481.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 98/600 (dataset index: 97)
Processing sample 98 (dataset index 97) with language 'en'
Sample 98 (dataset index 97) processed successfully with 3 rephrasings.
Processing sample 99/600 (dataset index: 98)
Processing sample 99 (dataset index 98) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 51.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 419.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 99 (dataset index 98): CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 51.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.85 GiB is allocated by PyTorch, and 419.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 100/600 (dataset index: 99)
Processing sample 100 (dataset index 99) with language 'en'
Sample 100 (dataset index 99) processed successfully with 3 rephrasings.
Processing sample 101/600 (dataset index: 100)
Processing sample 101 (dataset index 100) with language 'de'
Error in completion_gradient: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 23.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 17.82 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 101 (dataset index 100): CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 23.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 17.82 GiB is allocated by PyTorch, and 1.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 102/600 (dataset index: 101)
Processing sample 102 (dataset index 101) with language 'de'
Error in completion_gradient: CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 53.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 316.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 102 (dataset index 101): CUDA out of memory. Tried to allocate 66.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 53.06 MiB is free. Including non-PyTorch memory, this process has 19.49 GiB memory in use. Of the allocated memory 18.95 GiB is allocated by PyTorch, and 316.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 103/600 (dataset index: 102)
Processing sample 103 (dataset index 102) with language 'de'
Sample 103 (dataset index 102) processed successfully with 3 rephrasings.
Processing sample 104/600 (dataset index: 103)
Processing sample 104 (dataset index 103) with language 'de'
Sample 104 (dataset index 103) processed successfully with 3 rephrasings.
Processing sample 105/600 (dataset index: 104)
Processing sample 105 (dataset index 104) with language 'de'
Error in completion_gradient: CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 89.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 422.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 105 (dataset index 104): CUDA out of memory. Tried to allocate 124.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 89.06 MiB is free. Including non-PyTorch memory, this process has 19.46 GiB memory in use. Of the allocated memory 18.81 GiB is allocated by PyTorch, and 422.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 106/600 (dataset index: 105)
Processing sample 106 (dataset index 105) with language 'de'
Error in completion_gradient: CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 33.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 581.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 106 (dataset index 105): CUDA out of memory. Tried to allocate 38.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 33.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 581.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 107/600 (dataset index: 106)
Processing sample 107 (dataset index 106) with language 'de'
Error in completion_gradient: CUDA out of memory. Tried to allocate 608.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 225.06 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 281.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 107 (dataset index 106): CUDA out of memory. Tried to allocate 608.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 225.06 MiB is free. Including non-PyTorch memory, this process has 19.32 GiB memory in use. Of the allocated memory 18.82 GiB is allocated by PyTorch, and 281.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 108/600 (dataset index: 107)
Processing sample 108 (dataset index 107) with language 'de'
slurmstepd-abakus11: error: *** JOB 2018 ON abakus11 CANCELLED AT 2025-05-04T18:05:46 ***
