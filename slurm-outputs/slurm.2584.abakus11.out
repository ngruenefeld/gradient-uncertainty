slurmstepd-abakus11: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus11: error: Setting TMPDIR to /tmp
Running job with commit: 8d80cfb41f702faae1dc2132f7831d37cb914223
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 2584
Dataset: ag-pubmed
Model: medical-chatbot
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Mode: full
Quantization bits: 4
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: rephrase
Number of perturbations: 3
Max tokens: 0
Sample Size Per Label: 200
Processing sample 1/1000 (dataset index: 0)
Processing sample 1 (dataset index 0)
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 29.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.23 GiB is allocated by PyTorch, and 67.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 1 (dataset index 0): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 29.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.23 GiB is allocated by PyTorch, and 67.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 2/1000 (dataset index: 1)
Processing sample 2 (dataset index 1)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 17.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 33.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 2 (dataset index 1): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 17.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 33.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 3/1000 (dataset index: 2)
Processing sample 3 (dataset index 2)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 32.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 3 (dataset index 2): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 32.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 4/1000 (dataset index: 3)
Processing sample 4 (dataset index 3)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 26.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 4 (dataset index 3): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 26.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 5/1000 (dataset index: 4)
Processing sample 5 (dataset index 4)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 17.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 5 (dataset index 4): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 17.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 6/1000 (dataset index: 5)
Processing sample 6 (dataset index 5)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 24.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 6 (dataset index 5): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 24.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 7/1000 (dataset index: 6)
Processing sample 7 (dataset index 6)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 38.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 7 (dataset index 6): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 38.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 8/1000 (dataset index: 7)
Processing sample 8 (dataset index 7)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 45.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 8 (dataset index 7): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 45.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 9/1000 (dataset index: 8)
Processing sample 9 (dataset index 8)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 47.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 9 (dataset index 8): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 47.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 10/1000 (dataset index: 9)
Processing sample 10 (dataset index 9)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 17.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 37.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 10 (dataset index 9): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 17.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 37.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 11/1000 (dataset index: 10)
Processing sample 11 (dataset index 10)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 47.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 11 (dataset index 10): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 47.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 12/1000 (dataset index: 11)
Processing sample 12 (dataset index 11)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 29.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 12 (dataset index 11): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 29.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 13/1000 (dataset index: 12)
Processing sample 13 (dataset index 12)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 13 (dataset index 12): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 14/1000 (dataset index: 13)
Processing sample 14 (dataset index 13)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 35.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 14 (dataset index 13): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 35.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 15/1000 (dataset index: 14)
Processing sample 15 (dataset index 14)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.25 GiB is allocated by PyTorch, and 49.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 15 (dataset index 14): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.25 GiB is allocated by PyTorch, and 49.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 16/1000 (dataset index: 15)
Processing sample 16 (dataset index 15)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 33.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 16 (dataset index 15): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 33.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 17/1000 (dataset index: 16)
Processing sample 17 (dataset index 16)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 17.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 17 (dataset index 16): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 17.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 18/1000 (dataset index: 17)
Processing sample 18 (dataset index 17)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 51.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 18 (dataset index 17): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 51.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 19/1000 (dataset index: 18)
Processing sample 19 (dataset index 18)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 19 (dataset index 18): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 20/1000 (dataset index: 19)
Processing sample 20 (dataset index 19)
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 27.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 85.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 20 (dataset index 19): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 27.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 85.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 21/1000 (dataset index: 20)
Processing sample 21 (dataset index 20)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 28.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 21 (dataset index 20): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 28.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 22/1000 (dataset index: 21)
Processing sample 22 (dataset index 21)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 27.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 22 (dataset index 21): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 27.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 23/1000 (dataset index: 22)
Processing sample 23 (dataset index 22)
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 39.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 70.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 23 (dataset index 22): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 39.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 70.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 24/1000 (dataset index: 23)
Processing sample 24 (dataset index 23)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 27.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 24 (dataset index 23): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 27.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 25/1000 (dataset index: 24)
Processing sample 25 (dataset index 24)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 25 (dataset index 24): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 26/1000 (dataset index: 25)
Processing sample 26 (dataset index 25)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 26 (dataset index 25): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 27/1000 (dataset index: 26)
Processing sample 27 (dataset index 26)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 31.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 27 (dataset index 26): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 31.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 28/1000 (dataset index: 27)
Processing sample 28 (dataset index 27)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 36.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 28 (dataset index 27): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 36.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 29/1000 (dataset index: 28)
Processing sample 29 (dataset index 28)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 45.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 29 (dataset index 28): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 45.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 30/1000 (dataset index: 29)
Processing sample 30 (dataset index 29)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 29.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 30 (dataset index 29): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 29.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 31/1000 (dataset index: 30)
Processing sample 31 (dataset index 30)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 31 (dataset index 30): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 32/1000 (dataset index: 31)
Processing sample 32 (dataset index 31)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 48.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 32 (dataset index 31): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 9.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 48.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 33/1000 (dataset index: 32)
Processing sample 33 (dataset index 32)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 33 (dataset index 32): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 55.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 34/1000 (dataset index: 33)
Processing sample 34 (dataset index 33)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 34 (dataset index 33): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 30.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 35/1000 (dataset index: 34)
Processing sample 35 (dataset index 34)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 46.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 35 (dataset index 34): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 46.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 36/1000 (dataset index: 35)
Processing sample 36 (dataset index 35)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 43.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 36 (dataset index 35): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 43.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 37/1000 (dataset index: 36)
Processing sample 37 (dataset index 36)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 42.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 37 (dataset index 36): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 42.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 38/1000 (dataset index: 37)
Processing sample 38 (dataset index 37)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 33.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 38 (dataset index 37): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 33.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 39/1000 (dataset index: 38)
Processing sample 39 (dataset index 38)
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 35.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 75.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 39 (dataset index 38): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 35.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 75.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 40/1000 (dataset index: 39)
Processing sample 40 (dataset index 39)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 19.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 40 (dataset index 39): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 19.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 41/1000 (dataset index: 40)
Processing sample 41 (dataset index 40)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.31 GiB is allocated by PyTorch, and 6.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 41 (dataset index 40): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.31 GiB is allocated by PyTorch, and 6.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 42/1000 (dataset index: 41)
Processing sample 42 (dataset index 41)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.31 GiB is allocated by PyTorch, and 4.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 42 (dataset index 41): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 5.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.31 GiB is allocated by PyTorch, and 4.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 43/1000 (dataset index: 42)
Processing sample 43 (dataset index 42)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 41.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 43 (dataset index 42): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 41.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 44/1000 (dataset index: 43)
Processing sample 44 (dataset index 43)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.31 GiB is allocated by PyTorch, and 11.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 44 (dataset index 43): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.31 GiB is allocated by PyTorch, and 11.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 45/1000 (dataset index: 44)
Processing sample 45 (dataset index 44)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 28.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 45 (dataset index 44): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 28.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 46/1000 (dataset index: 45)
Processing sample 46 (dataset index 45)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 29.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 46 (dataset index 45): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 29.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 47/1000 (dataset index: 46)
Processing sample 47 (dataset index 46)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 34.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 47 (dataset index 46): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 34.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 48/1000 (dataset index: 47)
Processing sample 48 (dataset index 47)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 31.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 48 (dataset index 47): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 31.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 49/1000 (dataset index: 48)
Processing sample 49 (dataset index 48)
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 33.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 77.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 49 (dataset index 48): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 33.06 MiB is free. Including non-PyTorch memory, this process has 19.51 GiB memory in use. Of the allocated memory 19.21 GiB is allocated by PyTorch, and 77.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 50/1000 (dataset index: 49)
Processing sample 50 (dataset index 49)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 51.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 50 (dataset index 49): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 51.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 51/1000 (dataset index: 50)
Processing sample 51 (dataset index 50)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 40.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 51 (dataset index 50): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 40.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 52/1000 (dataset index: 51)
Processing sample 52 (dataset index 51)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 29.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 52 (dataset index 51): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 29.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 53/1000 (dataset index: 52)
Processing sample 53 (dataset index 52)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 21.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 53 (dataset index 52): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 21.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 54/1000 (dataset index: 53)
Processing sample 54 (dataset index 53)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 30.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 54 (dataset index 53): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 30.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 55/1000 (dataset index: 54)
Processing sample 55 (dataset index 54)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 48.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 55 (dataset index 54): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 48.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 56/1000 (dataset index: 55)
Processing sample 56 (dataset index 55)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 30.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 56 (dataset index 55): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 30.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 57/1000 (dataset index: 56)
Processing sample 57 (dataset index 56)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 10.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 57 (dataset index 56): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 10.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 58/1000 (dataset index: 57)
Processing sample 58 (dataset index 57)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 34.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 58 (dataset index 57): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 15.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 34.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 59/1000 (dataset index: 58)
Processing sample 59 (dataset index 58)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 40.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 59 (dataset index 58): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 40.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 60/1000 (dataset index: 59)
Processing sample 60 (dataset index 59)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 17.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 60 (dataset index 59): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 17.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 13.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 61/1000 (dataset index: 60)
Processing sample 61 (dataset index 60)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 44.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 61 (dataset index 60): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 19.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 44.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 62/1000 (dataset index: 61)
Processing sample 62 (dataset index 61)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 36.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 62 (dataset index 61): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 36.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 63/1000 (dataset index: 62)
Processing sample 63 (dataset index 62)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 32.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 63 (dataset index 62): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 21.06 MiB is free. Including non-PyTorch memory, this process has 19.52 GiB memory in use. Of the allocated memory 19.27 GiB is allocated by PyTorch, and 32.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 64/1000 (dataset index: 63)
Processing sample 64 (dataset index 63)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 20.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 64 (dataset index 63): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 20.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 65/1000 (dataset index: 64)
Processing sample 65 (dataset index 64)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 20.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 65 (dataset index 64): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.30 GiB is allocated by PyTorch, and 20.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 66/1000 (dataset index: 65)
Processing sample 66 (dataset index 65)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 66 (dataset index 65): CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.26 GiB is allocated by PyTorch, and 61.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 67/1000 (dataset index: 66)
Processing sample 67 (dataset index 66)
Error in completion_gradient: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 27.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 67 (dataset index 66): CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 13.06 MiB is free. Including non-PyTorch memory, this process has 19.53 GiB memory in use. Of the allocated memory 19.28 GiB is allocated by PyTorch, and 27.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 68/1000 (dataset index: 67)
Processing sample 68 (dataset index 67)
Error in completion_gradient: CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 3.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 19.29 GiB is allocated by PyTorch, and 28.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
slurmstepd-abakus11: error: *** JOB 2584 ON abakus11 CANCELLED AT 2025-05-07T21:33:03 ***
