slurmstepd-abakus11: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus11: error: Setting TMPDIR to /tmp
Running job with commit: 784b4492af87f02a942e34ca3693415fec5fc539
Running command: python -um scripts.bert "59930" --key_mode "keyfile" --sample_size "0" --test_sample_size "5" --dataset "scienceqa" --epochs "10"
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 59930
Key mode: keyfile
Sample size: 0
Normalize: False
Counterfactual: identity
Dataset: scienceqa
Model: bert
Replacement probability: 1.0
Epochs: 10
Using full train dataset with 547 samples.
Using 5 randomly sampled examples from the test dataset.
Loading model: bert-base-uncased
BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.
  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes
  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).
  - If you are not the owner of the model architecture class, please contact the model code owner to update it.
Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Using device: cuda
Map:   0%|          | 0/547 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547/547 [00:00<00:00, 8585.30 examples/s]
/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/scripts/bert.py:240: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
Calculating uncertainties for 5 test samples before training (counterfactual mode: identity)...
Processing test sample 1/5 (before training)
torch.Size([135, 30522])
tensor([[-11.1946, -11.5160, -11.0007,  ..., -10.3924,  -9.9510,  -7.5108],
        [-10.5913, -10.8471, -10.7179,  ..., -10.3119,  -8.7649,  -8.6202],
        [ -9.9574, -10.3272, -10.2133,  ..., -10.5828,  -8.2276,  -7.0034],
        ...,
        [-14.3277, -14.6576, -14.5152,  ..., -14.4928, -10.0153,  -9.0067],
        [-10.6471, -11.1165, -10.9584,  ...,  -9.9307,  -7.9350,  -7.0781],
        [-14.3471, -14.5131, -14.3106,  ..., -13.7201, -10.8734, -11.6160]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([135])
tensor([7.1374e+00, 2.3439e+00, 2.7856e+00, 1.5496e+00, 4.0558e+00, 1.2720e-02,
        3.9571e-01, 9.0063e-03, 2.8593e+00, 1.3340e-02, 1.0937e-01, 2.3850e-03,
        1.4158e+00, 5.7586e-03, 8.3347e-03, 4.7050e-04, 4.3225e-01, 1.8013e-01,
        5.9626e-01, 2.3790e-02, 7.1347e-02, 1.3757e+00, 1.3778e-03, 1.3429e-02,
        1.4801e-01, 4.8534e-04, 2.3997e+00, 1.3619e+00, 1.6460e-02, 6.2507e-04,
        4.5294e-01, 5.6004e-04, 2.8476e-02, 1.3310e-01, 3.8649e-03, 3.4958e-02,
        1.3925e-02, 3.4418e-01, 2.3394e+00, 1.8121e-03, 5.0132e-01, 2.6676e+00,
        2.3814e+00, 4.2387e-01, 4.7781e-01, 7.2029e-01, 6.1427e-01, 7.2047e-01,
        5.0953e-02, 1.3257e+00, 3.5832e-01, 9.3511e-01, 1.2762e-02, 2.3224e+00,
        5.9263e-02, 4.2866e-01, 1.8303e-03, 1.5257e-02, 1.2242e-01, 3.2753e-01,
        7.9723e-03, 1.4806e-04, 1.0753e+00, 2.9155e-04, 2.1390e-02, 5.4134e+00,
        4.7693e-03, 7.0102e-01, 1.4088e-04, 1.8829e+00, 2.2917e-05, 2.1831e-01,
        8.8210e-01, 8.0400e-02, 2.7658e-04, 4.0740e+00, 3.5333e-05, 4.7479e-03,
        3.6449e-01, 3.0606e-04, 8.6545e-03, 3.0157e-03, 1.9865e-02, 1.7007e+00,
        1.4418e-01, 1.8114e+00, 2.9758e-01, 3.2874e+00, 8.2997e-03, 6.0620e-01,
        1.2628e+00, 4.5019e-02, 2.2576e+00, 1.6251e+00, 3.1726e-02, 2.6679e-01,
        1.2035e-02, 1.7100e-04, 7.2895e-02, 1.7954e-03, 6.1098e-04, 6.6503e-02,
        3.6957e-03, 5.9851e-01, 1.0814e-03, 1.2566e-03, 2.2397e+00, 5.1359e-01,
        4.0067e-03, 6.0028e-04, 1.3264e+00, 1.4781e-02, 1.4337e-01, 2.9028e-02,
        9.8327e-01, 2.6379e+00, 9.6930e-01, 1.8342e-01, 6.6327e-04, 5.8666e-03,
        3.7347e-02, 5.6058e-04, 2.3560e-03, 7.6694e-03, 3.4395e+00, 5.0583e-03,
        1.4004e-03, 7.1579e-01, 2.4676e-05, 1.2871e-02, 5.3672e-03, 1.7827e+00,
        1.8366e-03, 1.4571e+00, 2.7368e-04], device='cuda:0',
       grad_fn=<NegBackward0>)
Processing test sample 2/5 (before training)
torch.Size([167, 30522])
tensor([[ -9.6883, -10.0320,  -9.7458,  ...,  -9.2532,  -9.2471,  -5.4962],
        [ -8.9768,  -8.9917,  -8.9266,  ...,  -8.1320,  -8.4609,  -6.9684],
        [ -8.3531,  -8.2272,  -8.2167,  ...,  -7.1743,  -7.7953,  -5.5002],
        ...,
        [-12.8086, -13.1784, -13.2026,  ..., -11.2477,  -9.3510, -10.5211],
        [ -7.7982,  -8.0785,  -8.1562,  ...,  -6.7709,  -6.5188,  -2.6154],
        [-12.9305, -13.0377, -12.9923,  ..., -12.0385, -10.1749,  -9.3834]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([167])
tensor([5.8554e+00, 4.5099e+00, 4.7015e+00, 1.0693e+00, 3.3054e+00, 1.7105e-01,
        1.0461e+00, 3.1298e-01, 7.9659e-02, 4.2400e+00, 2.2966e-01, 4.7119e-02,
        3.1212e+00, 1.8183e+00, 2.3835e+00, 4.9448e-02, 1.0722e+00, 8.6570e-01,
        2.1924e-01, 5.9246e+00, 4.0372e+00, 7.4696e-01, 9.6250e-02, 1.3267e+00,
        1.6938e+00, 1.8990e-02, 3.3153e+00, 5.3740e-01, 2.6175e+00, 1.0935e+00,
        2.2692e-03, 4.5895e-01, 1.2332e+00, 2.5228e+00, 2.6139e-01, 1.5870e-01,
        3.4835e-01, 2.3420e+00, 1.6006e-01, 1.5526e+00, 6.8182e-02, 5.4325e+00,
        4.6972e+00, 4.2522e-01, 3.0585e-01, 8.9785e-04, 2.0052e-01, 3.4208e+00,
        5.6195e-02, 1.4666e+00, 4.6768e+00, 1.2114e+00, 1.0625e+00, 1.0197e+00,
        1.8296e-01, 3.4486e-02, 7.7734e-02, 2.9038e+00, 2.8133e-01, 6.6470e-01,
        4.6913e+00, 5.2276e-01, 6.2746e-01, 4.3990e-02, 3.3134e-01, 2.0918e-01,
        3.4900e-01, 3.6690e-01, 2.8540e-01, 5.0732e-04, 4.5417e-02, 2.7548e-02,
        1.2699e+00, 1.7621e-03, 2.2811e+00, 6.3535e-02, 7.8769e-01, 8.4261e-03,
        4.7479e+00, 4.1804e-02, 2.8199e+00, 5.6014e-03, 1.2612e+00, 5.7321e-02,
        4.4999e+00, 9.0398e-01, 3.3888e-03, 5.6516e-01, 5.8290e-02, 2.1381e+00,
        1.0766e-01, 1.4702e+00, 3.5790e-03, 5.1556e-02, 5.3142e-01, 7.2531e-02,
        5.3574e-03, 8.4098e-02, 2.8719e+00, 6.5211e-01, 1.0340e+00, 8.2888e-04,
        5.0882e+00, 1.3501e+00, 2.4382e+00, 5.9280e-01, 6.6373e-02, 1.7669e+00,
        5.2034e-04, 1.9696e+00, 2.2968e+00, 4.4792e-03, 5.5187e-04, 1.3760e-01,
        4.4920e-02, 6.1432e-02, 2.1551e+00, 3.9153e+00, 8.6892e-01, 1.2391e-01,
        1.9455e-04, 3.2433e+00, 2.1863e+00, 8.4035e-02, 1.3366e+00, 1.5941e-01,
        6.0383e-04, 1.2317e-01, 4.9589e-02, 2.2322e-01, 1.3171e-02, 5.1269e+00,
        2.7959e+00, 7.2434e-03, 7.7976e-01, 1.3368e+00, 8.9046e-03, 4.6811e-02,
        1.8623e-01, 2.1335e+00, 2.1664e+00, 2.2053e-02, 2.1436e+00, 4.1679e+00,
        3.4193e+00, 2.1011e+00, 9.9628e-01, 1.6378e-02, 2.2713e+00, 2.2912e-01,
        5.2266e+00, 4.2243e+00, 1.1681e-01, 6.1329e-01, 3.4058e-01, 6.0112e-02,
        3.4064e-02, 8.2608e-02, 1.0127e+00, 4.3297e+00, 6.6358e-03, 1.8961e+00,
        1.2054e+00, 1.4795e-01, 1.0304e+00, 3.7138e-01, 1.8814e-03],
       device='cuda:0', grad_fn=<NegBackward0>)
Processing test sample 3/5 (before training)
torch.Size([200, 30522])
tensor([[-10.6331, -10.6154, -10.6768,  ...,  -9.5307,  -9.8039,  -5.3606],
        [-13.0971, -13.3752, -13.4156,  ..., -11.9633, -11.8711, -11.4156],
        [-13.0489, -13.0880, -13.0311,  ..., -12.0078,  -9.9702, -12.5524],
        ...,
        [-10.5784, -11.3892, -11.2995,  ..., -10.6506, -11.2471,  -8.3226],
        [ -7.5228,  -7.9948,  -8.3036,  ...,  -7.2513,  -8.6655,  -5.8722],
        [ -8.1169,  -8.2354,  -8.5296,  ...,  -8.5495,  -8.1505,  -4.9669]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([200])
tensor([7.0951e+00, 5.0911e+00, 3.4037e+00, 7.2400e-01, 2.2478e-01, 5.5022e-01,
        1.4172e+00, 2.5607e-01, 5.2387e+00, 4.6993e+00, 3.3093e+00, 4.7235e-01,
        5.3772e+00, 1.1284e-01, 1.6278e-01, 5.1921e+00, 4.4985e-01, 7.3134e-01,
        5.6445e-01, 4.3904e-01, 2.8900e+00, 2.1252e-01, 1.2432e+00, 2.1494e+00,
        1.2976e+00, 4.4020e+00, 2.3121e+00, 1.9768e-01, 3.8301e+00, 1.8844e+00,
        3.5779e+00, 1.9060e-02, 4.8604e+00, 1.9353e+00, 9.6093e-01, 7.3616e-01,
        1.2394e+00, 4.5802e+00, 1.0381e-01, 5.4071e-01, 1.1196e+00, 1.0356e+00,
        5.7181e+00, 4.0459e+00, 4.0389e+00, 2.1465e+00, 6.2551e+00, 8.0867e-01,
        8.9276e-02, 6.5820e+00, 2.3494e+00, 1.7440e-01, 4.1596e+00, 5.2168e+00,
        5.4130e-01, 8.0466e-02, 3.1090e+00, 7.8695e-01, 2.3363e+00, 2.8782e-02,
        1.6367e+00, 1.3431e-02, 4.9238e+00, 7.2452e-01, 4.6709e+00, 1.8845e+00,
        1.1446e-02, 1.2390e+00, 3.2114e+00, 2.1664e-01, 1.4977e+00, 5.9212e+00,
        1.1658e+00, 2.2339e+00, 4.0069e-01, 2.1967e-01, 7.7593e-03, 6.9312e+00,
        2.9294e+00, 6.7183e-02, 4.3769e+00, 3.5177e+00, 1.0966e-01, 1.0277e-01,
        3.7760e+00, 5.9045e+00, 4.9046e-01, 6.1268e+00, 1.3498e-02, 3.0102e+00,
        1.5168e+00, 1.6918e-01, 3.8148e+00, 1.2422e-01, 1.3662e+00, 4.9841e-01,
        4.2766e+00, 6.9145e+00, 9.8068e-01, 2.0537e-03, 3.9990e+00, 4.9040e-01,
        2.8469e+00, 4.2522e+00, 4.7235e+00, 3.5343e+00, 4.0899e+00, 2.9794e+00,
        2.5193e+00, 4.9409e+00, 7.8908e-01, 1.1298e+00, 2.0558e+00, 5.3722e+00,
        2.3194e+00, 2.9050e-02, 5.0696e+00, 1.5922e+00, 4.3559e-01, 5.3014e+00,
        1.7949e+00, 2.6498e-01, 2.1690e+00, 8.2311e-01, 8.0757e-02, 2.1266e-02,
        5.0829e+00, 6.1276e-01, 7.6358e-02, 2.7194e+00, 1.3084e-02, 5.0734e+00,
        8.9293e-02, 5.7350e-02, 5.6154e+00, 6.6978e-02, 6.2910e-02, 3.9423e-01,
        4.2956e+00, 2.5187e-01, 8.7715e-01, 6.8942e-01, 2.5817e+00, 5.0113e-01,
        2.0570e+00, 2.9676e+00, 8.0729e-01, 5.5791e-01, 2.2457e-01, 2.3500e+00,
        2.6116e+00, 3.1246e-03, 5.6674e-02, 6.6641e+00, 3.4352e-02, 5.5363e+00,
        1.5452e-01, 3.2954e-01, 1.5672e+00, 9.3530e-01, 1.2953e+00, 5.9786e+00,
        2.1210e-02, 2.1911e-03, 2.9078e+00, 6.2201e+00, 3.2850e-02, 1.5062e-02,
        5.5924e+00, 2.4358e-02, 2.4780e-03, 3.8889e+00, 5.6277e+00, 2.8238e-01,
        1.8192e+00, 1.1979e-01, 3.5801e+00, 9.4014e-01, 2.8840e-01, 2.3286e+00,
        6.4753e+00, 2.3860e-01, 3.3268e-01, 3.7651e-02, 6.2799e-01, 1.0588e+00,
        1.6958e-02, 1.5320e-02, 8.0811e+00, 5.1803e+00, 2.3879e-01, 5.7124e-01,
        1.2150e+00, 1.0499e+00, 7.4603e+00, 1.2025e-02, 5.8183e-04, 3.5613e+00,
        3.6983e+00, 3.8190e-01], device='cuda:0', grad_fn=<NegBackward0>)
Processing test sample 4/5 (before training)
torch.Size([378, 30522])
tensor([[ -7.7671,  -8.0302,  -7.8793,  ...,  -7.1686,  -7.5304,  -5.3420],
        [ -6.3812,  -6.9475,  -6.8668,  ...,  -5.6674,  -6.0188,  -8.9803],
        [-12.2523, -12.1362, -12.2715,  ..., -10.6794, -10.3833, -11.5163],
        ...,
        [ -6.8775,  -6.5712,  -6.5212,  ...,  -3.5857,  -6.3812,  -9.5421],
        [ -5.6243,  -5.5958,  -5.3395,  ...,  -4.0052,  -4.8298,  -7.7946],
        [-17.4714, -17.4613, -17.6178,  ..., -15.2373, -15.7087, -13.1977]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([378])
tensor([7.9076e+00, 3.5472e+00, 5.1219e-02, 3.8843e-03, 6.8463e-01, 3.4939e-03,
        1.6005e+00, 1.7211e-01, 3.9525e+00, 2.5897e-01, 3.9244e-03, 1.1221e+00,
        7.8671e-02, 3.4037e-03, 3.9612e+00, 5.3278e-01, 7.3787e-04, 4.2283e-03,
        5.3545e-02, 1.5468e+00, 2.9433e-02, 2.6076e-04, 2.1862e+00, 3.9018e-01,
        2.7044e-02, 9.5607e-02, 7.0173e-01, 7.1679e-01, 8.0086e-01, 1.7302e-04,
        2.5037e-01, 4.3822e-03, 2.5727e-03, 1.4181e+00, 7.3222e-01, 4.5732e-04,
        2.0975e-03, 3.6899e+00, 1.7447e+00, 1.0170e-04, 3.3800e-03, 6.8605e-01,
        1.8399e-04, 2.4741e+00, 8.8967e-01, 1.2398e-02, 6.6230e-01, 9.4722e-01,
        1.2320e+00, 2.3075e-01, 1.7771e-03, 1.7856e+00, 1.8132e-02, 3.1413e-02,
        1.4148e+00, 6.7091e-01, 1.6046e+00, 4.2814e-01, 2.7396e+00, 2.6071e+00,
        4.5703e+00, 1.6530e-03, 5.0028e+00, 1.2988e-01, 1.4691e+00, 2.1678e-01,
        1.6875e-04, 8.1569e-03, 4.4668e-02, 3.1908e-01, 6.2472e-05, 2.8954e+00,
        2.1755e-02, 2.6867e-01, 9.2956e-01, 1.2284e+00, 2.0959e-01, 2.2143e-01,
        8.6814e-04, 2.9525e+00, 9.3396e-01, 1.8760e-01, 1.4131e-01, 1.0316e-04,
        1.7634e-02, 5.0429e-02, 7.4422e-01, 3.2896e-04, 3.4275e-03, 2.9007e-01,
        1.5549e-01, 2.2780e-01, 2.2980e+00, 1.0156e+00, 4.8784e-01, 1.9910e-04,
        7.3077e-02, 9.0190e-03, 1.0563e+00, 2.9293e-03, 1.1446e+00, 1.2183e-02,
        5.7956e-01, 8.2600e-01, 1.1680e+00, 6.0310e-01, 1.5601e+00, 4.1438e-01,
        5.7570e-04, 6.3182e-03, 9.8106e-03, 5.1468e-02, 2.8320e+00, 7.1013e-02,
        3.6518e-02, 6.0908e+00, 3.0439e-01, 1.7547e-04, 4.7669e-02, 3.6154e-04,
        5.3419e+00, 3.0543e-01, 1.9289e-02, 5.1198e-03, 1.6659e-05, 2.5717e-04,
        3.8397e+00, 3.4616e+00, 6.9321e-04, 1.8261e-01, 1.8272e-05, 1.5495e-01,
        1.8243e-01, 4.8843e-01, 1.5560e+00, 2.1041e+00, 5.0304e-02, 4.4733e+00,
        3.1466e-02, 4.7968e-04, 7.7412e-02, 2.0857e+00, 9.1899e-01, 4.0054e-01,
        2.9941e+00, 7.8282e-02, 1.0932e-01, 4.5444e-05, 2.4098e-01, 8.9497e-04,
        4.5520e-04, 3.0066e-01, 3.5117e-01, 4.5825e-02, 2.1887e-02, 6.1463e-02,
        1.4706e-03, 5.5232e-02, 1.1112e-01, 1.1331e+00, 6.4970e-01, 8.0572e-03,
        1.2946e-02, 4.4362e+00, 7.0570e-01, 1.7742e+00, 4.3245e-01, 7.9390e-01,
        2.0554e-01, 1.9931e+00, 3.3231e-02, 1.2956e+00, 1.1000e+00, 4.8170e-01,
        1.0303e-01, 8.7686e-04, 2.4426e-01, 2.9322e-01, 3.7818e-03, 4.6900e+00,
        3.1045e-03, 4.5412e+00, 5.4679e-04, 2.3452e-03, 2.8667e+00, 3.3296e+00,
        5.3834e-01, 2.7449e-01, 6.3230e-01, 3.3692e+00, 3.0768e-02, 1.0360e+00,
        2.7546e-04, 2.2567e-03, 8.5142e-01, 2.0286e+00, 8.1043e-01, 1.7716e-01,
        1.1967e+00, 1.5846e-01, 6.8144e-04, 8.0021e-02, 1.5612e+00, 5.7562e-02,
        8.9017e-04, 2.8666e-01, 1.4408e+00, 1.6250e-04, 3.9253e-02, 1.9181e+00,
        1.2054e-02, 6.8949e-02, 2.5730e-04, 1.2614e+00, 4.0381e-01, 6.9015e-01,
        2.8887e-01, 3.6298e-03, 9.0381e-04, 7.0053e-01, 5.7241e-02, 1.3514e+00,
        3.0048e+00, 2.3712e-01, 4.3226e+00, 5.5294e+00, 2.8533e+00, 3.9350e-01,
        7.0960e-04, 2.1400e+00, 1.6056e+00, 3.6828e+00, 2.3512e+00, 1.3649e-02,
        3.4980e-02, 3.0014e+00, 7.7678e-01, 2.3587e+00, 1.5730e-01, 2.7127e-01,
        1.1010e-01, 3.0774e+00, 2.4795e-01, 2.8764e+00, 1.9958e-01, 1.1701e+00,
        2.2622e-01, 3.7048e+00, 3.3891e-01, 2.4504e+00, 2.4299e-01, 4.2789e+00,
        2.6896e-02, 3.6507e+00, 3.0344e-01, 2.2470e-02, 3.4858e+00, 1.9723e-04,
        1.1229e+00, 4.2237e+00, 2.5266e-01, 1.9797e+00, 2.1639e-03, 2.7559e+00,
        3.9989e-02, 3.8530e+00, 3.2066e-03, 4.1725e+00, 1.4349e-02, 7.8158e-01,
        4.0431e+00, 4.7762e-03, 6.6357e-01, 7.0209e-02, 1.2189e-01, 1.2875e+00,
        1.2573e-03, 1.7348e+00, 3.2166e-02, 3.8943e+00, 1.1915e-01, 1.4792e+00,
        7.9036e-03, 1.0669e+00, 5.1906e-04, 3.4174e+00, 4.8309e-01, 5.5010e-02,
        8.6015e-03, 8.2953e-01, 1.1642e+00, 8.0325e-02, 2.7448e-01, 1.1960e+00,
        1.0217e-02, 6.3661e-01, 1.4927e+00, 9.0240e-03, 4.1353e+00, 3.0817e+00,
        2.7042e+00, 1.8974e-03, 3.1528e-01, 1.1150e-01, 1.5675e+00, 3.8769e+00,
        7.0130e-04, 3.8737e-04, 1.1596e+00, 1.8821e-02, 1.8642e-01, 1.5783e-01,
        5.5342e-01, 1.2324e-01, 2.8058e+00, 3.2069e-01, 1.6538e-02, 6.9179e-02,
        1.7615e+00, 2.5273e-01, 1.1483e+00, 1.7209e-01, 4.0672e-02, 1.6503e+00,
        1.8834e+00, 5.4876e-01, 1.3115e+00, 2.8199e-03, 5.6314e-01, 2.7116e+00,
        4.7358e-01, 2.5028e-01, 3.3056e-02, 2.4803e-02, 6.8256e-01, 5.7888e-02,
        6.4731e-04, 1.4603e+00, 2.5623e-03, 3.7457e-04, 1.6964e-02, 1.6572e-02,
        4.3749e-01, 2.3571e-01, 1.6174e-03, 5.0908e-01, 4.8079e-02, 2.3248e-01,
        5.5090e-04, 2.0258e+00, 1.3712e-01, 4.9186e-03, 1.9143e-04, 3.3633e-01,
        6.6677e-01, 1.9907e+00, 3.6031e-03, 1.2130e+00, 1.8664e-01, 2.7829e-01,
        6.2202e+00, 2.0977e-03, 1.0681e+00, 2.5273e-01, 2.1849e-04, 1.1156e+00,
        5.2920e-01, 9.2066e-03, 8.8957e-01, 3.1886e-01, 5.6445e-01, 1.7339e+00,
        1.1890e+00, 3.2827e-02, 4.2797e+00, 4.4297e+00, 1.7088e-01, 3.9790e-04],
       device='cuda:0', grad_fn=<NegBackward0>)
Processing test sample 5/5 (before training)
torch.Size([249, 30522])
tensor([[-11.8598, -12.0230, -11.8058,  ..., -11.5038, -10.6545,  -7.6323],
        [-10.1111, -10.4923, -10.5482,  ..., -11.4285,  -9.1876, -10.5220],
        [ -9.5858, -10.1581, -10.1714,  ..., -12.4201,  -8.5976, -10.0323],
        ...,
        [-15.4900, -15.3985, -15.7995,  ..., -16.0324, -14.0765, -10.9679],
        [-12.5709, -12.5990, -12.8998,  ..., -12.2950, -10.7215, -10.1644],
        [-14.2814, -14.3351, -14.4203,  ..., -13.7795, -12.1040,  -7.9395]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([249])
tensor([5.9392e+00, 2.1935e-01, 5.1782e+00, 1.3450e-02, 5.7424e-03, 4.4436e+00,
        1.9305e+00, 1.3448e+00, 1.9667e-02, 4.3059e+00, 1.1819e-03, 1.6557e+00,
        4.6320e-02, 1.6838e-01, 1.9935e-02, 1.3387e+00, 8.6667e-01, 1.4980e-02,
        2.8833e-03, 3.9233e-01, 1.5699e-02, 7.0980e-01, 1.6668e-01, 7.3676e-02,
        2.7492e+00, 3.8991e-03, 5.1099e-01, 1.7201e+00, 1.5616e-03, 3.2070e+00,
        3.1118e+00, 1.1708e-02, 2.1344e-03, 7.4637e-01, 1.1514e-02, 4.6199e-01,
        5.2718e-01, 1.4398e-04, 2.6606e+00, 4.4237e+00, 7.2379e-01, 5.8434e-04,
        3.8843e+00, 6.3270e-02, 8.1011e-04, 2.5511e-01, 3.2284e-01, 4.3827e-03,
        4.3034e+00, 7.9590e-02, 5.9880e-04, 3.6222e+00, 6.7322e-01, 3.1852e-01,
        3.7001e-02, 8.6592e-02, 6.0240e-01, 3.5706e-03, 5.7352e-02, 5.0434e+00,
        3.6198e-01, 1.2403e-02, 2.4598e-01, 6.6077e-01, 3.2588e-03, 4.5062e-01,
        1.2716e-03, 3.2380e-02, 1.5408e+00, 1.1532e-03, 2.2822e-02, 2.6858e+00,
        2.9608e-01, 9.1898e-01, 9.3799e-02, 4.1184e-02, 3.6001e+00, 3.6349e-03,
        3.8292e-01, 5.7825e-03, 9.9620e-02, 4.1073e+00, 2.7358e-02, 1.1669e+00,
        4.1216e-01, 1.1938e-03, 1.4335e-02, 4.4612e-01, 4.8905e-03, 4.2644e-01,
        4.3897e-02, 1.7368e-02, 1.5791e+00, 1.7569e-03, 3.3335e+00, 4.1312e+00,
        3.5796e-02, 1.3399e-03, 3.4694e+00, 6.8101e-04, 1.5681e-02, 3.2922e-01,
        1.7324e-04, 3.8169e+00, 1.7433e+00, 9.6466e-01, 3.2838e+00, 1.6100e-03,
        8.2883e-01, 6.7044e-02, 5.7362e-04, 1.5014e-01, 5.4308e-02, 3.2897e-02,
        3.6539e+00, 1.2007e-01, 5.5935e-04, 2.6877e+00, 1.1129e-01, 6.2513e-02,
        2.7573e+00, 9.6246e-04, 3.8439e-03, 6.6172e-02, 2.2982e+00, 1.3423e+00,
        4.0181e-01, 1.5896e-02, 1.1433e+00, 4.0243e-02, 1.5553e-01, 4.0523e-01,
        6.7750e-02, 6.6725e-01, 1.9098e+00, 1.5689e+00, 2.6338e+00, 8.4835e-02,
        2.7754e-02, 1.7960e+00, 8.7413e-01, 2.4374e-02, 1.3209e-01, 4.9681e-02,
        3.9719e-03, 4.0324e+00, 3.7978e+00, 5.0388e-01, 1.0761e+00, 4.7500e-04,
        1.1793e-01, 5.6990e-01, 1.4860e-01, 8.0424e-01, 1.7422e-03, 4.6240e-02,
        2.6982e-02, 3.6495e+00, 1.2894e-03, 5.1868e-02, 5.6640e-04, 9.7397e-04,
        7.6232e-01, 5.2501e-03, 1.6104e-01, 4.0213e+00, 3.1467e-01, 1.2859e-01,
        1.3629e+00, 5.0815e-02, 2.7764e+00, 5.3452e-02, 4.9133e+00, 1.5556e-03,
        7.1797e-02, 6.5292e-02, 1.7606e+00, 2.5592e-02, 3.3643e+00, 5.7352e+00,
        1.0477e-03, 2.1339e+00, 3.9374e+00, 1.5592e+00, 1.8137e+00, 6.9868e-01,
        5.2548e-01, 5.2726e-01, 4.9701e+00, 1.3935e-01, 1.6659e-02, 3.1011e+00,
        4.6322e+00, 3.4605e-02, 5.1520e-03, 5.3700e+00, 1.2492e-03, 3.4732e-02,
        7.9614e-01, 5.0234e-01, 1.0250e+00, 1.7801e-03, 4.8248e+00, 6.3700e-01,
        1.1826e+00, 3.2649e-02, 5.2069e+00, 8.9884e-02, 1.0865e-02, 2.9931e-03,
        3.6914e+00, 3.1382e+00, 2.2773e-03, 3.3412e-01, 2.3911e+00, 4.1049e+00,
        4.3215e-04, 2.4524e+00, 3.2812e-02, 3.9796e+00, 2.0272e+00, 1.1302e-03,
        3.5076e-02, 1.6191e-03, 1.8798e-03, 3.1698e+00, 2.1157e-03, 3.2076e+00,
        5.6388e-01, 2.8066e+00, 5.0185e-01, 1.8909e-01, 2.8355e-01, 4.8239e+00,
        5.8125e-01, 5.3367e-02, 2.2396e+00, 1.7259e-01, 1.3433e-02, 2.2036e+00,
        5.6059e+00, 7.9929e-01, 2.3138e+00, 4.5579e-03, 1.5494e+00, 4.1341e-01,
        2.4517e-02, 4.6049e+00, 3.7090e-03], device='cuda:0',
       grad_fn=<NegBackward0>)
Training model...
  0%|          | 0/350 [00:00<?, ?it/s]  0%|          | 1/350 [00:00<01:06,  5.22it/s]  1%|          | 3/350 [00:00<00:36,  9.56it/s]  1%|â–         | 5/350 [00:00<00:29, 11.78it/s]  2%|â–         | 7/350 [00:00<00:26, 12.78it/s]  3%|â–Ž         | 9/350 [00:00<00:25, 13.30it/s]  3%|â–Ž         | 11/350 [00:00<00:24, 13.69it/s]  4%|â–Ž         | 13/350 [00:01<00:24, 13.92it/s]  4%|â–         | 15/350 [00:01<00:23, 14.10it/s]  5%|â–         | 17/350 [00:01<00:23, 14.22it/s]  5%|â–Œ         | 19/350 [00:01<00:23, 14.30it/s]  6%|â–Œ         | 21/350 [00:01<00:22, 14.34it/s]  7%|â–‹         | 23/350 [00:01<00:22, 14.37it/s]  7%|â–‹         | 25/350 [00:01<00:22, 14.39it/s]  8%|â–Š         | 27/350 [00:01<00:22, 14.41it/s]  8%|â–Š         | 29/350 [00:02<00:22, 14.43it/s]  9%|â–‰         | 31/350 [00:02<00:22, 14.44it/s]  9%|â–‰         | 33/350 [00:02<00:21, 14.43it/s] 10%|â–ˆ         | 35/350 [00:02<00:20, 15.25it/s] 11%|â–ˆ         | 37/350 [00:02<00:20, 15.03it/s] 11%|â–ˆ         | 39/350 [00:02<00:20, 14.85it/s] 12%|â–ˆâ–        | 41/350 [00:02<00:21, 14.71it/s] 12%|â–ˆâ–        | 43/350 [00:03<00:21, 14.60it/s] 13%|â–ˆâ–Ž        | 45/350 [00:03<00:20, 14.55it/s] 13%|â–ˆâ–Ž        | 47/350 [00:03<00:20, 14.50it/s] 14%|â–ˆâ–        | 49/350 [00:03<00:20, 14.47it/s] 15%|â–ˆâ–        | 51/350 [00:03<00:20, 14.46it/s] 15%|â–ˆâ–Œ        | 53/350 [00:03<00:20, 14.46it/s] 16%|â–ˆâ–Œ        | 55/350 [00:03<00:20, 14.43it/s] 16%|â–ˆâ–‹        | 57/350 [00:04<00:20, 14.43it/s] 17%|â–ˆâ–‹        | 59/350 [00:04<00:20, 14.42it/s] 17%|â–ˆâ–‹        | 61/350 [00:04<00:20, 14.41it/s] 18%|â–ˆâ–Š        | 63/350 [00:04<00:19, 14.40it/s] 19%|â–ˆâ–Š        | 65/350 [00:04<00:19, 14.41it/s] 19%|â–ˆâ–‰        | 67/350 [00:04<00:19, 14.41it/s] 20%|â–ˆâ–‰        | 69/350 [00:04<00:19, 14.52it/s] 20%|â–ˆâ–ˆ        | 71/350 [00:04<00:18, 15.42it/s] 21%|â–ˆâ–ˆ        | 73/350 [00:05<00:18, 15.09it/s] 21%|â–ˆâ–ˆâ–       | 75/350 [00:05<00:18, 14.88it/s] 22%|â–ˆâ–ˆâ–       | 77/350 [00:05<00:18, 14.71it/s] 23%|â–ˆâ–ˆâ–Ž       | 79/350 [00:05<00:18, 14.61it/s] 23%|â–ˆâ–ˆâ–Ž       | 81/350 [00:05<00:18, 14.55it/s] 24%|â–ˆâ–ˆâ–Ž       | 83/350 [00:05<00:18, 14.51it/s] 24%|â–ˆâ–ˆâ–       | 85/350 [00:05<00:18, 14.48it/s] 25%|â–ˆâ–ˆâ–       | 87/350 [00:06<00:18, 14.46it/s] 25%|â–ˆâ–ˆâ–Œ       | 89/350 [00:06<00:18, 14.45it/s] 26%|â–ˆâ–ˆâ–Œ       | 91/350 [00:06<00:17, 14.45it/s] 27%|â–ˆâ–ˆâ–‹       | 93/350 [00:06<00:17, 14.42it/s] 27%|â–ˆâ–ˆâ–‹       | 95/350 [00:06<00:17, 14.41it/s] 28%|â–ˆâ–ˆâ–Š       | 97/350 [00:06<00:17, 14.41it/s] 28%|â–ˆâ–ˆâ–Š       | 99/350 [00:06<00:17, 14.44it/s]                                                {'loss': 0.4063, 'grad_norm': 9.45599365234375, 'learning_rate': 3.6e-05, 'epoch': 2.86}
 29%|â–ˆâ–ˆâ–Š       | 100/350 [00:07<00:17, 14.44it/s] 29%|â–ˆâ–ˆâ–‰       | 101/350 [00:07<00:17, 14.41it/s] 29%|â–ˆâ–ˆâ–‰       | 103/350 [00:07<00:17, 14.43it/s] 30%|â–ˆâ–ˆâ–ˆ       | 105/350 [00:07<00:15, 15.55it/s] 31%|â–ˆâ–ˆâ–ˆ       | 107/350 [00:07<00:15, 15.25it/s] 31%|â–ˆâ–ˆâ–ˆ       | 109/350 [00:07<00:16, 15.01it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 111/350 [00:07<00:16, 14.84it/s] 32%|â–ˆâ–ˆâ–ˆâ–      | 113/350 [00:07<00:16, 14.73it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 115/350 [00:08<00:16, 14.65it/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/350 [00:08<00:15, 14.59it/s] 34%|â–ˆâ–ˆâ–ˆâ–      | 119/350 [00:08<00:15, 14.56it/s] 35%|â–ˆâ–ˆâ–ˆâ–      | 121/350 [00:08<00:15, 14.54it/s] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 123/350 [00:08<00:15, 14.52it/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 125/350 [00:08<00:15, 14.51it/s] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 127/350 [00:08<00:15, 14.49it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 129/350 [00:08<00:15, 14.47it/s] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 131/350 [00:09<00:15, 14.47it/s] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 133/350 [00:09<00:14, 14.48it/s] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 135/350 [00:09<00:14, 14.47it/s] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 137/350 [00:09<00:14, 14.47it/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 139/350 [00:09<00:14, 14.57it/s] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 141/350 [00:09<00:13, 15.58it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 143/350 [00:09<00:13, 15.22it/s] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 145/350 [00:10<00:13, 14.99it/s] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 147/350 [00:10<00:13, 14.81it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 149/350 [00:10<00:13, 14.69it/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 151/350 [00:10<00:13, 14.62it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 153/350 [00:10<00:13, 14.58it/s] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 155/350 [00:10<00:13, 14.55it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/350 [00:10<00:13, 14.53it/s] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 159/350 [00:11<00:13, 14.50it/s] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 161/350 [00:11<00:13, 14.48it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 163/350 [00:11<00:12, 14.47it/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 165/350 [00:11<00:12, 14.48it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 167/350 [00:11<00:12, 14.48it/s] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 169/350 [00:11<00:12, 14.46it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 171/350 [00:11<00:12, 14.40it/s] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 173/350 [00:11<00:12, 14.40it/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 175/350 [00:12<00:11, 15.52it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 177/350 [00:12<00:11, 15.24it/s] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 179/350 [00:12<00:11, 14.99it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 181/350 [00:12<00:11, 14.82it/s] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/350 [00:12<00:11, 14.71it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 185/350 [00:12<00:11, 14.64it/s] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 187/350 [00:12<00:11, 14.59it/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 189/350 [00:13<00:11, 14.55it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 191/350 [00:13<00:10, 14.52it/s] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 193/350 [00:13<00:10, 14.49it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 195/350 [00:13<00:10, 14.47it/s] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 197/350 [00:13<00:10, 14.45it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 199/350 [00:13<00:10, 14.45it/s]                                                 {'loss': 0.0581, 'grad_norm': 3.3791725635528564, 'learning_rate': 2.1714285714285715e-05, 'epoch': 5.71}
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 200/350 [00:13<00:10, 14.45it/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 201/350 [00:13<00:10, 14.43it/s] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 203/350 [00:14<00:10, 14.43it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 205/350 [00:14<00:10, 14.41it/s] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 207/350 [00:14<00:09, 14.42it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 209/350 [00:14<00:09, 14.53it/s] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 211/350 [00:14<00:09, 15.40it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 213/350 [00:14<00:09, 15.10it/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 215/350 [00:14<00:09, 14.90it/s] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 217/350 [00:14<00:09, 14.76it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 219/350 [00:15<00:08, 14.67it/s] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 221/350 [00:15<00:08, 14.60it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 223/350 [00:15<00:08, 14.55it/s] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 225/350 [00:15<00:08, 14.51it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 227/350 [00:15<00:08, 14.49it/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 229/350 [00:15<00:08, 14.49it/s] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 231/350 [00:15<00:08, 14.48it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 233/350 [00:16<00:08, 14.48it/s] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 235/350 [00:16<00:07, 14.46it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 237/350 [00:16<00:07, 14.45it/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 239/350 [00:16<00:07, 14.43it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 241/350 [00:16<00:07, 14.42it/s] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 243/350 [00:16<00:07, 14.43it/s] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 245/350 [00:16<00:06, 15.53it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 247/350 [00:17<00:06, 15.21it/s] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 249/350 [00:17<00:06, 14.97it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 251/350 [00:17<00:06, 14.81it/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 253/350 [00:17<00:06, 14.69it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 255/350 [00:17<00:06, 14.61it/s] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 257/350 [00:17<00:06, 14.55it/s] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 259/350 [00:17<00:06, 14.51it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 261/350 [00:17<00:06, 14.46it/s] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 263/350 [00:18<00:06, 14.44it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 265/350 [00:18<00:05, 14.43it/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 267/350 [00:18<00:05, 14.43it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 269/350 [00:18<00:05, 14.44it/s] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 271/350 [00:18<00:05, 14.44it/s] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 273/350 [00:18<00:05, 14.45it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 275/350 [00:18<00:05, 14.43it/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 277/350 [00:19<00:05, 14.41it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 279/350 [00:19<00:04, 14.49it/s] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 281/350 [00:19<00:04, 15.38it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 283/350 [00:19<00:04, 15.09it/s] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 285/350 [00:19<00:04, 14.89it/s] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 287/350 [00:19<00:04, 14.75it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 289/350 [00:19<00:04, 14.65it/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 291/350 [00:20<00:04, 14.57it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 293/350 [00:20<00:03, 14.51it/s] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 295/350 [00:20<00:03, 14.46it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 297/350 [00:20<00:03, 14.45it/s] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 299/350 [00:20<00:03, 14.43it/s]                                                 {'loss': 0.0377, 'grad_norm': 0.7391067743301392, 'learning_rate': 7.428571428571429e-06, 'epoch': 8.57}
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 300/350 [00:20<00:03, 14.43it/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 301/350 [00:20<00:03, 14.40it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 303/350 [00:20<00:03, 14.40it/s] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 305/350 [00:21<00:03, 14.39it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 307/350 [00:21<00:02, 14.40it/s] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 309/350 [00:21<00:02, 14.40it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 311/350 [00:21<00:02, 14.40it/s] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 313/350 [00:21<00:02, 14.40it/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 315/350 [00:21<00:02, 15.47it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 317/350 [00:21<00:02, 15.17it/s] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 319/350 [00:21<00:02, 14.93it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 321/350 [00:22<00:01, 14.77it/s] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 323/350 [00:22<00:01, 14.64it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 325/350 [00:22<00:01, 14.55it/s] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 327/350 [00:22<00:01, 14.50it/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329/350 [00:22<00:01, 14.46it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 331/350 [00:22<00:01, 14.43it/s] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 333/350 [00:22<00:01, 14.41it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 335/350 [00:23<00:01, 14.40it/s] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 337/350 [00:23<00:00, 14.38it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 339/350 [00:23<00:00, 14.38it/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 341/350 [00:23<00:00, 14.37it/s] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 343/350 [00:23<00:00, 14.38it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 345/350 [00:23<00:00, 14.38it/s] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 347/350 [00:23<00:00, 14.39it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 349/350 [00:24<00:00, 14.49it/s]                                                 {'train_runtime': 24.0855, 'train_samples_per_second': 227.107, 'train_steps_per_second': 14.532, 'train_loss': 0.1487437129020691, 'epoch': 10.0}
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [00:24<00:00, 14.49it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 350/350 [00:24<00:00, 14.53it/s]
Calculating uncertainties for 5 test samples after training (counterfactual mode: identity)...
Processing test sample 1/5 (after training)
torch.Size([135, 30522])
tensor([[ -9.4844, -10.1641,  -9.9609,  ...,  -9.6641, -10.5156,  -5.7969],
        [-10.3672, -10.5859, -10.8906,  ...,  -9.0781,  -8.9688,  -5.8516],
        [ -5.5781,  -6.0586,  -5.7695,  ...,  -5.4688,  -4.8203,  -4.4492],
        ...,
        [-10.6875, -10.8359, -10.8359,  ..., -10.5781,  -9.5234,  -6.5000],
        [ -7.5039,  -7.7656,  -7.8398,  ...,  -5.9844,  -6.1406,  -8.3047],
        [-16.8906, -16.8750, -17.3281,  ..., -15.0625, -14.8125, -12.1719]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([135])
tensor([5.1255e-01, 9.1919e-01, 3.9321e+00, 4.8706e-02, 1.2604e+00, 4.8586e-04,
        2.0002e+00, 1.8720e-04, 2.6955e+00, 1.0158e-04, 5.6193e-01, 1.9029e-04,
        1.5966e-01, 3.8461e-02, 3.2169e-01, 7.5689e-04, 6.1048e-01, 5.7568e-04,
        7.1083e-03, 1.5721e-02, 4.4290e-01, 1.6433e+00, 8.4333e-06, 1.0532e-03,
        3.0668e-01, 4.3720e-04, 8.2345e-01, 3.3582e-01, 1.6564e-03, 7.7231e-06,
        5.9022e-02, 2.4204e-05, 4.0586e-04, 1.0698e-02, 8.6114e-04, 1.0098e-01,
        7.1697e-04, 1.2949e-01, 5.4641e-04, 9.2776e-05, 2.8838e-01, 3.4184e+00,
        7.7311e-04, 2.1350e-03, 9.4976e-01, 1.1162e-01, 4.4236e-01, 3.4954e-01,
        1.3153e-04, 1.3626e+00, 1.5822e-03, 2.8803e-01, 1.9432e-03, 3.4674e+00,
        6.7113e-02, 2.0900e-01, 8.8148e-04, 4.6237e-05, 2.3941e+00, 1.6103e+00,
        3.8975e-04, 5.1372e-05, 2.4952e+00, 8.2579e-06, 6.9070e-04, 4.5192e+00,
        3.2108e-04, 5.9540e-02, 4.1551e-05, 2.7937e-01, 9.5789e-05, 7.9819e-01,
        3.3255e+00, 5.8710e-02, 2.2738e-04, 1.7598e+00, 1.9898e-04, 7.5895e-04,
        1.8301e-01, 4.1454e-04, 2.2028e-01, 3.0686e-05, 4.5125e-01, 1.9805e+00,
        1.2610e-04, 1.5800e+00, 3.6193e-01, 2.2354e+00, 2.1405e-02, 3.7256e+00,
        2.5067e-03, 8.5609e-03, 1.4285e+00, 1.6235e-01, 2.4654e-03, 2.8084e-01,
        7.2737e-05, 1.7809e-05, 2.9170e-02, 2.7881e-05, 4.9545e-02, 5.2189e-01,
        2.2660e-03, 1.5402e-01, 6.7150e-03, 7.2024e-04, 2.8161e+00, 4.3495e-03,
        3.0324e-02, 8.6800e-05, 1.7630e-01, 5.8021e-04, 2.1365e-01, 7.7237e-04,
        5.0941e-01, 7.3828e-02, 1.7774e-01, 2.9485e-03, 4.7111e-05, 3.7961e-02,
        2.0963e-01, 5.8934e-03, 2.9395e-01, 1.2854e-03, 8.7938e-01, 5.5472e-04,
        9.2483e-05, 2.7859e+00, 2.0849e-05, 4.1498e-01, 2.5495e-04, 2.4641e-02,
        2.8846e-05, 2.4467e+00, 2.3361e-04], device='cuda:0',
       grad_fn=<NegBackward0>)
Processing test sample 2/5 (after training)
torch.Size([167, 30522])
tensor([[ -9.5391,  -9.9531,  -9.4219,  ...,  -9.1641, -10.1562,  -5.2305],
        [ -8.8516,  -9.2266,  -8.8125,  ...,  -8.5859,  -9.2031,  -8.8828],
        [ -6.8320,  -7.1289,  -6.6602,  ...,  -7.1328,  -7.1094,  -3.1973],
        ...,
        [-12.6016, -12.9375, -12.8672,  ..., -11.7109, -10.9062,  -9.2344],
        [ -9.1641,  -9.3359,  -9.2344,  ...,  -6.4766,  -7.7578,  -5.2773],
        [-12.8828, -12.6016, -13.3125,  ..., -11.4062, -10.4688,  -8.5234]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([167])
tensor([1.4521e+00, 8.0456e-01, 8.5637e-01, 3.9416e-04, 1.7068e-02, 2.0725e-03,
        6.2776e-02, 6.8706e-02, 8.6321e-03, 2.9945e+00, 9.1703e-05, 1.3643e-02,
        1.1827e+00, 9.2801e-01, 4.2316e-01, 3.9400e-03, 2.1461e-01, 6.7078e-04,
        1.7293e-03, 4.1136e-01, 5.9328e-02, 2.6728e-02, 3.9186e-02, 8.3446e-02,
        3.0963e-01, 1.5296e-04, 3.4875e-02, 6.1816e-02, 2.1927e-01, 4.9843e-03,
        1.8210e-03, 4.5280e-02, 3.4599e-01, 3.3059e-01, 6.4512e-01, 1.9462e-04,
        1.7243e-03, 6.4699e-01, 4.1697e-03, 1.2056e-01, 4.3341e-05, 3.2492e+00,
        2.2983e+00, 1.6117e-01, 2.5018e-02, 4.9612e-04, 8.5748e-02, 1.5138e+00,
        1.2200e-01, 1.1531e+00, 4.3601e-01, 7.8404e-02, 2.7530e-01, 1.5186e+00,
        2.1644e-01, 1.4025e-03, 1.0416e-01, 2.8559e+00, 7.1462e-02, 7.1541e-01,
        1.4181e+00, 5.4458e-02, 8.0287e-02, 3.4909e-01, 1.5317e-02, 5.9844e-02,
        5.8300e-01, 1.7682e-01, 7.1583e-01, 3.7959e-04, 1.3427e-02, 7.5362e-04,
        1.6996e+00, 1.8305e-04, 3.5687e-02, 1.1419e-01, 3.9145e-01, 6.8762e-04,
        1.1482e-01, 1.5066e-03, 9.9536e-01, 2.5279e-04, 9.9741e-02, 1.6789e-03,
        3.9948e-01, 1.0265e+00, 5.1653e-04, 5.4769e-02, 1.6530e-02, 2.2459e+00,
        1.1405e-03, 1.0180e+00, 2.8241e-05, 2.8361e-02, 2.1442e-01, 2.1816e-04,
        2.3189e-02, 6.5356e-03, 1.6178e+00, 7.3252e-02, 2.9374e+00, 2.8785e-03,
        3.7531e+00, 2.8795e+00, 1.1937e+00, 3.7848e-02, 2.8330e-02, 1.4049e+00,
        1.3188e-04, 9.6694e-03, 1.4877e+00, 1.8633e-03, 1.4478e-05, 3.0049e-01,
        1.8446e-04, 1.0637e-02, 1.3003e-02, 9.0928e-01, 1.1903e-01, 7.0223e-02,
        7.2556e-05, 4.2228e+00, 9.2024e-01, 3.9075e-04, 2.5664e-01, 1.2515e-02,
        5.3320e-05, 2.6653e-01, 4.4195e-05, 9.4497e-05, 1.1302e-03, 1.7913e+00,
        3.6223e+00, 9.0829e-02, 8.0381e-01, 1.1066e+00, 1.0013e-04, 3.3231e-02,
        2.0056e-04, 4.9020e-01, 1.1858e+00, 7.9022e-04, 7.4337e-01, 1.0728e-01,
        5.3522e-04, 1.2093e-01, 3.5325e-01, 1.9642e-05, 6.4875e-03, 6.2192e-04,
        2.0732e+00, 2.8672e+00, 3.9813e-02, 8.1639e-01, 3.1593e-02, 6.2804e-04,
        1.1190e-02, 3.9484e-05, 1.9931e-01, 1.5008e-01, 5.9792e-04, 7.9219e-01,
        3.1581e-02, 1.2881e-04, 3.6925e-01, 8.5363e-03, 1.7347e-04],
       device='cuda:0', grad_fn=<NegBackward0>)
Processing test sample 3/5 (after training)
torch.Size([200, 30522])
tensor([[-11.9922, -12.6875, -12.7344,  ..., -11.8984, -12.4062,  -7.8906],
        [-10.9609, -11.5859, -11.8125,  ...,  -9.4062,  -9.6094, -12.4062],
        [ -7.2070,  -7.4414,  -7.5742,  ...,  -6.7266,  -6.7891,  -7.6602],
        ...,
        [ -9.1953,  -9.8438,  -9.7969,  ...,  -8.2500,  -8.0859, -13.8672],
        [ -4.6523,  -4.7070,  -4.7617,  ...,  -3.0586,  -4.2734,  -8.5000],
        [-13.4219, -13.4609, -14.0547,  ..., -12.6797, -11.4844,  -6.8086]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([200])
tensor([1.8939e-01, 4.6892e-01, 1.1520e+00, 1.2537e-02, 1.1973e-02, 2.6951e+00,
        7.0290e-01, 4.2547e-05, 3.2696e-02, 2.6070e+00, 8.4033e-02, 6.1501e-01,
        2.2510e+00, 2.1960e-02, 1.6426e-03, 5.5060e-01, 2.2137e-01, 1.0510e-02,
        2.8954e-02, 8.7219e-04, 1.9393e+00, 6.4948e-02, 3.5431e-02, 4.7511e-01,
        3.5287e-02, 1.5492e+00, 6.6794e-02, 1.3407e-01, 3.4540e-01, 2.8165e-01,
        8.9163e-02, 1.6318e-03, 2.3365e+00, 2.1994e+00, 2.8814e-01, 2.3617e-02,
        7.1551e-05, 2.4325e+00, 1.5208e-03, 2.4009e-04, 2.1728e-02, 5.6577e-05,
        9.0583e-02, 7.8734e-01, 1.3428e-01, 7.2041e-01, 5.6110e-01, 6.0353e-01,
        1.1077e-02, 6.6761e-01, 4.5747e-05, 5.5093e-04, 2.0567e-02, 1.7592e-01,
        1.0544e-02, 3.0456e-03, 1.3912e+00, 8.0406e-03, 5.2409e-01, 1.2814e-04,
        4.6480e-01, 5.0254e-04, 2.7482e-01, 3.1240e-02, 3.2277e+00, 1.5566e-02,
        4.1922e-02, 1.6086e-01, 1.8217e+00, 8.7112e-03, 9.4675e-02, 8.6028e-01,
        6.5819e-04, 7.0867e-02, 7.5270e-02, 4.2531e-01, 3.0691e-03, 8.6574e-01,
        3.6657e-03, 1.0878e-03, 1.6475e+00, 1.2497e+00, 3.8750e-04, 8.5976e-04,
        5.3154e-02, 1.0036e+00, 5.3842e-01, 2.6790e-01, 1.5672e-03, 2.5276e-03,
        8.5405e-03, 2.0126e-03, 6.2928e-01, 3.6776e-04, 2.0221e-01, 4.1539e-05,
        3.6766e-02, 2.6870e-03, 2.3520e-02, 3.9280e-04, 6.9984e-01, 6.6755e-01,
        2.6257e+00, 1.5359e+00, 9.3967e-01, 4.3473e-01, 2.2018e-01, 2.1564e+00,
        1.1736e+00, 5.6993e-01, 3.0481e-06, 9.3384e-01, 2.7023e-02, 6.1931e-01,
        9.1377e-02, 4.2868e-05, 6.6613e-01, 2.6499e-03, 5.0624e-03, 5.9835e-01,
        1.1404e-05, 1.0116e-03, 2.0751e-02, 1.1624e-02, 1.6833e-04, 8.2501e-06,
        5.6558e-01, 2.3797e-03, 3.0559e-03, 1.5145e-02, 9.0466e-06, 2.4855e+00,
        1.5548e-04, 3.2793e-03, 8.0562e-01, 8.8827e-02, 8.2208e-05, 3.2453e-02,
        1.5123e+00, 2.4797e-03, 1.8122e-03, 1.7236e-01, 1.3487e-02, 1.9041e-04,
        2.0398e-02, 1.3715e+00, 2.7157e-01, 1.2642e-02, 1.7457e-04, 1.6304e-01,
        1.5941e-01, 4.0410e-02, 1.4221e-02, 1.2531e+00, 3.7658e-03, 1.8454e-01,
        3.0778e-04, 2.4611e-02, 5.5395e-04, 9.8957e-04, 1.7250e-02, 1.7399e-01,
        3.0202e-03, 5.2322e-05, 4.0810e-02, 4.7109e-01, 8.2703e-05, 8.0618e-03,
        1.9488e+00, 3.1431e-02, 2.8186e-05, 9.9156e-02, 1.8103e+00, 1.6779e-03,
        5.9491e-01, 1.2357e-02, 5.1614e-01, 4.4605e-02, 2.3672e-03, 2.8153e-02,
        1.2611e-01, 1.4606e-04, 8.6643e-03, 9.8778e-04, 2.3750e-02, 2.5793e-01,
        1.1221e-02, 7.3064e-04, 1.7618e+00, 5.2437e-01, 9.7787e-02, 6.0544e-04,
        8.6238e-02, 7.4621e-02, 1.0636e+00, 1.8511e-03, 1.0625e-04, 7.4756e-02,
        1.7615e-01, 9.1905e-05], device='cuda:0', grad_fn=<NegBackward0>)
Processing test sample 4/5 (after training)
torch.Size([378, 30522])
tensor([[ -9.9141, -10.6172, -10.4609,  ...,  -9.6641, -10.1172,  -5.7305],
        [ -7.1211,  -7.7305,  -7.2969,  ...,  -6.6172,  -6.5508,  -8.7266],
        [ -8.4766,  -8.7422,  -8.7812,  ...,  -7.8125,  -5.7852, -10.6328],
        ...,
        [ -6.9297,  -7.0859,  -6.8359,  ...,  -4.8750,  -6.7344, -10.4453],
        [ -9.1562,  -9.6016,  -9.2656,  ...,  -8.5312,  -7.8555,  -9.0000],
        [-14.0469, -13.8750, -14.5000,  ..., -11.9531, -12.6094, -10.7500]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([378])
tensor([3.8553e-01, 2.8348e+00, 2.8195e-04, 1.5205e-04, 5.6851e-01, 8.4577e-06,
        4.7764e-01, 3.1238e-03, 1.6901e+00, 1.4198e-04, 2.2941e-04, 2.5089e+00,
        1.8995e-05, 6.9134e-05, 9.6239e-01, 5.8179e-01, 3.0643e-04, 1.3244e-02,
        1.2132e+00, 1.2419e-01, 2.6087e-04, 2.8556e-04, 3.7473e+00, 2.4324e+00,
        6.4223e-03, 6.9604e-03, 1.7211e-01, 7.8215e-01, 7.4572e-02, 8.6871e-05,
        2.7889e-01, 6.9276e-05, 2.2216e-06, 3.8296e-01, 1.6566e-02, 2.9709e-03,
        2.8131e-02, 4.2383e+00, 7.5027e-02, 4.0172e-05, 4.1099e-05, 9.9623e-02,
        2.1811e-04, 1.0208e+00, 4.4442e+00, 7.3854e-04, 5.3112e-01, 1.5707e-02,
        8.4257e-02, 5.2148e-03, 5.1120e-05, 2.1387e+00, 6.1276e-06, 5.8890e-04,
        1.6333e+00, 1.1783e-02, 9.9655e-03, 6.1722e-01, 1.0928e+00, 1.5664e-02,
        1.1788e+00, 1.4129e-02, 1.0150e+00, 3.9711e-02, 1.4832e-01, 1.7019e-01,
        3.5951e-04, 8.1644e-04, 1.8371e-04, 2.6896e-01, 3.7636e-04, 1.2740e+00,
        1.2817e-02, 3.8198e-02, 1.9733e+00, 3.5716e+00, 6.0152e-03, 1.0824e-01,
        2.1372e-01, 1.9033e+00, 2.6076e-01, 1.2104e-01, 2.3173e-01, 1.8184e-04,
        2.8904e-03, 1.4099e-02, 1.6720e+00, 1.5369e-04, 1.0096e-05, 2.0760e-01,
        2.5670e-01, 8.7200e-04, 1.0099e-02, 1.0646e-02, 3.6981e-05, 1.2573e-05,
        9.7890e-02, 1.6641e-01, 9.9301e-02, 7.5492e-05, 1.1001e-01, 1.1500e-02,
        2.0775e-02, 5.5488e-01, 8.5962e-01, 1.3598e+00, 3.4080e+00, 2.2865e-02,
        2.1325e-05, 4.8863e-01, 1.1982e-04, 2.5811e-01, 8.6388e-01, 3.5481e-01,
        2.0125e-02, 3.9307e+00, 1.9932e+00, 1.1367e-06, 4.1611e-02, 1.1914e-05,
        3.6846e+00, 5.3904e-01, 7.1557e-02, 4.9478e-04, 7.9725e-06, 1.4574e-05,
        3.1618e+00, 1.4403e-01, 1.0578e-04, 4.7761e-03, 2.1844e-05, 6.1362e-01,
        1.9044e-04, 3.2152e-01, 9.4649e-02, 3.6284e+00, 3.2755e-01, 3.6144e+00,
        3.6174e-01, 3.1518e-04, 3.0636e-01, 3.4421e-02, 2.4663e+00, 1.0041e-01,
        2.2102e+00, 6.2345e-02, 2.0424e-02, 6.2254e-05, 9.1169e-01, 5.2700e-03,
        4.8442e-06, 2.2935e+00, 1.0381e+00, 1.2402e-03, 9.1930e-03, 7.7591e-03,
        1.0032e-05, 5.1484e-02, 7.1230e-02, 5.4739e-01, 5.7629e-01, 8.0447e-02,
        3.3371e-02, 4.2309e+00, 3.1097e+00, 4.2433e-01, 9.9163e-01, 3.9882e-01,
        1.2576e-02, 2.4863e+00, 9.6537e-04, 4.0774e-01, 1.4226e-03, 4.7297e-01,
        1.8917e+00, 2.7889e-04, 1.0727e-03, 1.6660e-01, 2.5775e-02, 7.3586e-01,
        2.0225e-05, 2.8478e-01, 3.0210e-05, 5.0179e-03, 4.1537e-01, 3.3073e+00,
        6.4247e-03, 1.0215e-01, 5.4471e-01, 2.8600e+00, 1.4799e-02, 7.6189e-02,
        1.1291e-04, 2.7493e-06, 1.8951e+00, 2.9533e-01, 1.6129e-03, 1.3576e-02,
        1.3509e-04, 4.1015e-04, 3.3166e-04, 3.6955e-01, 1.2683e-02, 2.6754e-04,
        5.8443e-05, 1.7049e-01, 8.6772e-03, 6.4339e-04, 5.4422e-01, 3.6555e+00,
        7.7818e-02, 5.2945e-01, 3.5633e-06, 1.8166e+00, 6.1762e-01, 2.6600e-02,
        3.1079e-01, 1.1624e-03, 1.0238e-03, 1.9928e-01, 3.3875e-02, 3.0441e-01,
        3.1567e+00, 3.1989e-02, 8.8285e-01, 4.0433e-01, 1.0807e+00, 3.1221e-01,
        3.2650e-04, 2.1933e+00, 4.3355e-01, 6.3695e-01, 3.6777e+00, 8.6465e-03,
        1.2914e+00, 2.6285e+00, 2.5748e-01, 3.4926e+00, 3.6989e-03, 2.1092e+00,
        6.1872e-02, 2.9617e+00, 9.2254e-04, 1.6970e+00, 6.5266e-03, 1.3991e+00,
        1.2714e-03, 3.5802e+00, 7.3381e-04, 2.4163e+00, 6.7926e-03, 3.2279e+00,
        7.7510e-05, 2.6865e+00, 2.1848e-05, 2.5887e-03, 4.1733e+00, 4.0720e-04,
        2.0332e+00, 4.8394e+00, 6.6337e-01, 1.4476e+00, 9.6138e-02, 3.3625e+00,
        3.1320e-03, 3.6935e+00, 4.8895e-03, 3.2215e+00, 1.0506e-05, 3.3761e-02,
        1.4112e+00, 2.0550e-04, 1.8135e-03, 2.3359e-01, 5.0131e-01, 5.3277e-01,
        3.5966e-04, 5.9613e-02, 3.9671e-02, 8.6541e-01, 1.2171e+00, 2.4667e+00,
        3.3631e-02, 5.9959e-01, 8.6886e-05, 4.1955e+00, 1.4740e+00, 5.3567e-03,
        8.2006e-04, 6.5053e-01, 1.3147e-01, 4.9020e-01, 9.7210e-02, 1.9459e-01,
        1.7728e-05, 8.1884e-01, 2.5473e+00, 4.5481e-04, 1.8587e+00, 2.0510e-01,
        4.1639e+00, 6.1535e-06, 3.1433e-01, 2.7699e-03, 3.9541e-03, 1.9119e+00,
        2.6188e-05, 1.8901e-05, 4.0334e+00, 3.0616e-03, 2.9413e+00, 3.5097e+00,
        7.1933e-04, 6.8139e-03, 2.3969e-03, 1.1717e-04, 8.0446e-02, 1.2408e-02,
        7.7467e-02, 1.4415e-01, 3.6312e+00, 1.3414e-01, 3.9074e-02, 1.1562e+00,
        5.4600e-01, 7.0718e-01, 3.6764e+00, 5.6616e-04, 1.7761e-01, 2.4767e+00,
        6.7481e-01, 6.1731e-02, 5.9833e-06, 6.9819e-03, 1.5240e-01, 1.0172e-02,
        1.0088e-01, 1.0871e-01, 2.9291e-05, 1.0980e-04, 6.5168e-03, 4.8909e-03,
        7.0671e-01, 1.2890e-02, 7.2502e-05, 3.1740e+00, 3.7120e-04, 8.2425e-01,
        6.1476e-04, 3.2859e+00, 5.0156e-02, 2.7105e-02, 1.3225e-04, 1.4047e+00,
        2.0526e-02, 2.5657e+00, 7.6025e-03, 3.0366e-01, 2.8091e+00, 2.0097e-02,
        2.1374e+00, 5.1791e-04, 4.6784e-01, 2.4061e+00, 2.1129e-05, 2.6969e+00,
        2.4929e+00, 1.0762e-03, 2.0922e-02, 3.9729e-02, 6.5532e-03, 3.8596e+00,
        8.8671e-01, 6.2028e-03, 1.5704e+00, 4.2404e+00, 2.6228e+00, 1.0838e-05],
       device='cuda:0', grad_fn=<NegBackward0>)
Processing test sample 5/5 (after training)
torch.Size([249, 30522])
tensor([[ -9.9531, -10.7109, -10.4062,  ..., -10.8750, -10.4609,  -7.3945],
        [-10.7891, -11.5312, -11.2031,  ..., -11.5938,  -9.3828,  -7.8281],
        [ -4.1328,  -4.9023,  -5.0078,  ...,  -5.9570,  -4.0156,  -8.8125],
        ...,
        [-10.6172, -11.0000, -10.7891,  ..., -10.5156,  -8.6484,  -7.0977],
        [ -8.7891,  -8.8281,  -8.9219,  ...,  -8.2031,  -7.6250,  -6.7734],
        [-15.8438, -15.5234, -16.0781,  ..., -14.5469, -14.4844, -10.1484]],
       device='cuda:0', grad_fn=<UnbindBackward0>)
torch.Size([249])
tensor([4.4659e-01, 1.4205e-01, 5.8736e+00, 3.3761e-05, 2.4143e-03, 2.7785e-01,
        3.8840e-02, 7.8002e-01, 5.8151e-04, 1.7427e+00, 5.6246e-04, 2.3838e+00,
        1.9892e-04, 3.6115e-01, 6.6116e-04, 1.2814e-01, 3.2943e-02, 4.1167e-01,
        1.4277e-04, 1.7783e+00, 3.7362e-03, 2.9443e-02, 2.0889e-03, 5.7264e-01,
        2.1448e+00, 9.0414e-06, 1.2319e-02, 7.6174e-01, 3.2858e-03, 3.7229e-01,
        7.6664e-01, 2.2125e-03, 1.2519e-05, 2.4612e-01, 1.1577e-04, 1.4687e-04,
        1.8969e-03, 5.3118e-06, 1.3946e+00, 8.0302e-02, 3.2574e-03, 2.1868e-05,
        8.0916e-01, 1.9872e-02, 1.0056e-04, 4.7406e-02, 2.9497e-04, 5.8547e-06,
        1.3939e+00, 6.4315e-03, 1.1094e-03, 2.5642e-01, 1.6160e-04, 1.2155e-01,
        6.1212e-04, 8.1925e-02, 5.1187e-04, 1.6976e-04, 7.7192e-02, 2.9850e+00,
        4.6794e-03, 5.8399e-03, 1.6663e+00, 4.9870e-01, 5.5907e-04, 3.7129e-01,
        1.1872e-05, 1.2963e-01, 2.0327e+00, 1.2501e-04, 5.0276e-05, 3.1476e+00,
        6.9265e-04, 4.7073e-01, 1.0640e-04, 3.4164e-04, 8.2610e-01, 2.3921e-04,
        1.7425e-01, 1.2328e-05, 8.1724e-02, 6.0145e+00, 2.1910e-04, 7.1554e-01,
        1.0825e+00, 7.3597e-04, 3.6901e-05, 1.9565e+00, 4.6080e-04, 1.5137e+00,
        7.3682e-04, 8.3965e-05, 1.2133e+00, 3.5424e-04, 1.0245e-01, 2.1591e+00,
        4.2292e-03, 9.7949e-06, 3.0996e+00, 2.1781e-02, 1.7659e-04, 7.3015e-03,
        3.6847e-05, 1.2152e+00, 4.8900e-01, 3.7599e-02, 1.4496e-02, 2.0589e-04,
        1.1872e+00, 1.3211e-02, 1.1893e-03, 1.7241e-01, 1.9748e-03, 4.1126e-05,
        4.1091e+00, 1.4134e-03, 7.0824e-05, 1.1947e+00, 1.4831e-04, 2.2048e-02,
        1.2123e-02, 4.9947e-05, 6.1417e-03, 6.6769e-03, 3.9335e-02, 1.2680e-04,
        2.1671e-03, 2.1392e-04, 1.3425e-01, 1.1111e-04, 1.4779e-02, 2.3306e-03,
        2.6039e-04, 1.5648e+00, 1.4154e+00, 2.1809e+00, 5.6503e-01, 3.0468e-03,
        4.7701e-04, 1.3503e+00, 5.6851e-02, 1.1927e-04, 4.0050e-02, 1.8857e-04,
        6.1758e-03, 3.9302e-01, 1.2214e-01, 1.7816e-02, 2.6226e-03, 5.6309e-04,
        9.2291e-04, 2.2312e-02, 3.7951e-03, 3.1273e-01, 2.3376e-05, 3.2053e-01,
        3.5010e-01, 2.6695e-01, 1.5072e-04, 4.0395e-02, 8.6027e-05, 9.0174e-04,
        1.9370e-01, 2.4551e-04, 5.1591e-02, 4.4586e+00, 8.1010e-03, 6.8010e-04,
        1.7004e-01, 2.7256e-02, 8.4148e-01, 8.5401e-02, 2.7971e+00, 2.0751e-04,
        4.1988e-01, 1.6119e-01, 1.6388e-01, 9.7228e-04, 3.1325e-01, 1.1573e+00,
        1.2475e-05, 7.5107e-01, 7.0465e-01, 2.6208e+00, 3.9198e-02, 1.4368e-01,
        4.1821e-02, 1.5854e-04, 7.5495e-01, 1.7330e+00, 3.2288e-03, 1.0741e-03,
        8.9455e-01, 5.3083e-03, 1.5352e-05, 1.9714e+00, 2.0197e-03, 1.2013e-02,
        1.2807e-01, 7.3601e-04, 1.1084e-02, 1.4275e-03, 4.4544e-01, 8.4108e-02,
        1.5118e-01, 2.8908e-03, 2.5853e+00, 1.4943e-01, 4.1188e-05, 3.9342e-04,
        3.4458e+00, 1.0576e+00, 5.3359e-04, 9.4868e-04, 1.5698e-01, 1.7495e+00,
        7.8735e-06, 1.6600e+00, 2.0251e-01, 9.9339e-01, 9.5471e-01, 7.2934e-04,
        9.2859e-01, 1.8928e-03, 3.3928e-05, 1.5048e+00, 7.4472e-03, 5.5474e-01,
        3.0600e-01, 1.9612e+00, 1.0345e-01, 4.4364e-02, 6.3276e-03, 1.7681e+00,
        1.3130e-01, 1.1017e-03, 1.8334e+00, 4.3127e-01, 2.9407e-04, 1.9394e+00,
        4.8861e+00, 2.2475e-03, 4.5533e+00, 8.8367e-06, 3.5075e+00, 1.2475e-02,
        1.3291e-04, 4.8984e+00, 8.8652e-04], device='cuda:0',
       grad_fn=<NegBackward0>)

Processing complete. Saved 5 results. Failed: 0
[main 6768201] BERT Script Results for Run 59930 (Model: bert, Dataset: scienceqa, Epochs: 10, Commit: 784b449)
 3 files changed, 547 insertions(+)
 create mode 100644 data/full/bert_results_59930_ds-scienceqa.pkl
 create mode 100644 slurm-outputs/slurm.59930.abakus11.out
To github.com:ngruenefeld/gradient-uncertainty.git
   784b449..6768201  main -> main
