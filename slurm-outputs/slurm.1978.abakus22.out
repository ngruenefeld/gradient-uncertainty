slurmstepd-abakus22: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus22: error: Setting TMPDIR to /tmp
Running job with commit: afa949d1752c9a9684311103ff45a1fa47e515ce
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 1978
Dataset: commoncorpus
Model: polylm-1.7b
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Sample size: 10
Mode: test
Quantization bits: 4
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: rephrase
Number of perturbations: 3
Using slow tokenizer implementation for polylm-1.7b
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
Repo card metadata block was not found. Setting CardData to empty.
slurmstepd-abakus22: error: *** JOB 1978 ON abakus22 CANCELLED AT 2025-05-04T14:13:07 ***
