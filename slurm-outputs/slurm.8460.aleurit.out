slurmstepd-aleurit: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-aleurit: error: Setting TMPDIR to /tmp
Running job with commit: 9ba87ae36a123b8b704dd2c7ba5421e6827e2ba4
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 8460
Dataset: truthful
Model: llama-3.1-8b
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Sample size: 0
Mode: full
Streaming dataset: False
Quantization bits: 4
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: rephrase
Number of perturbations: 10
Divergence: low
Skip evaluation: True
Loading model in 4-bit precision to reduce memory usage
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:44<02:14, 44.68s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:29<01:29, 44.69s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:13<00:44, 44.35s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:23<00:00, 30.98s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:23<00:00, 35.95s/it]
Processing sample 1/817 (dataset index: 0)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 879.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 266.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 1 (dataset index 0): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 879.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 266.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 2/817 (dataset index: 1)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 2 (dataset index 1): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 3/817 (dataset index: 2)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 3 (dataset index 2): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 4/817 (dataset index: 3)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 4 (dataset index 3): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 5/817 (dataset index: 4)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 5 (dataset index 4): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 6/817 (dataset index: 5)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 6 (dataset index 5): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 7/817 (dataset index: 6)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 931.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 239.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 7 (dataset index 6): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 931.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 239.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 8/817 (dataset index: 7)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 8 (dataset index 7): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 9/817 (dataset index: 8)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 9 (dataset index 8): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 10/817 (dataset index: 9)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 10 (dataset index 9): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 11/817 (dataset index: 10)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 941.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 225.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 11 (dataset index 10): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 941.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 225.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 12/817 (dataset index: 11)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 881.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 283.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 12 (dataset index 11): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 881.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 283.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 13/817 (dataset index: 12)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 13 (dataset index 12): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 14/817 (dataset index: 13)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 14 (dataset index 13): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 15/817 (dataset index: 14)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 15 (dataset index 14): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 16/817 (dataset index: 15)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 16 (dataset index 15): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 17/817 (dataset index: 16)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 17 (dataset index 16): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 18/817 (dataset index: 17)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 18 (dataset index 17): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 19/817 (dataset index: 18)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 19 (dataset index 18): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 20/817 (dataset index: 19)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 20 (dataset index 19): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 21/817 (dataset index: 20)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 21 (dataset index 20): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 22/817 (dataset index: 21)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 805.88 MiB is free. Including non-PyTorch memory, this process has 6.80 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 334.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 22 (dataset index 21): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 805.88 MiB is free. Including non-PyTorch memory, this process has 6.80 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 334.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 23/817 (dataset index: 22)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 23 (dataset index 22): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 24/817 (dataset index: 23)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 24 (dataset index 23): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 25/817 (dataset index: 24)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 25 (dataset index 24): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 26/817 (dataset index: 25)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 26 (dataset index 25): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 27/817 (dataset index: 26)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 27 (dataset index 26): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 28/817 (dataset index: 27)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 28 (dataset index 27): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 29/817 (dataset index: 28)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 29 (dataset index 28): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 30/817 (dataset index: 29)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 30 (dataset index 29): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 31/817 (dataset index: 30)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 31 (dataset index 30): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 32/817 (dataset index: 31)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 32 (dataset index 31): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 33/817 (dataset index: 32)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 33 (dataset index 32): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 34/817 (dataset index: 33)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 34 (dataset index 33): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 35/817 (dataset index: 34)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 35 (dataset index 34): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 36/817 (dataset index: 35)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 36 (dataset index 35): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 37/817 (dataset index: 36)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 37 (dataset index 36): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 38/817 (dataset index: 37)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 38 (dataset index 37): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 39/817 (dataset index: 38)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 39 (dataset index 38): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 40/817 (dataset index: 39)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 40 (dataset index 39): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 41/817 (dataset index: 40)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 41 (dataset index 40): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 42/817 (dataset index: 41)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 42 (dataset index 41): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 43/817 (dataset index: 42)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 43 (dataset index 42): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 44/817 (dataset index: 43)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 44 (dataset index 43): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 45/817 (dataset index: 44)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 45 (dataset index 44): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 46/817 (dataset index: 45)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 46 (dataset index 45): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 47/817 (dataset index: 46)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 47 (dataset index 46): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 48/817 (dataset index: 47)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 48 (dataset index 47): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 49/817 (dataset index: 48)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 49 (dataset index 48): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 50/817 (dataset index: 49)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 50 (dataset index 49): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 51/817 (dataset index: 50)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 51 (dataset index 50): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 52/817 (dataset index: 51)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 52 (dataset index 51): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 53/817 (dataset index: 52)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 53 (dataset index 52): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 54/817 (dataset index: 53)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 54 (dataset index 53): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 55/817 (dataset index: 54)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 55 (dataset index 54): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 56/817 (dataset index: 55)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 56 (dataset index 55): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 57/817 (dataset index: 56)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 57 (dataset index 56): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 58/817 (dataset index: 57)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 58 (dataset index 57): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 59/817 (dataset index: 58)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 59 (dataset index 58): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 60/817 (dataset index: 59)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 60 (dataset index 59): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 61/817 (dataset index: 60)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 61 (dataset index 60): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 62/817 (dataset index: 61)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 62 (dataset index 61): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 63/817 (dataset index: 62)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 63 (dataset index 62): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 64/817 (dataset index: 63)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 327.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 64 (dataset index 63): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 327.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 65/817 (dataset index: 64)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 65 (dataset index 64): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 66/817 (dataset index: 65)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 66 (dataset index 65): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 67/817 (dataset index: 66)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 67 (dataset index 66): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 68/817 (dataset index: 67)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 68 (dataset index 67): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 69/817 (dataset index: 68)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 69 (dataset index 68): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 70/817 (dataset index: 69)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 70 (dataset index 69): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 71/817 (dataset index: 70)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 71 (dataset index 70): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 72/817 (dataset index: 71)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 72 (dataset index 71): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 73/817 (dataset index: 72)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 73 (dataset index 72): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 74/817 (dataset index: 73)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 74 (dataset index 73): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 75/817 (dataset index: 74)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 75 (dataset index 74): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 76/817 (dataset index: 75)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 76 (dataset index 75): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 77/817 (dataset index: 76)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 77 (dataset index 76): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 78/817 (dataset index: 77)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 78 (dataset index 77): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 79/817 (dataset index: 78)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 79 (dataset index 78): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 80/817 (dataset index: 79)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 324.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 80 (dataset index 79): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 324.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 81/817 (dataset index: 80)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 81 (dataset index 80): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 82/817 (dataset index: 81)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 82 (dataset index 81): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 83/817 (dataset index: 82)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 83 (dataset index 82): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 84/817 (dataset index: 83)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 84 (dataset index 83): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 85/817 (dataset index: 84)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 85 (dataset index 84): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 86/817 (dataset index: 85)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 86 (dataset index 85): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 87/817 (dataset index: 86)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 87 (dataset index 86): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 88/817 (dataset index: 87)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 88 (dataset index 87): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 89/817 (dataset index: 88)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 89 (dataset index 88): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 90/817 (dataset index: 89)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 90 (dataset index 89): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 91/817 (dataset index: 90)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 91 (dataset index 90): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 92/817 (dataset index: 91)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 92 (dataset index 91): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 93/817 (dataset index: 92)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 899.88 MiB is free. Including non-PyTorch memory, this process has 6.71 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 277.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 93 (dataset index 92): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 899.88 MiB is free. Including non-PyTorch memory, this process has 6.71 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 277.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 94/817 (dataset index: 93)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 324.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 94 (dataset index 93): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 324.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 95/817 (dataset index: 94)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 95 (dataset index 94): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 96/817 (dataset index: 95)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 96 (dataset index 95): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 97/817 (dataset index: 96)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 97 (dataset index 96): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 98/817 (dataset index: 97)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 98 (dataset index 97): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 99/817 (dataset index: 98)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 99 (dataset index 98): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 100/817 (dataset index: 99)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 100 (dataset index 99): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 101/817 (dataset index: 100)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 101 (dataset index 100): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 102/817 (dataset index: 101)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 929.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 249.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 102 (dataset index 101): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 929.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 249.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 103/817 (dataset index: 102)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 103 (dataset index 102): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 104/817 (dataset index: 103)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 104 (dataset index 103): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 105/817 (dataset index: 104)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 381.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 105 (dataset index 104): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 381.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 106/817 (dataset index: 105)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 106 (dataset index 105): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 107/817 (dataset index: 106)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 107 (dataset index 106): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 108/817 (dataset index: 107)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 108 (dataset index 107): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 109/817 (dataset index: 108)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 905.88 MiB is free. Including non-PyTorch memory, this process has 6.70 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 269.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 109 (dataset index 108): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 905.88 MiB is free. Including non-PyTorch memory, this process has 6.70 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 269.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 110/817 (dataset index: 109)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 110 (dataset index 109): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 111/817 (dataset index: 110)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 111 (dataset index 110): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 112/817 (dataset index: 111)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 112 (dataset index 111): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 113/817 (dataset index: 112)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 113 (dataset index 112): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 114/817 (dataset index: 113)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 114 (dataset index 113): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 115/817 (dataset index: 114)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 115 (dataset index 114): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 116/817 (dataset index: 115)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 116 (dataset index 115): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 117/817 (dataset index: 116)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 117 (dataset index 116): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 118/817 (dataset index: 117)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 118 (dataset index 117): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 119/817 (dataset index: 118)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 119 (dataset index 118): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 120/817 (dataset index: 119)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 120 (dataset index 119): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 121/817 (dataset index: 120)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 919.88 MiB is free. Including non-PyTorch memory, this process has 6.69 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 258.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 121 (dataset index 120): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 919.88 MiB is free. Including non-PyTorch memory, this process has 6.69 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 258.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 122/817 (dataset index: 121)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 122 (dataset index 121): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 123/817 (dataset index: 122)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 123 (dataset index 122): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 124/817 (dataset index: 123)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 124 (dataset index 123): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 125/817 (dataset index: 124)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 125 (dataset index 124): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 126/817 (dataset index: 125)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 126 (dataset index 125): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 127/817 (dataset index: 126)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 127 (dataset index 126): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 128/817 (dataset index: 127)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 128 (dataset index 127): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 129/817 (dataset index: 128)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 129 (dataset index 128): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 130/817 (dataset index: 129)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 130 (dataset index 129): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 131/817 (dataset index: 130)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 939.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 231.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 131 (dataset index 130): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 939.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 231.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 132/817 (dataset index: 131)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 132 (dataset index 131): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 133/817 (dataset index: 132)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 133 (dataset index 132): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 134/817 (dataset index: 133)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 335.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 134 (dataset index 133): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 335.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 135/817 (dataset index: 134)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 135 (dataset index 134): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 136/817 (dataset index: 135)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 308.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 136 (dataset index 135): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 308.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 137/817 (dataset index: 136)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 137 (dataset index 136): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 138/817 (dataset index: 137)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 138 (dataset index 137): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 139/817 (dataset index: 138)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 139 (dataset index 138): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 140/817 (dataset index: 139)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 140 (dataset index 139): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 141/817 (dataset index: 140)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 141 (dataset index 140): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 142/817 (dataset index: 141)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 142 (dataset index 141): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 143/817 (dataset index: 142)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 143 (dataset index 142): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 144/817 (dataset index: 143)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 144 (dataset index 143): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 145/817 (dataset index: 144)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 891.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 278.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 145 (dataset index 144): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 891.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 278.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 146/817 (dataset index: 145)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 937.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 236.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 146 (dataset index 145): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 937.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 236.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 147/817 (dataset index: 146)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 147 (dataset index 146): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 148/817 (dataset index: 147)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 148 (dataset index 147): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 149/817 (dataset index: 148)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 149 (dataset index 148): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 150/817 (dataset index: 149)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 150 (dataset index 149): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 151/817 (dataset index: 150)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 151 (dataset index 150): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 152/817 (dataset index: 151)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 152 (dataset index 151): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 153/817 (dataset index: 152)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 153 (dataset index 152): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 154/817 (dataset index: 153)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 154 (dataset index 153): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 155/817 (dataset index: 154)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 155 (dataset index 154): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 156/817 (dataset index: 155)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 156 (dataset index 155): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 157/817 (dataset index: 156)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 157 (dataset index 156): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 158/817 (dataset index: 157)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 158 (dataset index 157): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 159/817 (dataset index: 158)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 159 (dataset index 158): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 160/817 (dataset index: 159)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 160 (dataset index 159): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 161/817 (dataset index: 160)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 161 (dataset index 160): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 162/817 (dataset index: 161)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 162 (dataset index 161): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 163/817 (dataset index: 162)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 163 (dataset index 162): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 164/817 (dataset index: 163)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 164 (dataset index 163): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 165/817 (dataset index: 164)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 165 (dataset index 164): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 166/817 (dataset index: 165)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 166 (dataset index 165): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 167/817 (dataset index: 166)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 167 (dataset index 166): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 168/817 (dataset index: 167)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 168 (dataset index 167): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 169/817 (dataset index: 168)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 169 (dataset index 168): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 170/817 (dataset index: 169)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 170 (dataset index 169): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 171/817 (dataset index: 170)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 171 (dataset index 170): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 172/817 (dataset index: 171)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 172 (dataset index 171): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 173/817 (dataset index: 172)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 173 (dataset index 172): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 174/817 (dataset index: 173)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 174 (dataset index 173): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 175/817 (dataset index: 174)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 963.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 208.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 175 (dataset index 174): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 963.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 208.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 176/817 (dataset index: 175)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 947.88 MiB is free. Including non-PyTorch memory, this process has 6.66 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 224.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 176 (dataset index 175): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 947.88 MiB is free. Including non-PyTorch memory, this process has 6.66 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 224.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 177/817 (dataset index: 176)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 177 (dataset index 176): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 178/817 (dataset index: 177)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 939.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 233.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 178 (dataset index 177): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 939.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 233.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 179/817 (dataset index: 178)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 179 (dataset index 178): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 180/817 (dataset index: 179)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 180 (dataset index 179): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 181/817 (dataset index: 180)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 181 (dataset index 180): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 182/817 (dataset index: 181)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 182 (dataset index 181): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 183/817 (dataset index: 182)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 183 (dataset index 182): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 184/817 (dataset index: 183)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 184 (dataset index 183): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 185/817 (dataset index: 184)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 185 (dataset index 184): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 186/817 (dataset index: 185)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 186 (dataset index 185): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 187/817 (dataset index: 186)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 187 (dataset index 186): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 188/817 (dataset index: 187)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 188 (dataset index 187): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 189/817 (dataset index: 188)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 189 (dataset index 188): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 190/817 (dataset index: 189)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 190 (dataset index 189): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 191/817 (dataset index: 190)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 191 (dataset index 190): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 192/817 (dataset index: 191)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 192 (dataset index 191): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 193/817 (dataset index: 192)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 193 (dataset index 192): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 194/817 (dataset index: 193)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 194 (dataset index 193): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 195/817 (dataset index: 194)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 195 (dataset index 194): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 196/817 (dataset index: 195)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 196 (dataset index 195): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 197/817 (dataset index: 196)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 197 (dataset index 196): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 198/817 (dataset index: 197)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 198 (dataset index 197): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 199/817 (dataset index: 198)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 199 (dataset index 198): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 200/817 (dataset index: 199)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 385.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 200 (dataset index 199): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 385.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 201/817 (dataset index: 200)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 201 (dataset index 200): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 202/817 (dataset index: 201)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 326.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 202 (dataset index 201): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 326.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 203/817 (dataset index: 202)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 203 (dataset index 202): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 204/817 (dataset index: 203)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 204 (dataset index 203): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 205/817 (dataset index: 204)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 205 (dataset index 204): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 206/817 (dataset index: 205)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 206 (dataset index 205): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 207/817 (dataset index: 206)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 207 (dataset index 206): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 208/817 (dataset index: 207)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 315.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 208 (dataset index 207): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 315.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 209/817 (dataset index: 208)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 209 (dataset index 208): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 210/817 (dataset index: 209)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 210 (dataset index 209): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 211/817 (dataset index: 210)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 211 (dataset index 210): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 212/817 (dataset index: 211)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 212 (dataset index 211): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 213/817 (dataset index: 212)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 213 (dataset index 212): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 214/817 (dataset index: 213)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 214 (dataset index 213): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 215/817 (dataset index: 214)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 215 (dataset index 214): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 216/817 (dataset index: 215)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 216 (dataset index 215): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 217/817 (dataset index: 216)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 217 (dataset index 216): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 218/817 (dataset index: 217)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 218 (dataset index 217): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 219/817 (dataset index: 218)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 219 (dataset index 218): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 220/817 (dataset index: 219)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 220 (dataset index 219): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 221/817 (dataset index: 220)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 221 (dataset index 220): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 222/817 (dataset index: 221)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 222 (dataset index 221): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 223/817 (dataset index: 222)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 223 (dataset index 222): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 224/817 (dataset index: 223)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 224 (dataset index 223): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 225/817 (dataset index: 224)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 225 (dataset index 224): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 226/817 (dataset index: 225)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 313.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 226 (dataset index 225): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 313.84 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 227/817 (dataset index: 226)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 227 (dataset index 226): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 228/817 (dataset index: 227)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 228 (dataset index 227): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 229/817 (dataset index: 228)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 929.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 247.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 229 (dataset index 228): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 929.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 247.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 230/817 (dataset index: 229)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 230 (dataset index 229): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 231/817 (dataset index: 230)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 231 (dataset index 230): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 232/817 (dataset index: 231)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 232 (dataset index 231): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 233/817 (dataset index: 232)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 233 (dataset index 232): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 234/817 (dataset index: 233)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 773.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 371.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 234 (dataset index 233): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 773.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 371.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 235/817 (dataset index: 234)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 957.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 213.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 235 (dataset index 234): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 957.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 213.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 236/817 (dataset index: 235)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 236 (dataset index 235): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 237/817 (dataset index: 236)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 237 (dataset index 236): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 238/817 (dataset index: 237)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 238 (dataset index 237): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 239/817 (dataset index: 238)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 239 (dataset index 238): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 240/817 (dataset index: 239)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 240 (dataset index 239): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 241/817 (dataset index: 240)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 241 (dataset index 240): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 242/817 (dataset index: 241)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 242 (dataset index 241): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 243/817 (dataset index: 242)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 243 (dataset index 242): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 244/817 (dataset index: 243)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 244 (dataset index 243): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 245/817 (dataset index: 244)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 245 (dataset index 244): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 246/817 (dataset index: 245)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 246 (dataset index 245): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 247/817 (dataset index: 246)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 247 (dataset index 246): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 248/817 (dataset index: 247)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 248 (dataset index 247): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 249/817 (dataset index: 248)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 249 (dataset index 248): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 250/817 (dataset index: 249)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 250 (dataset index 249): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 251/817 (dataset index: 250)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 251 (dataset index 250): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 252/817 (dataset index: 251)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 252 (dataset index 251): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 253/817 (dataset index: 252)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 835.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 309.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 253 (dataset index 252): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 835.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 309.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 254/817 (dataset index: 253)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 254 (dataset index 253): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 255/817 (dataset index: 254)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 255 (dataset index 254): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 256/817 (dataset index: 255)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 303.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 256 (dataset index 255): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 303.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 257/817 (dataset index: 256)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 257 (dataset index 256): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 258/817 (dataset index: 257)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 258 (dataset index 257): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 259/817 (dataset index: 258)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 259 (dataset index 258): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 260/817 (dataset index: 259)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 260 (dataset index 259): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 261/817 (dataset index: 260)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 261 (dataset index 260): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 262/817 (dataset index: 261)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 262 (dataset index 261): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 263/817 (dataset index: 262)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 263 (dataset index 262): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 382.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 264/817 (dataset index: 263)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 264 (dataset index 263): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 265/817 (dataset index: 264)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 265 (dataset index 264): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 266/817 (dataset index: 265)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 266 (dataset index 265): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 267/817 (dataset index: 266)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 267 (dataset index 266): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 268/817 (dataset index: 267)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 268 (dataset index 267): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 269/817 (dataset index: 268)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 269 (dataset index 268): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 270/817 (dataset index: 269)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 334.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 270 (dataset index 269): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 334.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 271/817 (dataset index: 270)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 941.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 229.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 271 (dataset index 270): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 941.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 229.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 272/817 (dataset index: 271)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 272 (dataset index 271): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 273/817 (dataset index: 272)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 273 (dataset index 272): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 274/817 (dataset index: 273)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 274 (dataset index 273): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 275/817 (dataset index: 274)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 275 (dataset index 274): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 276/817 (dataset index: 275)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 307.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 276 (dataset index 275): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 307.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 277/817 (dataset index: 276)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 277 (dataset index 276): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 278/817 (dataset index: 277)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 278 (dataset index 277): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 279/817 (dataset index: 278)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 813.88 MiB is free. Including non-PyTorch memory, this process has 6.79 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 326.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 279 (dataset index 278): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 813.88 MiB is free. Including non-PyTorch memory, this process has 6.79 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 326.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 280/817 (dataset index: 279)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 280 (dataset index 279): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 281/817 (dataset index: 280)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 281 (dataset index 280): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 282/817 (dataset index: 281)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 282 (dataset index 281): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 283/817 (dataset index: 282)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 283 (dataset index 282): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 284/817 (dataset index: 283)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 284 (dataset index 283): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 285/817 (dataset index: 284)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 285 (dataset index 284): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 286/817 (dataset index: 285)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 286 (dataset index 285): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 287/817 (dataset index: 286)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 287 (dataset index 286): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 288/817 (dataset index: 287)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 288 (dataset index 287): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 289/817 (dataset index: 288)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 289 (dataset index 288): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 290/817 (dataset index: 289)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 290 (dataset index 289): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 291/817 (dataset index: 290)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 291 (dataset index 290): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 292/817 (dataset index: 291)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 292 (dataset index 291): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 293/817 (dataset index: 292)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 293 (dataset index 292): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 294/817 (dataset index: 293)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 294 (dataset index 293): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 295/817 (dataset index: 294)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 295 (dataset index 294): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 296/817 (dataset index: 295)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 296 (dataset index 295): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 297/817 (dataset index: 296)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 297 (dataset index 296): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 298/817 (dataset index: 297)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 298 (dataset index 297): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 299/817 (dataset index: 298)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 829.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 310.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 299 (dataset index 298): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 829.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 310.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 300/817 (dataset index: 299)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 837.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 315.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 300 (dataset index 299): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 837.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 315.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 301/817 (dataset index: 300)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 301 (dataset index 300): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 302/817 (dataset index: 301)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 775.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 369.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 302 (dataset index 301): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 775.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 369.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 303/817 (dataset index: 302)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 210.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 303 (dataset index 302): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 210.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 304/817 (dataset index: 303)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 841.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 315.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 304 (dataset index 303): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 841.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 315.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 305/817 (dataset index: 304)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 305 (dataset index 304): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 306/817 (dataset index: 305)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 306 (dataset index 305): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 307/817 (dataset index: 306)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 307 (dataset index 306): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 308/817 (dataset index: 307)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 308 (dataset index 307): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 309/817 (dataset index: 308)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 309 (dataset index 308): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 310/817 (dataset index: 309)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 310 (dataset index 309): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 311/817 (dataset index: 310)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 311 (dataset index 310): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 312/817 (dataset index: 311)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 312 (dataset index 311): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 313/817 (dataset index: 312)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 313 (dataset index 312): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 314/817 (dataset index: 313)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 314 (dataset index 313): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 315/817 (dataset index: 314)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 315 (dataset index 314): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 316/817 (dataset index: 315)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 316 (dataset index 315): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 317/817 (dataset index: 316)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 374.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 317 (dataset index 316): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 374.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 318/817 (dataset index: 317)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 318 (dataset index 317): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 319/817 (dataset index: 318)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 319 (dataset index 318): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 320/817 (dataset index: 319)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 320 (dataset index 319): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 321/817 (dataset index: 320)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 321 (dataset index 320): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 322/817 (dataset index: 321)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 322 (dataset index 321): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 323/817 (dataset index: 322)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 323 (dataset index 322): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 324/817 (dataset index: 323)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 829.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 326.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 324 (dataset index 323): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 829.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 326.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 325/817 (dataset index: 324)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 325 (dataset index 324): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 326/817 (dataset index: 325)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 326 (dataset index 325): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 327/817 (dataset index: 326)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 337.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 327 (dataset index 326): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 337.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 328/817 (dataset index: 327)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 328 (dataset index 327): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 329/817 (dataset index: 328)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 329 (dataset index 328): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 330/817 (dataset index: 329)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 336.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 330 (dataset index 329): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 336.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 331/817 (dataset index: 330)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 331 (dataset index 330): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 332/817 (dataset index: 331)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 332 (dataset index 331): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 333/817 (dataset index: 332)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 333 (dataset index 332): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 334/817 (dataset index: 333)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 334 (dataset index 333): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 335/817 (dataset index: 334)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 335 (dataset index 334): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 336/817 (dataset index: 335)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 336 (dataset index 335): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 337/817 (dataset index: 336)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 337 (dataset index 336): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 338/817 (dataset index: 337)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 208.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 338 (dataset index 337): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 208.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 339/817 (dataset index: 338)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 339 (dataset index 338): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 340/817 (dataset index: 339)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 340 (dataset index 339): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 341/817 (dataset index: 340)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 341 (dataset index 340): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 342/817 (dataset index: 341)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 342 (dataset index 341): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 343/817 (dataset index: 342)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 343 (dataset index 342): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 344/817 (dataset index: 343)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 344 (dataset index 343): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 345/817 (dataset index: 344)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 345 (dataset index 344): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 346/817 (dataset index: 345)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 346 (dataset index 345): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 347/817 (dataset index: 346)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 347 (dataset index 346): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 348/817 (dataset index: 347)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 348 (dataset index 347): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 349/817 (dataset index: 348)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 349 (dataset index 348): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 350/817 (dataset index: 349)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 350 (dataset index 349): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 351/817 (dataset index: 350)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 351 (dataset index 350): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 352/817 (dataset index: 351)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 352 (dataset index 351): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 353/817 (dataset index: 352)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 353 (dataset index 352): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 354/817 (dataset index: 353)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 354 (dataset index 353): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 355/817 (dataset index: 354)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 355 (dataset index 354): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 356/817 (dataset index: 355)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 356 (dataset index 355): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 357/817 (dataset index: 356)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 357 (dataset index 356): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 358/817 (dataset index: 357)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 358 (dataset index 357): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 359/817 (dataset index: 358)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 359 (dataset index 358): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 360/817 (dataset index: 359)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 773.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 371.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 360 (dataset index 359): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 773.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 371.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 361/817 (dataset index: 360)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 361 (dataset index 360): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 362/817 (dataset index: 361)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 362 (dataset index 361): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 363/817 (dataset index: 362)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 363 (dataset index 362): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 364/817 (dataset index: 363)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 364 (dataset index 363): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 365/817 (dataset index: 364)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 365 (dataset index 364): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 366/817 (dataset index: 365)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 366 (dataset index 365): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 367/817 (dataset index: 366)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 367 (dataset index 366): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 368/817 (dataset index: 367)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 368 (dataset index 367): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 369/817 (dataset index: 368)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 369 (dataset index 368): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 370/817 (dataset index: 369)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 370 (dataset index 369): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 371/817 (dataset index: 370)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 374.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 371 (dataset index 370): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 374.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 372/817 (dataset index: 371)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 372 (dataset index 371): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 373/817 (dataset index: 372)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 373 (dataset index 372): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 374/817 (dataset index: 373)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 879.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 286.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 374 (dataset index 373): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 879.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 286.86 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 375/817 (dataset index: 374)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 375 (dataset index 374): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 376/817 (dataset index: 375)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 376 (dataset index 375): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 377/817 (dataset index: 376)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 377 (dataset index 376): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 378/817 (dataset index: 377)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 797.88 MiB is free. Including non-PyTorch memory, this process has 6.81 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 358.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 378 (dataset index 377): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 797.88 MiB is free. Including non-PyTorch memory, this process has 6.81 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 358.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 379/817 (dataset index: 378)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 379 (dataset index 378): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 380/817 (dataset index: 379)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 380 (dataset index 379): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 381/817 (dataset index: 380)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 381 (dataset index 380): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 382/817 (dataset index: 381)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 382 (dataset index 381): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 383/817 (dataset index: 382)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 383 (dataset index 382): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 384/817 (dataset index: 383)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 384 (dataset index 383): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 385/817 (dataset index: 384)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 385 (dataset index 384): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 386/817 (dataset index: 385)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 386 (dataset index 385): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 387/817 (dataset index: 386)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 931.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 239.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 387 (dataset index 386): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 931.88 MiB is free. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 239.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 388/817 (dataset index: 387)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 388 (dataset index 387): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 389/817 (dataset index: 388)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 389 (dataset index 388): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 390/817 (dataset index: 389)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 390 (dataset index 389): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 391/817 (dataset index: 390)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 391 (dataset index 390): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 392/817 (dataset index: 391)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 302.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 392 (dataset index 391): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 302.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 393/817 (dataset index: 392)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 393 (dataset index 392): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 394/817 (dataset index: 393)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 394 (dataset index 393): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 395/817 (dataset index: 394)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 395 (dataset index 394): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 396/817 (dataset index: 395)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 396 (dataset index 395): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 397/817 (dataset index: 396)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 397 (dataset index 396): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 398/817 (dataset index: 397)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 305.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 398 (dataset index 397): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 305.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 399/817 (dataset index: 398)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 399 (dataset index 398): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 400/817 (dataset index: 399)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 400 (dataset index 399): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 401/817 (dataset index: 400)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 401 (dataset index 400): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 402/817 (dataset index: 401)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 336.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 402 (dataset index 401): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 336.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 403/817 (dataset index: 402)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 403 (dataset index 402): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 404/817 (dataset index: 403)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 404 (dataset index 403): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 405/817 (dataset index: 404)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 405 (dataset index 404): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 406/817 (dataset index: 405)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 406 (dataset index 405): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 407/817 (dataset index: 406)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 407 (dataset index 406): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 408/817 (dataset index: 407)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 408 (dataset index 407): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 409/817 (dataset index: 408)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 409 (dataset index 408): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 410/817 (dataset index: 409)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 410 (dataset index 409): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 411/817 (dataset index: 410)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 411 (dataset index 410): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 412/817 (dataset index: 411)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 412 (dataset index 411): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 413/817 (dataset index: 412)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 413 (dataset index 412): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 414/817 (dataset index: 413)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 414 (dataset index 413): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 415/817 (dataset index: 414)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 415 (dataset index 414): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 416/817 (dataset index: 415)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 416 (dataset index 415): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 417/817 (dataset index: 416)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 417 (dataset index 416): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 418/817 (dataset index: 417)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 965.88 MiB is free. Including non-PyTorch memory, this process has 6.64 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 199.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 418 (dataset index 417): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 965.88 MiB is free. Including non-PyTorch memory, this process has 6.64 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 199.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 419/817 (dataset index: 418)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 419 (dataset index 418): empty completion produced
Processing sample 420/817 (dataset index: 419)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 420 (dataset index 419): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 421/817 (dataset index: 420)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 421 (dataset index 420): empty completion produced
Processing sample 422/817 (dataset index: 421)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 422 (dataset index 421): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 423/817 (dataset index: 422)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 375.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 423 (dataset index 422): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 375.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 424/817 (dataset index: 423)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 264.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 424 (dataset index 423): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 264.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 425/817 (dataset index: 424)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 831.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 308.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 425 (dataset index 424): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 831.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 308.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 426/817 (dataset index: 425)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 871.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 267.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 426 (dataset index 425): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 871.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 267.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 427/817 (dataset index: 426)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 427 (dataset index 426): empty completion produced
Processing sample 428/817 (dataset index: 427)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 375.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 428 (dataset index 427): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 375.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 429/817 (dataset index: 428)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 429 (dataset index 428): empty completion produced
Processing sample 430/817 (dataset index: 429)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 430 (dataset index 429): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 431/817 (dataset index: 430)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 431 (dataset index 430): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 432/817 (dataset index: 431)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 432 (dataset index 431): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 433/817 (dataset index: 432)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 325.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 433 (dataset index 432): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 325.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 434/817 (dataset index: 433)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 434 (dataset index 433): empty completion produced
Processing sample 435/817 (dataset index: 434)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 435 (dataset index 434): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 436/817 (dataset index: 435)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 436 (dataset index 435): empty completion produced
Processing sample 437/817 (dataset index: 436)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 437 (dataset index 436): empty completion produced
Processing sample 438/817 (dataset index: 437)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 374.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 438 (dataset index 437): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 374.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 439/817 (dataset index: 438)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 376.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 439 (dataset index 438): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 376.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 440/817 (dataset index: 439)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 440 (dataset index 439): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 441/817 (dataset index: 440)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 284.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 441 (dataset index 440): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 284.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 442/817 (dataset index: 441)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 442 (dataset index 441): empty completion produced
Processing sample 443/817 (dataset index: 442)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 443 (dataset index 442): empty completion produced
Processing sample 444/817 (dataset index: 443)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 444 (dataset index 443): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 445/817 (dataset index: 444)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 394.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 445 (dataset index 444): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 394.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 446/817 (dataset index: 445)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 446 (dataset index 445): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 447/817 (dataset index: 446)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 447 (dataset index 446): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 448/817 (dataset index: 447)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 448 (dataset index 447): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 449/817 (dataset index: 448)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 957.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 206.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 449 (dataset index 448): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 957.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 206.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 450/817 (dataset index: 449)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 450 (dataset index 449): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 451/817 (dataset index: 450)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 775.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 370.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 451 (dataset index 450): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 775.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 370.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 452/817 (dataset index: 451)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 452 (dataset index 451): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 453/817 (dataset index: 452)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 453 (dataset index 452): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 454/817 (dataset index: 453)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 454 (dataset index 453): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 455/817 (dataset index: 454)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 455 (dataset index 454): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 456/817 (dataset index: 455)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 456 (dataset index 455): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 457/817 (dataset index: 456)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 457 (dataset index 456): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 458/817 (dataset index: 457)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 458 (dataset index 457): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 459/817 (dataset index: 458)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 459 (dataset index 458): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 460/817 (dataset index: 459)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 307.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 460 (dataset index 459): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 307.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 461/817 (dataset index: 460)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 461 (dataset index 460): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 462/817 (dataset index: 461)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 462 (dataset index 461): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 463/817 (dataset index: 462)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 463 (dataset index 462): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 464/817 (dataset index: 463)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 299.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 464 (dataset index 463): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 299.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 465/817 (dataset index: 464)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 465 (dataset index 464): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 466/817 (dataset index: 465)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 466 (dataset index 465): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 467/817 (dataset index: 466)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 467 (dataset index 466): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 468/817 (dataset index: 467)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 468 (dataset index 467): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 469/817 (dataset index: 468)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 469 (dataset index 468): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 470/817 (dataset index: 469)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 470 (dataset index 469): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 471/817 (dataset index: 470)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 471 (dataset index 470): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 472/817 (dataset index: 471)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 472 (dataset index 471): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 473/817 (dataset index: 472)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 314.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 473 (dataset index 472): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 314.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 474/817 (dataset index: 473)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 474 (dataset index 473): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 475/817 (dataset index: 474)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 475 (dataset index 474): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 476/817 (dataset index: 475)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 476 (dataset index 475): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 477/817 (dataset index: 476)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 477 (dataset index 476): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 478/817 (dataset index: 477)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 885.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 284.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 478 (dataset index 477): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 885.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 284.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 479/817 (dataset index: 478)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 479 (dataset index 478): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 480/817 (dataset index: 479)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 480 (dataset index 479): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 481/817 (dataset index: 480)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 481 (dataset index 480): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 482/817 (dataset index: 481)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 482 (dataset index 481): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 483/817 (dataset index: 482)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 483 (dataset index 482): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 484/817 (dataset index: 483)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 391.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 484 (dataset index 483): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 391.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 485/817 (dataset index: 484)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 485 (dataset index 484): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 486/817 (dataset index: 485)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 486 (dataset index 485): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 487/817 (dataset index: 486)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 308.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 487 (dataset index 486): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 308.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 488/817 (dataset index: 487)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 488 (dataset index 487): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 489/817 (dataset index: 488)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 489 (dataset index 488): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 490/817 (dataset index: 489)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 490 (dataset index 489): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 491/817 (dataset index: 490)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 491 (dataset index 490): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 492/817 (dataset index: 491)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 492 (dataset index 491): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 493/817 (dataset index: 492)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 493 (dataset index 492): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 494/817 (dataset index: 493)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 494 (dataset index 493): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 495/817 (dataset index: 494)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 495 (dataset index 494): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 496/817 (dataset index: 495)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 496 (dataset index 495): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 497/817 (dataset index: 496)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 497 (dataset index 496): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 498/817 (dataset index: 497)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 498 (dataset index 497): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 499/817 (dataset index: 498)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 499 (dataset index 498): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 500/817 (dataset index: 499)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 500 (dataset index 499): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 501/817 (dataset index: 500)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 501 (dataset index 500): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 502/817 (dataset index: 501)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 306.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 502 (dataset index 501): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 306.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 503/817 (dataset index: 502)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 503 (dataset index 502): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 504/817 (dataset index: 503)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 504 (dataset index 503): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 505/817 (dataset index: 504)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 505 (dataset index 504): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 506/817 (dataset index: 505)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 307.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 506 (dataset index 505): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 307.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 507/817 (dataset index: 506)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 507 (dataset index 506): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 508/817 (dataset index: 507)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 508 (dataset index 507): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 509/817 (dataset index: 508)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 284.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 509 (dataset index 508): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 284.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 510/817 (dataset index: 509)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 312.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 510 (dataset index 509): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 312.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 511/817 (dataset index: 510)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 391.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 511 (dataset index 510): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 391.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 512/817 (dataset index: 511)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 835.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 305.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 512 (dataset index 511): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 835.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 305.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 513/817 (dataset index: 512)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 513 (dataset index 512): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 514/817 (dataset index: 513)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 316.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 514 (dataset index 513): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 823.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 316.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 515/817 (dataset index: 514)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 515 (dataset index 514): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 516/817 (dataset index: 515)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 516 (dataset index 515): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 517/817 (dataset index: 516)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 517 (dataset index 516): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 518/817 (dataset index: 517)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 518 (dataset index 517): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 519/817 (dataset index: 518)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 893.88 MiB is free. Including non-PyTorch memory, this process has 6.71 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 275.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 519 (dataset index 518): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 893.88 MiB is free. Including non-PyTorch memory, this process has 6.71 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 275.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 520/817 (dataset index: 519)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 520 (dataset index 519): empty completion produced
Processing sample 521/817 (dataset index: 520)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 521 (dataset index 520): empty completion produced
Processing sample 522/817 (dataset index: 521)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 837.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 303.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 522 (dataset index 521): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 837.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 303.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 523/817 (dataset index: 522)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 839.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 301.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 523 (dataset index 522): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 839.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 301.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 524/817 (dataset index: 523)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 524 (dataset index 523): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 525/817 (dataset index: 524)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 525 (dataset index 524): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 526/817 (dataset index: 525)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 526 (dataset index 525): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 527/817 (dataset index: 526)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 527 (dataset index 526): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 528/817 (dataset index: 527)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 528 (dataset index 527): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 529/817 (dataset index: 528)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 529 (dataset index 528): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 530/817 (dataset index: 529)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 530 (dataset index 529): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 531/817 (dataset index: 530)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 531 (dataset index 530): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 532/817 (dataset index: 531)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 297.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 532 (dataset index 531): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 297.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 533/817 (dataset index: 532)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 215.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 533 (dataset index 532): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 215.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 534/817 (dataset index: 533)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 534 (dataset index 533): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 535/817 (dataset index: 534)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 535 (dataset index 534): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 536/817 (dataset index: 535)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 536 (dataset index 535): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 537/817 (dataset index: 536)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 537 (dataset index 536): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 538/817 (dataset index: 537)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 538 (dataset index 537): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 539/817 (dataset index: 538)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 539 (dataset index 538): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 540/817 (dataset index: 539)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 540 (dataset index 539): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 541/817 (dataset index: 540)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 541 (dataset index 540): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 542/817 (dataset index: 541)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 542 (dataset index 541): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 543/817 (dataset index: 542)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 543 (dataset index 542): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 544/817 (dataset index: 543)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 544 (dataset index 543): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 545/817 (dataset index: 544)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 919.88 MiB is free. Including non-PyTorch memory, this process has 6.69 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 255.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 545 (dataset index 544): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 919.88 MiB is free. Including non-PyTorch memory, this process has 6.69 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 255.92 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 546/817 (dataset index: 545)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 546 (dataset index 545): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 547/817 (dataset index: 546)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 547 (dataset index 546): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 548/817 (dataset index: 547)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 548 (dataset index 547): empty completion produced
Processing sample 549/817 (dataset index: 548)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 549 (dataset index 548): empty completion produced
Processing sample 550/817 (dataset index: 549)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 550 (dataset index 549): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 551/817 (dataset index: 550)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 551 (dataset index 550): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 552/817 (dataset index: 551)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 552 (dataset index 551): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 553/817 (dataset index: 552)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 553 (dataset index 552): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 554/817 (dataset index: 553)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 554 (dataset index 553): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 555/817 (dataset index: 554)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 555 (dataset index 554): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 556/817 (dataset index: 555)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 556 (dataset index 555): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 557/817 (dataset index: 556)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 557 (dataset index 556): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 558/817 (dataset index: 557)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 558 (dataset index 557): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 559/817 (dataset index: 558)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 957.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 210.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 559 (dataset index 558): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 957.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 210.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 560/817 (dataset index: 559)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 869.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 560 (dataset index 559): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 869.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 561/817 (dataset index: 560)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 333.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 561 (dataset index 560): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 333.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 562/817 (dataset index: 561)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 562 (dataset index 561): empty completion produced
Processing sample 563/817 (dataset index: 562)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 563 (dataset index 562): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 873.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 263.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 564/817 (dataset index: 563)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 883.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 282.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 564 (dataset index 563): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 883.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 282.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 565/817 (dataset index: 564)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 565 (dataset index 564): empty completion produced
Processing sample 566/817 (dataset index: 565)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 807.88 MiB is free. Including non-PyTorch memory, this process has 6.80 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 332.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 566 (dataset index 565): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 807.88 MiB is free. Including non-PyTorch memory, this process has 6.80 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 332.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 567/817 (dataset index: 566)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 567 (dataset index 566): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 568/817 (dataset index: 567)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 568 (dataset index 567): empty completion produced
Processing sample 569/817 (dataset index: 568)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 871.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 266.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 569 (dataset index 568): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 871.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 266.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 570/817 (dataset index: 569)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 375.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 570 (dataset index 569): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 375.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 571/817 (dataset index: 570)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 376.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 571 (dataset index 570): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 759.88 MiB is free. Including non-PyTorch memory, this process has 6.85 GiB memory in use. Of the allocated memory 6.36 GiB is allocated by PyTorch, and 376.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 572/817 (dataset index: 571)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 215.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 572 (dataset index 571): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 215.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 573/817 (dataset index: 572)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 573 (dataset index 572): empty completion produced
Processing sample 574/817 (dataset index: 573)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 202.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 574 (dataset index 573): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 202.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 575/817 (dataset index: 574)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 575 (dataset index 574): empty completion produced
Processing sample 576/817 (dataset index: 575)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Skipping sample 576 (dataset index 575): empty completion produced
Processing sample 577/817 (dataset index: 576)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 577 (dataset index 576): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 578/817 (dataset index: 577)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 578 (dataset index 577): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 579/817 (dataset index: 578)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 579 (dataset index 578): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 580/817 (dataset index: 579)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 580 (dataset index 579): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 581/817 (dataset index: 580)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 581 (dataset index 580): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 582/817 (dataset index: 581)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 582 (dataset index 581): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 583/817 (dataset index: 582)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 583 (dataset index 582): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 584/817 (dataset index: 583)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 584 (dataset index 583): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 585/817 (dataset index: 584)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 585 (dataset index 584): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 586/817 (dataset index: 585)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 586 (dataset index 585): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 587/817 (dataset index: 586)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 587 (dataset index 586): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 588/817 (dataset index: 587)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 588 (dataset index 587): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 589/817 (dataset index: 588)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 589 (dataset index 588): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 590/817 (dataset index: 589)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 590 (dataset index 589): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 591/817 (dataset index: 590)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 591 (dataset index 590): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 592/817 (dataset index: 591)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 592 (dataset index 591): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 593/817 (dataset index: 592)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 593 (dataset index 592): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 594/817 (dataset index: 593)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 594 (dataset index 593): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 595/817 (dataset index: 594)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 595 (dataset index 594): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 596/817 (dataset index: 595)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 596 (dataset index 595): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 597/817 (dataset index: 596)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 837.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 303.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 597 (dataset index 596): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 837.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 303.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 598/817 (dataset index: 597)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 598 (dataset index 597): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 599/817 (dataset index: 598)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 599 (dataset index 598): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 600/817 (dataset index: 599)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 600 (dataset index 599): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 601/817 (dataset index: 600)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 215.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 601 (dataset index 600): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 955.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 215.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 602/817 (dataset index: 601)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 312.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 602 (dataset index 601): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 312.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 603/817 (dataset index: 602)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 603 (dataset index 602): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 604/817 (dataset index: 603)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 604 (dataset index 603): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 287.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 605/817 (dataset index: 604)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 390.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 605 (dataset index 604): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 390.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 606/817 (dataset index: 605)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 877.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 287.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 606 (dataset index 605): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 877.88 MiB is free. Including non-PyTorch memory, this process has 6.73 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 287.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 607/817 (dataset index: 606)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 285.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 607 (dataset index 606): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 285.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 608/817 (dataset index: 607)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 939.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 227.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 608 (dataset index 607): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 939.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 227.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 609/817 (dataset index: 608)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 609 (dataset index 608): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 610/817 (dataset index: 609)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 610 (dataset index 609): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 611/817 (dataset index: 610)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 611 (dataset index 610): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 612/817 (dataset index: 611)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 612 (dataset index 611): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 613/817 (dataset index: 612)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 613 (dataset index 612): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 614/817 (dataset index: 613)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 614 (dataset index 613): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 615/817 (dataset index: 614)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 297.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 615 (dataset index 614): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 297.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 616/817 (dataset index: 615)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 203.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 616 (dataset index 615): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 203.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 617/817 (dataset index: 616)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 617 (dataset index 616): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 618/817 (dataset index: 617)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 618 (dataset index 617): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 777.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 367.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 619/817 (dataset index: 618)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 619 (dataset index 618): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 620/817 (dataset index: 619)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 620 (dataset index 619): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 621/817 (dataset index: 620)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 621 (dataset index 620): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 622/817 (dataset index: 621)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 622 (dataset index 621): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 623/817 (dataset index: 622)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 623 (dataset index 622): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 624/817 (dataset index: 623)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 624 (dataset index 623): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 625/817 (dataset index: 624)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 625 (dataset index 624): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 626/817 (dataset index: 625)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 626 (dataset index 625): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 627/817 (dataset index: 626)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 627 (dataset index 626): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 628/817 (dataset index: 627)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 628 (dataset index 627): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 629/817 (dataset index: 628)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 629 (dataset index 628): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 630/817 (dataset index: 629)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 630 (dataset index 629): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 631/817 (dataset index: 630)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 631 (dataset index 630): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 632/817 (dataset index: 631)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 632 (dataset index 631): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 633/817 (dataset index: 632)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 633 (dataset index 632): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 634/817 (dataset index: 633)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 634 (dataset index 633): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 635/817 (dataset index: 634)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 635 (dataset index 634): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 636/817 (dataset index: 635)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 374.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 636 (dataset index 635): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 374.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 637/817 (dataset index: 636)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 637 (dataset index 636): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 638/817 (dataset index: 637)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 638 (dataset index 637): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 639/817 (dataset index: 638)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 639 (dataset index 638): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 640/817 (dataset index: 639)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 640 (dataset index 639): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 641/817 (dataset index: 640)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 641 (dataset index 640): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 642/817 (dataset index: 641)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 642 (dataset index 641): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 643/817 (dataset index: 642)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 643 (dataset index 642): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 644/817 (dataset index: 643)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 644 (dataset index 643): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 645/817 (dataset index: 644)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 312.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 645 (dataset index 644): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 312.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 646/817 (dataset index: 645)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 646 (dataset index 645): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 647/817 (dataset index: 646)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 647 (dataset index 646): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 648/817 (dataset index: 647)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 648 (dataset index 647): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 649/817 (dataset index: 648)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 649 (dataset index 648): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 650/817 (dataset index: 649)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 650 (dataset index 649): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 651/817 (dataset index: 650)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 651 (dataset index 650): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 652/817 (dataset index: 651)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 652 (dataset index 651): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 653/817 (dataset index: 652)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 653 (dataset index 652): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 654/817 (dataset index: 653)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 654 (dataset index 653): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 655/817 (dataset index: 654)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 655 (dataset index 654): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 656/817 (dataset index: 655)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 656 (dataset index 655): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 657/817 (dataset index: 656)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 657 (dataset index 656): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 658/817 (dataset index: 657)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 658 (dataset index 657): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 659/817 (dataset index: 658)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 659 (dataset index 658): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 660/817 (dataset index: 659)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 660 (dataset index 659): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 661/817 (dataset index: 660)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 661 (dataset index 660): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 662/817 (dataset index: 661)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 662 (dataset index 661): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 663/817 (dataset index: 662)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 663 (dataset index 662): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 664/817 (dataset index: 663)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 664 (dataset index 663): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 665/817 (dataset index: 664)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 665 (dataset index 664): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 666/817 (dataset index: 665)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 666 (dataset index 665): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 667/817 (dataset index: 666)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 667 (dataset index 666): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 668/817 (dataset index: 667)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 668 (dataset index 667): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 669/817 (dataset index: 668)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 839.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 301.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 669 (dataset index 668): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 839.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 301.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 670/817 (dataset index: 669)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 670 (dataset index 669): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 671/817 (dataset index: 670)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 671 (dataset index 670): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 672/817 (dataset index: 671)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 672 (dataset index 671): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 673/817 (dataset index: 672)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 673 (dataset index 672): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 674/817 (dataset index: 673)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 674 (dataset index 673): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 675/817 (dataset index: 674)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 675 (dataset index 674): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 676/817 (dataset index: 675)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 676 (dataset index 675): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 677/817 (dataset index: 676)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 677 (dataset index 676): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 678/817 (dataset index: 677)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 678 (dataset index 677): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 679/817 (dataset index: 678)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 679 (dataset index 678): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 680/817 (dataset index: 679)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 680 (dataset index 679): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 681/817 (dataset index: 680)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 681 (dataset index 680): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 682/817 (dataset index: 681)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 682 (dataset index 681): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 683/817 (dataset index: 682)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 799.88 MiB is free. Including non-PyTorch memory, this process has 6.81 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 356.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 683 (dataset index 682): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 799.88 MiB is free. Including non-PyTorch memory, this process has 6.81 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 356.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 684/817 (dataset index: 683)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 684 (dataset index 683): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 685/817 (dataset index: 684)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 685 (dataset index 684): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 686/817 (dataset index: 685)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 686 (dataset index 685): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 687/817 (dataset index: 686)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 687 (dataset index 686): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 688/817 (dataset index: 687)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 688 (dataset index 687): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 689/817 (dataset index: 688)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 302.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 689 (dataset index 688): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 302.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 690/817 (dataset index: 689)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 690 (dataset index 689): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 691/817 (dataset index: 690)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 691 (dataset index 690): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 692/817 (dataset index: 691)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 692 (dataset index 691): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 693/817 (dataset index: 692)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 693 (dataset index 692): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 694/817 (dataset index: 693)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 773.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 372.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 694 (dataset index 693): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 773.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 372.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 695/817 (dataset index: 694)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 813.88 MiB is free. Including non-PyTorch memory, this process has 6.79 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 346.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 695 (dataset index 694): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 813.88 MiB is free. Including non-PyTorch memory, this process has 6.79 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 346.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 696/817 (dataset index: 695)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 696 (dataset index 695): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 697/817 (dataset index: 696)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 697 (dataset index 696): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 698/817 (dataset index: 697)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 698 (dataset index 697): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 699/817 (dataset index: 698)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 699 (dataset index 698): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 377.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 700/817 (dataset index: 699)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 700 (dataset index 699): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 701/817 (dataset index: 700)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 701 (dataset index 700): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 702/817 (dataset index: 701)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 702 (dataset index 701): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 703/817 (dataset index: 702)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 703 (dataset index 702): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 704/817 (dataset index: 703)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 704 (dataset index 703): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 705/817 (dataset index: 704)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 705 (dataset index 704): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 706/817 (dataset index: 705)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 706 (dataset index 705): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 707/817 (dataset index: 706)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 707 (dataset index 706): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 708/817 (dataset index: 707)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 708 (dataset index 707): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 709/817 (dataset index: 708)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 709 (dataset index 708): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 710/817 (dataset index: 709)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 710 (dataset index 709): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 711/817 (dataset index: 710)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 306.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 711 (dataset index 710): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 306.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 712/817 (dataset index: 711)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 712 (dataset index 711): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 713/817 (dataset index: 712)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 713 (dataset index 712): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 714/817 (dataset index: 713)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 941.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 225.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 714 (dataset index 713): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 941.88 MiB is free. Including non-PyTorch memory, this process has 6.67 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 225.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 715/817 (dataset index: 714)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 715 (dataset index 714): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 716/817 (dataset index: 715)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 716 (dataset index 715): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 375.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 717/817 (dataset index: 716)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 717 (dataset index 716): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 718/817 (dataset index: 717)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 865.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 273.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 718 (dataset index 717): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 865.88 MiB is free. Including non-PyTorch memory, this process has 6.74 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 273.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 719/817 (dataset index: 718)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 719 (dataset index 718): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 720/817 (dataset index: 719)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 720 (dataset index 719): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 721/817 (dataset index: 720)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 384.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 721 (dataset index 720): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 384.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 722/817 (dataset index: 721)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 722 (dataset index 721): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 723/817 (dataset index: 722)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 723 (dataset index 722): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 724/817 (dataset index: 723)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 831.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 309.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 724 (dataset index 723): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 831.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 309.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 725/817 (dataset index: 724)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 813.88 MiB is free. Including non-PyTorch memory, this process has 6.79 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 336.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 725 (dataset index 724): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 813.88 MiB is free. Including non-PyTorch memory, this process has 6.79 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 336.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 726/817 (dataset index: 725)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 726 (dataset index 725): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 727/817 (dataset index: 726)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 727 (dataset index 726): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 728/817 (dataset index: 727)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 728 (dataset index 727): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 729/817 (dataset index: 728)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 729 (dataset index 728): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 730/817 (dataset index: 729)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 730 (dataset index 729): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 731/817 (dataset index: 730)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 731 (dataset index 730): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 732/817 (dataset index: 731)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 732 (dataset index 731): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 733/817 (dataset index: 732)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 335.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 733 (dataset index 732): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 335.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 734/817 (dataset index: 733)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 734 (dataset index 733): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 735/817 (dataset index: 734)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 735 (dataset index 734): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 294.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 736/817 (dataset index: 735)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 736 (dataset index 735): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 737/817 (dataset index: 736)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 737 (dataset index 736): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 738/817 (dataset index: 737)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 738 (dataset index 737): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 849.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 739/817 (dataset index: 738)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 739 (dataset index 738): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 740/817 (dataset index: 739)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 740 (dataset index 739): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 741/817 (dataset index: 740)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 310.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 741 (dataset index 740): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 843.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 310.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 742/817 (dataset index: 741)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 742 (dataset index 741): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 743/817 (dataset index: 742)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 743 (dataset index 742): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 744/817 (dataset index: 743)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 744 (dataset index 743): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 745/817 (dataset index: 744)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 745 (dataset index 744): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 746/817 (dataset index: 745)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 746 (dataset index 745): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 747/817 (dataset index: 746)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 747 (dataset index 746): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 748/817 (dataset index: 747)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 748 (dataset index 747): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 749/817 (dataset index: 748)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 749 (dataset index 748): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 750/817 (dataset index: 749)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 750 (dataset index 749): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 751/817 (dataset index: 750)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 751 (dataset index 750): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 752/817 (dataset index: 751)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 752 (dataset index 751): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 753/817 (dataset index: 752)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 753 (dataset index 752): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 754/817 (dataset index: 753)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 754 (dataset index 753): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 755/817 (dataset index: 754)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 755 (dataset index 754): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 756/817 (dataset index: 755)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 756 (dataset index 755): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 757/817 (dataset index: 756)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 757 (dataset index 756): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 758/817 (dataset index: 757)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 758 (dataset index 757): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 759/817 (dataset index: 758)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 759 (dataset index 758): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 292.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 760/817 (dataset index: 759)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 760 (dataset index 759): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 761/817 (dataset index: 760)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 761 (dataset index 760): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 762/817 (dataset index: 761)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 762 (dataset index 761): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 763/817 (dataset index: 762)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 763 (dataset index 762): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 847.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 296.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 764/817 (dataset index: 763)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 764 (dataset index 763): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 765/817 (dataset index: 764)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 959.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 208.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 765 (dataset index 764): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 959.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 208.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 766/817 (dataset index: 765)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 766 (dataset index 765): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 767/817 (dataset index: 766)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 767 (dataset index 766): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 768/817 (dataset index: 767)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 768 (dataset index 767): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 769/817 (dataset index: 768)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 769 (dataset index 768): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 770/817 (dataset index: 769)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 887.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 282.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 770 (dataset index 769): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 887.88 MiB is free. Including non-PyTorch memory, this process has 6.72 GiB memory in use. Of the allocated memory 6.32 GiB is allocated by PyTorch, and 282.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 771/817 (dataset index: 770)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 771 (dataset index 770): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 772/817 (dataset index: 771)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 772 (dataset index 771): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 773/817 (dataset index: 772)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 773 (dataset index 772): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 291.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 774/817 (dataset index: 773)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 774 (dataset index 773): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 775/817 (dataset index: 774)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 775 (dataset index 774): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 776/817 (dataset index: 775)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 776 (dataset index 775): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 761.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 384.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 777/817 (dataset index: 776)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 777 (dataset index 776): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 769.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 376.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 778/817 (dataset index: 777)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 775.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 369.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 778 (dataset index 777): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 775.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 369.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 779/817 (dataset index: 778)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 779 (dataset index 778): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 780/817 (dataset index: 779)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 780 (dataset index 779): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 781/817 (dataset index: 780)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 202.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 781 (dataset index 780): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 961.88 MiB is free. Including non-PyTorch memory, this process has 6.65 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 202.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 782/817 (dataset index: 781)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 782 (dataset index 781): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 783/817 (dataset index: 782)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 783 (dataset index 782): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 771.88 MiB is free. Including non-PyTorch memory, this process has 6.83 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 373.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 784/817 (dataset index: 783)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 784 (dataset index 783): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 785/817 (dataset index: 784)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 785 (dataset index 784): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 295.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 786/817 (dataset index: 785)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 786 (dataset index 785): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 851.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 293.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 787/817 (dataset index: 786)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 787 (dataset index 786): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 788/817 (dataset index: 787)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 788 (dataset index 787): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 789/817 (dataset index: 788)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 789 (dataset index 788): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 790/817 (dataset index: 789)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 790 (dataset index 789): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 791/817 (dataset index: 790)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 791 (dataset index 790): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 288.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 792/817 (dataset index: 791)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 792 (dataset index 791): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 793/817 (dataset index: 792)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 793 (dataset index 792): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 794/817 (dataset index: 793)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 794 (dataset index 793): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 383.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 795/817 (dataset index: 794)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 335.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 795 (dataset index 794): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 825.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 335.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 796/817 (dataset index: 795)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 796 (dataset index 795): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 797/817 (dataset index: 796)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 797 (dataset index 796): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 798/817 (dataset index: 797)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 798 (dataset index 797): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 799/817 (dataset index: 798)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 799 (dataset index 798): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 800/817 (dataset index: 799)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 800 (dataset index 799): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 855.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 289.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 801/817 (dataset index: 800)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 801 (dataset index 800): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 845.88 MiB is free. Including non-PyTorch memory, this process has 6.76 GiB memory in use. Of the allocated memory 6.34 GiB is allocated by PyTorch, and 309.53 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 802/817 (dataset index: 801)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 802 (dataset index 801): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 803/817 (dataset index: 802)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 803 (dataset index 802): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 857.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 286.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 804/817 (dataset index: 803)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 804 (dataset index 803): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 379.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 805/817 (dataset index: 804)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 805 (dataset index 804): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 853.88 MiB is free. Including non-PyTorch memory, this process has 6.75 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 290.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 806/817 (dataset index: 805)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 806 (dataset index 805): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 380.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 807/817 (dataset index: 806)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 807 (dataset index 806): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 808/817 (dataset index: 807)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 808 (dataset index 807): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 809/817 (dataset index: 808)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 809 (dataset index 808): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 810/817 (dataset index: 809)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 810 (dataset index 809): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 811/817 (dataset index: 810)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 811 (dataset index 810): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 383.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 812/817 (dataset index: 811)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 812 (dataset index 811): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 765.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 813/817 (dataset index: 812)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 841.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 299.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 813 (dataset index 812): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 841.88 MiB is free. Including non-PyTorch memory, this process has 6.77 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 299.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 814/817 (dataset index: 813)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 333.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 814 (dataset index 813): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 827.88 MiB is free. Including non-PyTorch memory, this process has 6.78 GiB memory in use. Of the allocated memory 6.33 GiB is allocated by PyTorch, and 333.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 815/817 (dataset index: 814)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 815 (dataset index 814): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 381.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 816/817 (dataset index: 815)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 816 (dataset index 815): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 763.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 382.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 817/817 (dataset index: 816)
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Error in completion_gradient: CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 817 (dataset index 816): CUDA out of memory. Tried to allocate 1002.00 MiB. GPU 0 has a total capacity of 7.60 GiB of which 767.88 MiB is free. Including non-PyTorch memory, this process has 6.84 GiB memory in use. Of the allocated memory 6.35 GiB is allocated by PyTorch, and 378.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing complete, but no successful results to save. Failed: 798. Skipped: 19
