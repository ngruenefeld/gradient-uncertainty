slurmstepd-abakus11: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus11: error: Setting TMPDIR to /tmp
Running job with commit: 72b2a45672ff5569b7b32fc3b375ba6fe28783a1
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 13497
Dataset: commoncorpus
Model: llama-awq
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Sample size: 0
Mode: full
Quantization bits: None (full precision)
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: synonym
Number of perturbations: 3
Max tokens: 1024
You have loaded an AWQ model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/scripts/multiling.py", line 440, in <module>
    main(args)
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/scripts/multiling.py", line 137, in main
    data = load_multilingual_datasets(dataset_name)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/utils/utils.py", line 815, in load_multilingual_datasets
    dataset = load_dataset("PleIAs/common_corpus", split="train", streaming=True)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/datasets/load.py", line 2062, in load_dataset
    builder_instance = load_dataset_builder(
                       ^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/datasets/load.py", line 1782, in load_dataset_builder
    dataset_module = dataset_module_factory(
                     ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/datasets/load.py", line 1664, in dataset_module_factory
    raise e1 from None
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/datasets/load.py", line 1565, in dataset_module_factory
    raise ConnectionError(f"Couldn't reach '{path}' on the Hub ({e.__class__.__name__})") from e
ConnectionError: Couldn't reach 'PleIAs/common_corpus' on the Hub (ReadTimeout)
[main 9aa9d92] Multilingual Script Results for Run 13497 (Commit: 72b2a45)
 9 files changed, 143 insertions(+)
 create mode 100644 slurm-outputs/slurm.13367.abakus21.out
 create mode 100644 slurm-outputs/slurm.13485.abakus11.out
 create mode 100644 slurm-outputs/slurm.13486.abakus12.out
 create mode 100644 slurm-outputs/slurm.13487.abakus21.out
 create mode 100644 slurm-outputs/slurm.13497.abakus11.out
 create mode 100644 slurm-outputs/slurm.13498.abakus12.out
 create mode 100644 slurm-outputs/slurm.13499.abakus21.out
To github.com:ngruenefeld/gradient-uncertainty.git
   72b2a45..9aa9d92  main -> main
