slurmstepd-abakus12: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus12: error: Setting TMPDIR to /tmp
Running job with commit: 72b2a45672ff5569b7b32fc3b375ba6fe28783a1
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 13498
Dataset: commoncorpus
Model: polylm-1.7b
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Sample size: 0
Mode: full
Quantization bits: 4
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: synonym
Number of perturbations: 3
Max tokens: 0
Loading model in 4-bit precision to reduce memory usage
Using slow tokenizer implementation for polylm-1.7b
You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565 - if you loaded a llama tokenizer from a GGUF file you can ignore this message
