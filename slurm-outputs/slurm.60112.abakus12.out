slurmstepd-abakus12: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus12: error: Setting TMPDIR to /tmp
Running job with commit: fcbcd910fffcee37edd7815f581f7774b1937f4e
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 60112
Dataset: finefineweb
Model: llama-3-8b
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Mode: full
Quantization bits: 4
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: rephrase
Number of perturbations: 3
Max tokens: 0
Sample Size Per Label: 1000
Loading model in 4-bit precision to reduce memory usage
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:09,  3.14s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:06<00:06,  3.21s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:09<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.32s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:10<00:00,  2.65s/it]
Processing sample 1/7200 (dataset index: 0)
Processing sample 1 (dataset index 0)
Sample 1 (dataset index 0) processed successfully with 3 rephrasings.
Processing sample 2/7200 (dataset index: 1)
Processing sample 2 (dataset index 1)
Sample 2 (dataset index 1) processed successfully with 3 rephrasings.
Processing sample 3/7200 (dataset index: 2)
Processing sample 3 (dataset index 2)
Error in completion_gradient: CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 928.06 MiB is free. Including non-PyTorch memory, this process has 18.65 GiB memory in use. Of the allocated memory 18.01 GiB is allocated by PyTorch, and 419.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 3 (dataset index 2): CUDA out of memory. Tried to allocate 972.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 928.06 MiB is free. Including non-PyTorch memory, this process has 18.65 GiB memory in use. Of the allocated memory 18.01 GiB is allocated by PyTorch, and 419.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 4/7200 (dataset index: 3)
Processing sample 4 (dataset index 3)
Sample 4 (dataset index 3) processed successfully with 3 rephrasings.
Processing sample 5/7200 (dataset index: 4)
Processing sample 5 (dataset index 4)
Sample 5 (dataset index 4) processed successfully with 3 rephrasings.
Processing sample 6/7200 (dataset index: 5)
Processing sample 6 (dataset index 5)
Sample 6 (dataset index 5) processed successfully with 3 rephrasings.
Processing sample 7/7200 (dataset index: 6)
Processing sample 7 (dataset index 6)
Sample 7 (dataset index 6) processed successfully with 3 rephrasings.
Processing sample 8/7200 (dataset index: 7)
Processing sample 8 (dataset index 7)
Error in completion_gradient: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 301.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 8 (dataset index 7): CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 301.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 9/7200 (dataset index: 8)
Processing sample 9 (dataset index 8)
Sample 9 (dataset index 8) processed successfully with 3 rephrasings.
Processing sample 10/7200 (dataset index: 9)
Processing sample 10 (dataset index 9)
Sample 10 (dataset index 9) processed successfully with 3 rephrasings.
Processing sample 11/7200 (dataset index: 10)
Processing sample 11 (dataset index 10)
Sample 11 (dataset index 10) processed successfully with 3 rephrasings.
Processing sample 12/7200 (dataset index: 11)
Processing sample 12 (dataset index 11)
JSONDecodeError: Expecting value: line 24288 column 1 (char 45108)
Error getting rephrasings for sample 12 (dataset index 11): Invalid JSON response from API
Processing sample 13/7200 (dataset index: 12)
Processing sample 13 (dataset index 12)
Sample 13 (dataset index 12) processed successfully with 3 rephrasings.
Processing sample 14/7200 (dataset index: 13)
Processing sample 14 (dataset index 13)
Sample 14 (dataset index 13) processed successfully with 3 rephrasings.
Processing sample 15/7200 (dataset index: 14)
Processing sample 15 (dataset index 14)
Sample 15 (dataset index 14) processed successfully with 3 rephrasings.
Processing sample 16/7200 (dataset index: 15)
Processing sample 16 (dataset index 15)
Error in completion_gradient: CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 581.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 16 (dataset index 15): CUDA out of memory. Tried to allocate 110.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 110.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.65 GiB is allocated by PyTorch, and 581.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 17/7200 (dataset index: 16)
Processing sample 17 (dataset index 16)
Sample 17 (dataset index 16) processed successfully with 3 rephrasings.
Processing sample 18/7200 (dataset index: 17)
Processing sample 18 (dataset index 17)
Sample 18 (dataset index 17) processed successfully with 3 rephrasings.
Processing sample 19/7200 (dataset index: 18)
Processing sample 19 (dataset index 18)
Sample 19 (dataset index 18) processed successfully with 3 rephrasings.
Processing sample 20/7200 (dataset index: 19)
Processing sample 20 (dataset index 19)
Sample 20 (dataset index 19) processed successfully with 3 rephrasings.
Processing sample 21/7200 (dataset index: 20)
Processing sample 21 (dataset index 20)
Sample 21 (dataset index 20) processed successfully with 3 rephrasings.
Processing sample 22/7200 (dataset index: 21)
Processing sample 22 (dataset index 21)
Sample 22 (dataset index 21) processed successfully with 3 rephrasings.
Processing sample 23/7200 (dataset index: 22)
Processing sample 23 (dataset index 22)
Sample 23 (dataset index 22) processed successfully with 3 rephrasings.
Processing sample 24/7200 (dataset index: 23)
Processing sample 24 (dataset index 23)
Error in completion_gradient: CUDA out of memory. Tried to allocate 1006.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.38 GiB is allocated by PyTorch, and 819.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 24 (dataset index 23): CUDA out of memory. Tried to allocate 1006.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 146.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.38 GiB is allocated by PyTorch, and 819.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 25/7200 (dataset index: 24)
Processing sample 25 (dataset index 24)
Sample 25 (dataset index 24) processed successfully with 2 rephrasings.
Processing sample 26/7200 (dataset index: 25)
Processing sample 26 (dataset index 25)
Sample 26 (dataset index 25) processed successfully with 3 rephrasings.
Processing sample 27/7200 (dataset index: 26)
Processing sample 27 (dataset index 26)
Sample 27 (dataset index 26) processed successfully with 3 rephrasings.
Processing sample 28/7200 (dataset index: 27)
Processing sample 28 (dataset index 27)
Sample 28 (dataset index 27) processed successfully with 3 rephrasings.
Processing sample 29/7200 (dataset index: 28)
Processing sample 29 (dataset index 28)
Error in completion_gradient: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.55 GiB is allocated by PyTorch, and 779.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 29 (dataset index 28): CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 16.06 MiB is free. Including non-PyTorch memory, this process has 19.54 GiB memory in use. Of the allocated memory 18.55 GiB is allocated by PyTorch, and 779.27 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 30/7200 (dataset index: 29)
Processing sample 30 (dataset index 29)
Sample 30 (dataset index 29) processed successfully with 3 rephrasings.
Processing sample 31/7200 (dataset index: 30)
Processing sample 31 (dataset index 30)
Sample 31 (dataset index 30) processed successfully with 3 rephrasings.
Processing sample 32/7200 (dataset index: 31)
Processing sample 32 (dataset index 31)
Sample 32 (dataset index 31) processed successfully with 3 rephrasings.
Processing sample 33/7200 (dataset index: 32)
Processing sample 33 (dataset index 32)
Sample 33 (dataset index 32) processed successfully with 3 rephrasings.
Processing sample 34/7200 (dataset index: 33)
Processing sample 34 (dataset index 33)
Sample 34 (dataset index 33) processed successfully with 3 rephrasings.
Processing sample 35/7200 (dataset index: 34)
Processing sample 35 (dataset index 34)
Sample 35 (dataset index 34) processed successfully with 3 rephrasings.
Processing sample 36/7200 (dataset index: 35)
Processing sample 36 (dataset index 35)
Sample 36 (dataset index 35) processed successfully with 3 rephrasings.
Processing sample 37/7200 (dataset index: 36)
Processing sample 37 (dataset index 36)
Sample 37 (dataset index 36) processed successfully with 3 rephrasings.
Processing sample 38/7200 (dataset index: 37)
Processing sample 38 (dataset index 37)
Sample 38 (dataset index 37) processed successfully with 3 rephrasings.
Processing sample 39/7200 (dataset index: 38)
Processing sample 39 (dataset index 38)
Sample 39 (dataset index 38) processed successfully with 3 rephrasings.
Processing sample 40/7200 (dataset index: 39)
Processing sample 40 (dataset index 39)
Sample 40 (dataset index 39) processed successfully with 3 rephrasings.
Processing sample 41/7200 (dataset index: 40)
Processing sample 41 (dataset index 40)
Sample 41 (dataset index 40) processed successfully with 3 rephrasings.
Processing sample 42/7200 (dataset index: 41)
Processing sample 42 (dataset index 41)
Sample 42 (dataset index 41) processed successfully with 3 rephrasings.
Processing sample 43/7200 (dataset index: 42)
Processing sample 43 (dataset index 42)
Sample 43 (dataset index 42) processed successfully with 3 rephrasings.
Processing sample 44/7200 (dataset index: 43)
Processing sample 44 (dataset index 43)
Sample 44 (dataset index 43) processed successfully with 3 rephrasings.
Processing sample 45/7200 (dataset index: 44)
Processing sample 45 (dataset index 44)
Sample 45 (dataset index 44) processed successfully with 3 rephrasings.
Processing sample 46/7200 (dataset index: 45)
Processing sample 46 (dataset index 45)
Sample 46 (dataset index 45) processed successfully with 3 rephrasings.
Processing sample 47/7200 (dataset index: 46)
Processing sample 47 (dataset index 46)
Sample 47 (dataset index 46) processed successfully with 3 rephrasings.
Processing sample 48/7200 (dataset index: 47)
Processing sample 48 (dataset index 47)
Sample 48 (dataset index 47) processed successfully with 3 rephrasings.
Processing sample 49/7200 (dataset index: 48)
Processing sample 49 (dataset index 48)
Sample 49 (dataset index 48) processed successfully with 3 rephrasings.
Processing sample 50/7200 (dataset index: 49)
Processing sample 50 (dataset index 49)
Sample 50 (dataset index 49) processed successfully with 3 rephrasings.
Processing sample 51/7200 (dataset index: 50)
Processing sample 51 (dataset index 50)
Sample 51 (dataset index 50) processed successfully with 3 rephrasings.
Processing sample 52/7200 (dataset index: 51)
Processing sample 52 (dataset index 51)
Sample 52 (dataset index 51) processed successfully with 3 rephrasings.
Processing sample 53/7200 (dataset index: 52)
Processing sample 53 (dataset index 52)
Error in completion_gradient: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.40 GiB is allocated by PyTorch, and 840.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 53 (dataset index 52): CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 108.06 MiB is free. Including non-PyTorch memory, this process has 19.45 GiB memory in use. Of the allocated memory 18.40 GiB is allocated by PyTorch, and 840.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 54/7200 (dataset index: 53)
Processing sample 54 (dataset index 53)
Sample 54 (dataset index 53) processed successfully with 3 rephrasings.
Processing sample 55/7200 (dataset index: 54)
Processing sample 55 (dataset index 54)
Error in completion_gradient: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 490.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 55 (dataset index 54): CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 70.06 MiB is free. Including non-PyTorch memory, this process has 19.48 GiB memory in use. Of the allocated memory 18.78 GiB is allocated by PyTorch, and 490.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 56/7200 (dataset index: 55)
Processing sample 56 (dataset index 55)
Sample 56 (dataset index 55) processed successfully with 1 rephrasings.
Processing sample 57/7200 (dataset index: 56)
Processing sample 57 (dataset index 56)
Error in completion_gradient: CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 268.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 57 (dataset index 56): CUDA out of memory. Tried to allocate 172.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 142.06 MiB is free. Including non-PyTorch memory, this process has 19.41 GiB memory in use. Of the allocated memory 18.92 GiB is allocated by PyTorch, and 268.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 58/7200 (dataset index: 57)
Processing sample 58 (dataset index 57)
Sample 58 (dataset index 57) processed successfully with 3 rephrasings.
Processing sample 59/7200 (dataset index: 58)
Processing sample 59 (dataset index 58)
Sample 59 (dataset index 58) processed successfully with 3 rephrasings.
Processing sample 60/7200 (dataset index: 59)
Processing sample 60 (dataset index 59)
Sample 60 (dataset index 59) processed successfully with 2 rephrasings.
Processing sample 61/7200 (dataset index: 60)
Processing sample 61 (dataset index 60)
Sample 61 (dataset index 60) processed successfully with 3 rephrasings.
Processing sample 62/7200 (dataset index: 61)
Processing sample 62 (dataset index 61)
Error in completion_gradient: CUDA out of memory. Tried to allocate 888.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 576.06 MiB is free. Including non-PyTorch memory, this process has 18.99 GiB memory in use. Of the allocated memory 17.97 GiB is allocated by PyTorch, and 809.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 62 (dataset index 61): CUDA out of memory. Tried to allocate 888.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 576.06 MiB is free. Including non-PyTorch memory, this process has 18.99 GiB memory in use. Of the allocated memory 17.97 GiB is allocated by PyTorch, and 809.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 63/7200 (dataset index: 62)
Processing sample 63 (dataset index 62)
Sample 63 (dataset index 62) processed successfully with 3 rephrasings.
Processing sample 64/7200 (dataset index: 63)
Processing sample 64 (dataset index 63)
Sample 64 (dataset index 63) processed successfully with 3 rephrasings.
Processing sample 65/7200 (dataset index: 64)
Processing sample 65 (dataset index 64)
Sample 65 (dataset index 64) processed successfully with 3 rephrasings.
Processing sample 66/7200 (dataset index: 65)
Processing sample 66 (dataset index 65)
Sample 66 (dataset index 65) processed successfully with 3 rephrasings.
Processing sample 67/7200 (dataset index: 66)
Processing sample 67 (dataset index 66)
Sample 67 (dataset index 66) processed successfully with 3 rephrasings.
Processing sample 68/7200 (dataset index: 67)
Processing sample 68 (dataset index 67)
Sample 68 (dataset index 67) processed successfully with 1 rephrasings.
Processing sample 69/7200 (dataset index: 68)
Processing sample 69 (dataset index 68)
Sample 69 (dataset index 68) processed successfully with 3 rephrasings.
Processing sample 70/7200 (dataset index: 69)
Processing sample 70 (dataset index 69)
Sample 70 (dataset index 69) processed successfully with 3 rephrasings.
Processing sample 71/7200 (dataset index: 70)
Processing sample 71 (dataset index 70)
Sample 71 (dataset index 70) processed successfully with 3 rephrasings.
Processing sample 72/7200 (dataset index: 71)
Processing sample 72 (dataset index 71)
Sample 72 (dataset index 71) processed successfully with 3 rephrasings.
Processing sample 73/7200 (dataset index: 72)
Processing sample 73 (dataset index 72)
Sample 73 (dataset index 72) processed successfully with 3 rephrasings.
Processing sample 74/7200 (dataset index: 73)
Processing sample 74 (dataset index 73)
Sample 74 (dataset index 73) processed successfully with 3 rephrasings.
Processing sample 75/7200 (dataset index: 74)
Processing sample 75 (dataset index 74)
Error in completion_gradient: CUDA out of memory. Tried to allocate 522.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 378.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 75 (dataset index 74): CUDA out of memory. Tried to allocate 522.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 244.06 MiB is free. Including non-PyTorch memory, this process has 19.31 GiB memory in use. Of the allocated memory 18.71 GiB is allocated by PyTorch, and 378.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 76/7200 (dataset index: 75)
Processing sample 76 (dataset index 75)
Sample 76 (dataset index 75) processed successfully with 3 rephrasings.
Processing sample 77/7200 (dataset index: 76)
Processing sample 77 (dataset index 76)
Sample 77 (dataset index 76) processed successfully with 3 rephrasings.
Processing sample 78/7200 (dataset index: 77)
Processing sample 78 (dataset index 77)
Sample 78 (dataset index 77) processed successfully with 3 rephrasings.
Processing sample 79/7200 (dataset index: 78)
Processing sample 79 (dataset index 78)
Sample 79 (dataset index 78) processed successfully with 3 rephrasings.
Processing sample 80/7200 (dataset index: 79)
Processing sample 80 (dataset index 79)
Sample 80 (dataset index 79) processed successfully with 3 rephrasings.
Processing sample 81/7200 (dataset index: 80)
Processing sample 81 (dataset index 80)
Sample 81 (dataset index 80) processed successfully with 3 rephrasings.
Processing sample 82/7200 (dataset index: 81)
Processing sample 82 (dataset index 81)
Sample 82 (dataset index 81) processed successfully with 3 rephrasings.
Processing sample 83/7200 (dataset index: 82)
Processing sample 83 (dataset index 82)
Sample 83 (dataset index 82) processed successfully with 3 rephrasings.
Processing sample 84/7200 (dataset index: 83)
Processing sample 84 (dataset index 83)
Sample 84 (dataset index 83) processed successfully with 3 rephrasings.
Processing sample 85/7200 (dataset index: 84)
Processing sample 85 (dataset index 84)
Sample 85 (dataset index 84) processed successfully with 3 rephrasings.
Processing sample 86/7200 (dataset index: 85)
Processing sample 86 (dataset index 85)
Error in completion_gradient: CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 205.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 86 (dataset index 85): CUDA out of memory. Tried to allocate 204.00 MiB. GPU 0 has a total capacity of 19.58 GiB of which 152.06 MiB is free. Including non-PyTorch memory, this process has 19.40 GiB memory in use. Of the allocated memory 18.97 GiB is allocated by PyTorch, and 205.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 87/7200 (dataset index: 86)
Processing sample 87 (dataset index 86)
