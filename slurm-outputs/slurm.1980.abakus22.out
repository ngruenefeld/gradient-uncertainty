slurmstepd-abakus22: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus22: error: Setting TMPDIR to /tmp
Running job with commit: 2625a2ee74b4373b6941f34dd3921af71b97d94c
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 1980
Dataset: commoncorpus
Model: polylm-13b
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Sample size: 10
Mode: test
Quantization bits: 4
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: rephrase
Number of perturbations: 3
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:  25%|██▌       | 1/4 [04:31<13:35, 271.89s/it]/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 8927.40 MB. The target location /home/g/gruenefeld/.cache/huggingface/hub/models--DAMO-NLP-MT--polylm-13b/blobs only has 8803.83 MB free disk space.
  warnings.warn(
Error while downloading from https://cdn-lfs.hf.co/repos/cb/62/cb62863cd6a91d24cf543eb0f2b3d6d7c9441bf1859ee3dfcd93bae08ec0dfec/350657500c0b18c5b3c6e2defcabd74aa5b2024915951ffe8d54a2bac927bda9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model-00002-of-00004.bin%3B+filename%3D%22pytorch_model-00002-of-00004.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1746365023&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NjM2NTAyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy9jYi82Mi9jYjYyODYzY2Q2YTkxZDI0Y2Y1NDNlYjBmMmIzZDZkN2M5NDQxYmYxODU5ZWUzZGZjZDkzYmFlMDhlYzBkZmVjLzM1MDY1NzUwMGMwYjE4YzViM2M2ZTJkZWZjYWJkNzRhYTViMjAyNDkxNTk1MWZmZThkNTRhMmJhYzkyN2JkYTk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=jNXuRF9MVr-HzDEgz9a0eKCP8-UF3ZAqaCcz308NBlvQWKJrUeyTpyDXVajP7fvKYQtmO7RkrdbErV1sXLVLEgsfyRo2y0dExXUHGl8PH1i6aj5FwqpPQ1kenHP7pCe6Kq%7EdUG02Bbs1Z-YqfNnPycq-s3zEDocYswGKGGOFp41MOFWcdxUHYnLeSbSWnflwC7dRSAuFFs7ZfJJzqtPfHUJV9Y0UEF5rDINR5ffvRXq2KgokhzfSuY9YscVg6FZHtpBKdj-tLuxomU9L9mG3xl5NUw4dBwdNfySr5JEFA7AMQ8%7EiQftSStHP-XpVELK6D5d9SJpatcjW6N%7EjWdr%7Eew__&Key-Pair-Id=K3RPWS32NSSJCE: HTTPSConnectionPool(host='cdn-lfs.hf.co', port=443): Read timed out.
Trying to resume download...
Downloading shards:  50%|█████     | 2/4 [09:46<09:54, 297.14s/it]/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 8927.40 MB. The target location /home/g/gruenefeld/.cache/huggingface/hub/models--DAMO-NLP-MT--polylm-13b/blobs only has 0.00 MB free disk space.
  warnings.warn(
Downloading shards:  75%|███████▌  | 3/4 [14:34<04:52, 292.65s/it]/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/huggingface_hub/file_download.py:752: UserWarning: Not enough free disk space to download the file. The expected file size is: 4106.53 MB. The target location /home/g/gruenefeld/.cache/huggingface/hub/models--DAMO-NLP-MT--polylm-13b/blobs only has 0.00 MB free disk space.
  warnings.warn(
Downloading shards: 100%|██████████| 4/4 [16:43<00:00, 228.40s/it]Downloading shards: 100%|██████████| 4/4 [16:43<00:00, 250.98s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:49<02:29, 49.69s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:57<00:49, 24.85s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:03<00:16, 16.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 19.47s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.95s/it]
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/scripts/multiling.py", line 431, in <module>
    main(args)
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/scripts/multiling.py", line 127, in main
    model = AutoModelForCausalLM.from_pretrained(model_path, **model_load_params)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4264, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/g/gruenefeld/Documents/GitHub/gradient-uncertainty/env/lib/python3.12/site-packages/transformers/modeling_utils.py", line 4834, in _load_pretrained_model
    raise RuntimeError(f"Error(s) in loading state_dict for {model.__class__.__name__}:\n\t{error_msg}")
RuntimeError: Error(s) in loading state_dict for GPT2LMHeadModel:
	size mismatch for transformer.h.0.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.0.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.0.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.1.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.1.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.1.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.2.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.2.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.2.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.3.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.3.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.3.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.4.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.4.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.4.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.5.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.5.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.5.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.6.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.6.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.6.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.7.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.7.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.7.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.8.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.8.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.8.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.9.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.9.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.9.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.10.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.10.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.10.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.11.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.11.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.11.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.12.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.12.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.12.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.13.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.13.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.13.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.14.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.14.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.14.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.15.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.15.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.15.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.16.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.16.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.16.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.17.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.17.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.17.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.18.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.18.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.18.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.19.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.19.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.19.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.20.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.20.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.20.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.21.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.21.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.21.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.22.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.22.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.22.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.23.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.23.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.23.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.24.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.24.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.24.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.25.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.25.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.25.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.26.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.26.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.26.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.27.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.27.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.27.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.28.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.28.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.28.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.29.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.29.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.29.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.30.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.30.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.30.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.31.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.31.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.31.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.32.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.32.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.32.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.33.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.33.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.33.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.34.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.34.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.34.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.35.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.35.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.35.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.36.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.36.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.36.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.37.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.37.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.37.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.38.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.38.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.38.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	size mismatch for transformer.h.39.attn.c_attn.weight: copying a param with shape torch.Size([15360, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 15360]).
	size mismatch for transformer.h.39.mlp.c_fc.weight: copying a param with shape torch.Size([20480, 5120]) from checkpoint, the shape in current model is torch.Size([5120, 20480]).
	size mismatch for transformer.h.39.mlp.c_proj.weight: copying a param with shape torch.Size([5120, 20480]) from checkpoint, the shape in current model is torch.Size([20480, 5120]).
	You may consider adding `ignore_mismatched_sizes=True` in the model `from_pretrained` method.
[main b63ce74] Multilingual Script Results for Run 1980 (Commit: 2625a2e)
 4 files changed, 187 insertions(+)
To github.com:ngruenefeld/gradient-uncertainty.git
   b09394a..b63ce74  main -> main
