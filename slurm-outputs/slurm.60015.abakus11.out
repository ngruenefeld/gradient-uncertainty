slurmstepd-abakus11: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus11: error: Setting TMPDIR to /tmp
Running job with commit: ebd4e1ca3056d395441d2d3ea54c8e6e3b2f7ab0
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 60015
Dataset: ag-pubmed
Model: llama-3-8b
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Mode: test
Quantization bits: 4
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: random
Number of perturbations: 3
Max tokens: 0
Sample Size Per Label: 5
Loading model in 4-bit precision to reduce memory usage
Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]Downloading shards:  25%|██▌       | 1/4 [03:13<09:41, 194.00s/it]Downloading shards:  50%|█████     | 2/4 [06:53<06:58, 209.01s/it]Downloading shards:  75%|███████▌  | 3/4 [10:25<03:30, 210.19s/it]Downloading shards: 100%|██████████| 4/4 [11:10<00:00, 145.25s/it]Downloading shards: 100%|██████████| 4/4 [11:10<00:00, 167.70s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:46<02:18, 46.01s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:31<01:31, 45.64s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [02:16<00:45, 45.17s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:26<00:00, 31.53s/it]Loading checkpoint shards: 100%|██████████| 4/4 [02:26<00:00, 36.66s/it]
Processing sample 1/25 (dataset index: 0)
Processing sample 1 (dataset index 0)
torch.Size([1, 57])
torch.Size([1, 57, 128256])
torch.Size([57])
Error processing sample 1 (dataset index 0): too many values to unpack (expected 2)
Processing sample 2/25 (dataset index: 1)
Processing sample 2 (dataset index 1)
torch.Size([1, 77])
torch.Size([1, 77, 128256])
torch.Size([77])
Error processing sample 2 (dataset index 1): too many values to unpack (expected 2)
Processing sample 3/25 (dataset index: 2)
Processing sample 3 (dataset index 2)
torch.Size([1, 70])
torch.Size([1, 70, 128256])
torch.Size([70])
Error processing sample 3 (dataset index 2): too many values to unpack (expected 2)
Processing sample 4/25 (dataset index: 3)
Processing sample 4 (dataset index 3)
torch.Size([1, 88])
torch.Size([1, 88, 128256])
torch.Size([88])
Error processing sample 4 (dataset index 3): too many values to unpack (expected 2)
Processing sample 5/25 (dataset index: 4)
Processing sample 5 (dataset index 4)
torch.Size([1, 31])
torch.Size([1, 31, 128256])
torch.Size([31])
Error processing sample 5 (dataset index 4): too many values to unpack (expected 2)
Processing sample 6/25 (dataset index: 5)
Processing sample 6 (dataset index 5)
torch.Size([1, 41])
torch.Size([1, 41, 128256])
torch.Size([41])
Error processing sample 6 (dataset index 5): too many values to unpack (expected 2)
Processing sample 7/25 (dataset index: 6)
Processing sample 7 (dataset index 6)
torch.Size([1, 87])
torch.Size([1, 87, 128256])
torch.Size([87])
Error processing sample 7 (dataset index 6): too many values to unpack (expected 2)
Processing sample 8/25 (dataset index: 7)
Processing sample 8 (dataset index 7)
torch.Size([1, 87])
torch.Size([1, 87, 128256])
torch.Size([87])
Error processing sample 8 (dataset index 7): too many values to unpack (expected 2)
Processing sample 9/25 (dataset index: 8)
Processing sample 9 (dataset index 8)
torch.Size([1, 87])
torch.Size([1, 87, 128256])
torch.Size([87])
Error processing sample 9 (dataset index 8): too many values to unpack (expected 2)
Processing sample 10/25 (dataset index: 9)
Processing sample 10 (dataset index 9)
torch.Size([1, 53])
torch.Size([1, 53, 128256])
torch.Size([53])
Error processing sample 10 (dataset index 9): too many values to unpack (expected 2)
Processing sample 11/25 (dataset index: 10)
Processing sample 11 (dataset index 10)
torch.Size([1, 36])
torch.Size([1, 36, 128256])
torch.Size([36])
Error processing sample 11 (dataset index 10): too many values to unpack (expected 2)
Processing sample 12/25 (dataset index: 11)
Processing sample 12 (dataset index 11)
torch.Size([1, 64])
torch.Size([1, 64, 128256])
torch.Size([64])
Error processing sample 12 (dataset index 11): too many values to unpack (expected 2)
Processing sample 13/25 (dataset index: 12)
Processing sample 13 (dataset index 12)
torch.Size([1, 68])
torch.Size([1, 68, 128256])
torch.Size([68])
Error processing sample 13 (dataset index 12): too many values to unpack (expected 2)
Processing sample 14/25 (dataset index: 13)
Processing sample 14 (dataset index 13)
torch.Size([1, 43])
torch.Size([1, 43, 128256])
torch.Size([43])
Error processing sample 14 (dataset index 13): too many values to unpack (expected 2)
Processing sample 15/25 (dataset index: 14)
Processing sample 15 (dataset index 14)
torch.Size([1, 59])
torch.Size([1, 59, 128256])
torch.Size([59])
Error processing sample 15 (dataset index 14): too many values to unpack (expected 2)
Processing sample 16/25 (dataset index: 15)
Processing sample 16 (dataset index 15)
torch.Size([1, 77])
torch.Size([1, 77, 128256])
torch.Size([77])
Error processing sample 16 (dataset index 15): too many values to unpack (expected 2)
Processing sample 17/25 (dataset index: 16)
Processing sample 17 (dataset index 16)
torch.Size([1, 53])
torch.Size([1, 53, 128256])
torch.Size([53])
Error processing sample 17 (dataset index 16): too many values to unpack (expected 2)
Processing sample 18/25 (dataset index: 17)
Processing sample 18 (dataset index 17)
torch.Size([1, 67])
torch.Size([1, 67, 128256])
torch.Size([67])
Error processing sample 18 (dataset index 17): too many values to unpack (expected 2)
Processing sample 19/25 (dataset index: 18)
Processing sample 19 (dataset index 18)
torch.Size([1, 52])
torch.Size([1, 52, 128256])
torch.Size([52])
Error processing sample 19 (dataset index 18): too many values to unpack (expected 2)
Processing sample 20/25 (dataset index: 19)
Processing sample 20 (dataset index 19)
torch.Size([1, 175])
torch.Size([1, 175, 128256])
torch.Size([175])
Error processing sample 20 (dataset index 19): too many values to unpack (expected 2)
Processing sample 21/25 (dataset index: 20)
Processing sample 21 (dataset index 20)
torch.Size([1, 97])
torch.Size([1, 97, 128256])
torch.Size([97])
Error processing sample 21 (dataset index 20): too many values to unpack (expected 2)
Processing sample 22/25 (dataset index: 21)
Processing sample 22 (dataset index 21)
torch.Size([1, 421])
torch.Size([1, 421, 128256])
torch.Size([421])
Error processing sample 22 (dataset index 21): too many values to unpack (expected 2)
Processing sample 23/25 (dataset index: 22)
Processing sample 23 (dataset index 22)
torch.Size([1, 228])
torch.Size([1, 228, 128256])
torch.Size([228])
Error processing sample 23 (dataset index 22): too many values to unpack (expected 2)
Processing sample 24/25 (dataset index: 23)
Processing sample 24 (dataset index 23)
torch.Size([1, 180])
torch.Size([1, 180, 128256])
torch.Size([180])
Error processing sample 24 (dataset index 23): too many values to unpack (expected 2)
Processing sample 25/25 (dataset index: 24)
Processing sample 25 (dataset index 24)
torch.Size([1, 402])
torch.Size([1, 402, 128256])
torch.Size([402])
Error processing sample 25 (dataset index 24): too many values to unpack (expected 2)
Processing complete, but no successful results to save. All 25 samples failed.
