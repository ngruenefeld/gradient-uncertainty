slurmstepd-abakus22: error: Unable to create TMPDIR [/tmp/user/24470]: Permission denied
slurmstepd-abakus22: error: Setting TMPDIR to /tmp
Running job with commit: 4c7d00dbc8c3c56ab0352b18dd4449d43ed0152c
[nltk_data] Downloading package stopwords to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
[nltk_data] Downloading package wordnet to
[nltk_data]     /home/g/gruenefeld/nltk_data...
[nltk_data]   Package wordnet is already up-to-date!
Job number: 2189
Dataset: commoncorpus
Model: llama-awq
GPT Model: gpt-4o-mini-2024-07-18
Key mode: keyfile
Sample size: 0
Mode: full
Quantization bits: None (full precision)
Full gradient: False
Response only: True
Normalize: False
Perturbation mode: rephrase
Number of perturbations: 3
Max tokens: 0
You have loaded an AWQ model on CPU and have a CUDA device available, make sure to set your model on a GPU device in order to run your model.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
Repo card metadata block was not found. Setting CardData to empty.
Processing sample 1/600 (dataset index: 0)
Processing sample 1 (dataset index 0) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 250.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 1 (dataset index 0): CUDA out of memory. Tried to allocate 94.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, and 250.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 2/600 (dataset index: 1)
Processing sample 2 (dataset index 1) with language 'en'
Sample 2 (dataset index 1) processed successfully with 3 rephrasings.
Processing sample 3/600 (dataset index: 2)
Processing sample 3 (dataset index 2) with language 'en'
Sample 3 (dataset index 2) processed successfully with 3 rephrasings.
Processing sample 4/600 (dataset index: 3)
Processing sample 4 (dataset index 3) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 43.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 357.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 4 (dataset index 3): CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 43.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 357.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 5/600 (dataset index: 4)
Processing sample 5 (dataset index 4) with language 'en'
Sample 5 (dataset index 4) processed successfully with 3 rephrasings.
Processing sample 6/600 (dataset index: 5)
Processing sample 6 (dataset index 5) with language 'en'
JSONDecodeError: Expecting value: line 19594 column 2 (char 55647)
Error getting rephrasings for sample 6 (dataset index 5): Invalid JSON response from API
Processing sample 7/600 (dataset index: 6)
Processing sample 7 (dataset index 6) with language 'en'
Sample 7 (dataset index 6) processed successfully with 3 rephrasings.
Processing sample 8/600 (dataset index: 7)
Processing sample 8 (dataset index 7) with language 'en'
Sample 8 (dataset index 7) processed successfully with 3 rephrasings.
Processing sample 9/600 (dataset index: 8)
Processing sample 9 (dataset index 8) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 89.00 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 435.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 9 (dataset index 8): CUDA out of memory. Tried to allocate 114.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 89.00 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 435.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 10/600 (dataset index: 9)
Processing sample 10 (dataset index 9) with language 'en'
Sample 10 (dataset index 9) processed successfully with 3 rephrasings.
Processing sample 11/600 (dataset index: 10)
Processing sample 11 (dataset index 10) with language 'en'
Sample 11 (dataset index 10) processed successfully with 3 rephrasings.
Processing sample 12/600 (dataset index: 11)
Processing sample 12 (dataset index 11) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 45.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 478.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 12 (dataset index 11): CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 45.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 478.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 13/600 (dataset index: 12)
Processing sample 13 (dataset index 12) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 467.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 13 (dataset index 12): CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 467.51 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 14/600 (dataset index: 13)
Processing sample 14 (dataset index 13) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 9.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 399.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 14 (dataset index 13): CUDA out of memory. Tried to allocate 108.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 9.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 399.32 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 15/600 (dataset index: 14)
Processing sample 15 (dataset index 14) with language 'en'
Sample 15 (dataset index 14) processed successfully with 3 rephrasings.
Processing sample 16/600 (dataset index: 15)
Processing sample 16 (dataset index 15) with language 'en'
Sample 16 (dataset index 15) processed successfully with 3 rephrasings.
Processing sample 17/600 (dataset index: 16)
Processing sample 17 (dataset index 16) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 63.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 435.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 17 (dataset index 16): CUDA out of memory. Tried to allocate 90.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 63.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 435.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 18/600 (dataset index: 17)
Processing sample 18 (dataset index 17) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 49.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 366.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 18 (dataset index 17): CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 49.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 366.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 19/600 (dataset index: 18)
Processing sample 19 (dataset index 18) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 69.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.12 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 19 (dataset index 18): CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 69.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.12 GiB is allocated by PyTorch, and 1.10 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 20/600 (dataset index: 19)
Processing sample 20 (dataset index 19) with language 'en'
Sample 20 (dataset index 19) processed successfully with 5 rephrasings.
Processing sample 21/600 (dataset index: 20)
Processing sample 21 (dataset index 20) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 147.00 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 514.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 21 (dataset index 20): CUDA out of memory. Tried to allocate 152.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 147.00 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 514.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 22/600 (dataset index: 21)
Processing sample 22 (dataset index 21) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 19.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 22 (dataset index 21): CUDA out of memory. Tried to allocate 52.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 19.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 1.96 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 23/600 (dataset index: 22)
Processing sample 23 (dataset index 22) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 91.00 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 516.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 23 (dataset index 22): CUDA out of memory. Tried to allocate 206.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 91.00 MiB is free. Including non-PyTorch memory, this process has 23.45 GiB memory in use. Of the allocated memory 22.69 GiB is allocated by PyTorch, and 516.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 24/600 (dataset index: 23)
Processing sample 24 (dataset index 23) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 169.00 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 294.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 24 (dataset index 23): CUDA out of memory. Tried to allocate 202.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 169.00 MiB is free. Including non-PyTorch memory, this process has 23.37 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 294.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 25/600 (dataset index: 24)
Processing sample 25 (dataset index 24) with language 'en'
Sample 25 (dataset index 24) processed successfully with 3 rephrasings.
Processing sample 26/600 (dataset index: 25)
Processing sample 26 (dataset index 25) with language 'en'
Sample 26 (dataset index 25) processed successfully with 3 rephrasings.
Processing sample 27/600 (dataset index: 26)
Processing sample 27 (dataset index 26) with language 'en'
Sample 27 (dataset index 26) processed successfully with 3 rephrasings.
Processing sample 28/600 (dataset index: 27)
Processing sample 28 (dataset index 27) with language 'en'
Sample 28 (dataset index 27) processed successfully with 3 rephrasings.
Processing sample 29/600 (dataset index: 28)
Processing sample 29 (dataset index 28) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 185.00 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 270.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 29 (dataset index 28): CUDA out of memory. Tried to allocate 324.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 185.00 MiB is free. Including non-PyTorch memory, this process has 23.36 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 270.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 30/600 (dataset index: 29)
Processing sample 30 (dataset index 29) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 165.00 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 543.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 30 (dataset index 29): CUDA out of memory. Tried to allocate 186.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 165.00 MiB is free. Including non-PyTorch memory, this process has 23.38 GiB memory in use. Of the allocated memory 22.59 GiB is allocated by PyTorch, and 543.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 31/600 (dataset index: 30)
Processing sample 31 (dataset index 30) with language 'en'
Sample 31 (dataset index 30) processed successfully with 6 rephrasings.
Processing sample 32/600 (dataset index: 31)
Processing sample 32 (dataset index 31) with language 'en'
Sample 32 (dataset index 31) processed successfully with 3 rephrasings.
Processing sample 33/600 (dataset index: 32)
Processing sample 33 (dataset index 32) with language 'en'
Sample 33 (dataset index 32) processed successfully with 3 rephrasings.
Processing sample 34/600 (dataset index: 33)
Processing sample 34 (dataset index 33) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 17.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 34 (dataset index 33): CUDA out of memory. Tried to allocate 28.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 17.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.00 GiB is allocated by PyTorch, and 1.27 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 35/600 (dataset index: 34)
Processing sample 35 (dataset index 34) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 135.00 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 379.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 35 (dataset index 34): CUDA out of memory. Tried to allocate 326.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 135.00 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 379.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 36/600 (dataset index: 35)
Processing sample 36 (dataset index 35) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 418.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 36 (dataset index 35): CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 418.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 37/600 (dataset index: 36)
Processing sample 37 (dataset index 36) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 412.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 37 (dataset index 36): CUDA out of memory. Tried to allocate 254.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.85 GiB is allocated by PyTorch, and 412.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 38/600 (dataset index: 37)
Processing sample 38 (dataset index 37) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 38 (dataset index 37): CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.19 GiB is allocated by PyTorch, and 1.03 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 39/600 (dataset index: 38)
Processing sample 39 (dataset index 38) with language 'en'
Sample 39 (dataset index 38) processed successfully with 3 rephrasings.
Processing sample 40/600 (dataset index: 39)
Processing sample 40 (dataset index 39) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 11.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 721.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 40 (dataset index 39): CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 11.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.56 GiB is allocated by PyTorch, and 721.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 41/600 (dataset index: 40)
Processing sample 41 (dataset index 40) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 57.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 507.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 41 (dataset index 40): CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 57.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.73 GiB is allocated by PyTorch, and 507.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 42/600 (dataset index: 41)
Processing sample 42 (dataset index 41) with language 'en'
Sample 42 (dataset index 41) processed successfully with 3 rephrasings.
Processing sample 43/600 (dataset index: 42)
Processing sample 43 (dataset index 42) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 17.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 514.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 43 (dataset index 42): CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 17.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.76 GiB is allocated by PyTorch, and 514.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 44/600 (dataset index: 43)
Processing sample 44 (dataset index 43) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 7.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 365.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 44 (dataset index 43): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 7.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 365.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 45/600 (dataset index: 44)
Processing sample 45 (dataset index 44) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 19.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 371.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 45 (dataset index 44): CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 19.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.90 GiB is allocated by PyTorch, and 371.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 46/600 (dataset index: 45)
Processing sample 46 (dataset index 45) with language 'en'
Sample 46 (dataset index 45) processed successfully with 3 rephrasings.
Processing sample 47/600 (dataset index: 46)
Processing sample 47 (dataset index 46) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 121.00 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 370.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 47 (dataset index 46): CUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 121.00 MiB is free. Including non-PyTorch memory, this process has 23.42 GiB memory in use. Of the allocated memory 22.80 GiB is allocated by PyTorch, and 370.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 48/600 (dataset index: 47)
Processing sample 48 (dataset index 47) with language 'en'
Sample 48 (dataset index 47) processed successfully with 3 rephrasings.
Processing sample 49/600 (dataset index: 48)
Processing sample 49 (dataset index 48) with language 'en'
Sample 49 (dataset index 48) processed successfully with 3 rephrasings.
Processing sample 50/600 (dataset index: 49)
Processing sample 50 (dataset index 49) with language 'en'
Sample 50 (dataset index 49) processed successfully with 3 rephrasings.
Processing sample 51/600 (dataset index: 50)
Processing sample 51 (dataset index 50) with language 'en'
Sample 51 (dataset index 50) processed successfully with 3 rephrasings.
Processing sample 52/600 (dataset index: 51)
Processing sample 52 (dataset index 51) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 147.00 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 258.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 52 (dataset index 51): CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 147.00 MiB is free. Including non-PyTorch memory, this process has 23.39 GiB memory in use. Of the allocated memory 22.88 GiB is allocated by PyTorch, and 258.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 53/600 (dataset index: 52)
Processing sample 53 (dataset index 52) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 53 (dataset index 52): CUDA out of memory. Tried to allocate 70.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.17 GiB is allocated by PyTorch, and 1.05 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 54/600 (dataset index: 53)
Processing sample 54 (dataset index 53) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 83.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 572.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 54 (dataset index 53): CUDA out of memory. Tried to allocate 150.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 83.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.64 GiB is allocated by PyTorch, and 572.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 55/600 (dataset index: 54)
Processing sample 55 (dataset index 54) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 239.00 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 287.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 55 (dataset index 54): CUDA out of memory. Tried to allocate 288.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 239.00 MiB is free. Including non-PyTorch memory, this process has 23.30 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 287.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 56/600 (dataset index: 55)
Processing sample 56 (dataset index 55) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 57.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 559.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 56 (dataset index 55): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 57.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.68 GiB is allocated by PyTorch, and 559.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 57/600 (dataset index: 56)
Processing sample 57 (dataset index 56) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 33.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 884.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 57 (dataset index 56): CUDA out of memory. Tried to allocate 40.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 33.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.38 GiB is allocated by PyTorch, and 884.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 58/600 (dataset index: 57)
Processing sample 58 (dataset index 57) with language 'en'
Sample 58 (dataset index 57) processed successfully with 3 rephrasings.
Processing sample 59/600 (dataset index: 58)
Processing sample 59 (dataset index 58) with language 'en'
Sample 59 (dataset index 58) processed successfully with 3 rephrasings.
Processing sample 60/600 (dataset index: 59)
Processing sample 60 (dataset index 59) with language 'en'
Sample 60 (dataset index 59) processed successfully with 3 rephrasings.
Processing sample 61/600 (dataset index: 60)
Processing sample 61 (dataset index 60) with language 'en'
Sample 61 (dataset index 60) processed successfully with 3 rephrasings.
Processing sample 62/600 (dataset index: 61)
Processing sample 62 (dataset index 61) with language 'en'
Sample 62 (dataset index 61) processed successfully with 3 rephrasings.
Processing sample 63/600 (dataset index: 62)
Processing sample 63 (dataset index 62) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 365.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 63 (dataset index 62): CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.86 GiB is allocated by PyTorch, and 365.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 64/600 (dataset index: 63)
Processing sample 64 (dataset index 63) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 47.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 260.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 64 (dataset index 63): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 47.00 MiB is free. Including non-PyTorch memory, this process has 23.49 GiB memory in use. Of the allocated memory 22.98 GiB is allocated by PyTorch, and 260.94 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 65/600 (dataset index: 64)
Processing sample 65 (dataset index 64) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 494.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 65 (dataset index 64): CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.72 GiB is allocated by PyTorch, and 494.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 66/600 (dataset index: 65)
Processing sample 66 (dataset index 65) with language 'en'
Sample 66 (dataset index 65) processed successfully with 3 rephrasings.
Processing sample 67/600 (dataset index: 66)
Processing sample 67 (dataset index 66) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 59.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 67 (dataset index 66): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 59.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 21.87 GiB is allocated by PyTorch, and 1.35 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 68/600 (dataset index: 67)
Processing sample 68 (dataset index 67) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 39.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 21.64 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 68 (dataset index 67): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 39.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 21.64 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 69/600 (dataset index: 68)
Processing sample 69 (dataset index 68) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 381.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 69 (dataset index 68): CUDA out of memory. Tried to allocate 82.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 67.00 MiB is free. Including non-PyTorch memory, this process has 23.47 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 381.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 70/600 (dataset index: 69)
Processing sample 70 (dataset index 69) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 41.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 464.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 70 (dataset index 69): CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 41.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.79 GiB is allocated by PyTorch, and 464.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 71/600 (dataset index: 70)
Processing sample 71 (dataset index 70) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 7.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 363.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 71 (dataset index 70): CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 7.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 363.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 72/600 (dataset index: 71)
Processing sample 72 (dataset index 71) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 139.00 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 261.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 72 (dataset index 71): CUDA out of memory. Tried to allocate 176.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 139.00 MiB is free. Including non-PyTorch memory, this process has 23.40 GiB memory in use. Of the allocated memory 22.89 GiB is allocated by PyTorch, and 261.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 73/600 (dataset index: 72)
Processing sample 73 (dataset index 72) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 461.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 73 (dataset index 72): CUDA out of memory. Tried to allocate 88.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 77.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.75 GiB is allocated by PyTorch, and 461.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 74/600 (dataset index: 73)
Processing sample 74 (dataset index 73) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 9.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 501.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 74 (dataset index 73): CUDA out of memory. Tried to allocate 210.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 9.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.78 GiB is allocated by PyTorch, and 501.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 75/600 (dataset index: 74)
Processing sample 75 (dataset index 74) with language 'en'
Sample 75 (dataset index 74) processed successfully with 3 rephrasings.
Processing sample 76/600 (dataset index: 75)
Processing sample 76 (dataset index 75) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 33.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 546.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 76 (dataset index 75): CUDA out of memory. Tried to allocate 118.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 33.00 MiB is free. Including non-PyTorch memory, this process has 23.50 GiB memory in use. Of the allocated memory 22.71 GiB is allocated by PyTorch, and 546.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 77/600 (dataset index: 76)
Processing sample 77 (dataset index 76) with language 'en'
Sample 77 (dataset index 76) processed successfully with 3 rephrasings.
Processing sample 78/600 (dataset index: 77)
Processing sample 78 (dataset index 77) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 417.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 78 (dataset index 77): CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 29.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.84 GiB is allocated by PyTorch, and 417.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 79/600 (dataset index: 78)
Processing sample 79 (dataset index 78) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 57.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 400.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 79 (dataset index 78): CUDA out of memory. Tried to allocate 120.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 57.00 MiB is free. Including non-PyTorch memory, this process has 23.48 GiB memory in use. Of the allocated memory 22.83 GiB is allocated by PyTorch, and 400.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 80/600 (dataset index: 79)
Processing sample 80 (dataset index 79) with language 'en'
Sample 80 (dataset index 79) processed successfully with 3 rephrasings.
Processing sample 81/600 (dataset index: 80)
Processing sample 81 (dataset index 80) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 7.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 943.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 81 (dataset index 80): CUDA out of memory. Tried to allocate 68.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 7.00 MiB is free. Including non-PyTorch memory, this process has 23.53 GiB memory in use. Of the allocated memory 22.35 GiB is allocated by PyTorch, and 943.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 82/600 (dataset index: 81)
Processing sample 82 (dataset index 81) with language 'en'
Sample 82 (dataset index 81) processed successfully with 3 rephrasings.
Processing sample 83/600 (dataset index: 82)
Processing sample 83 (dataset index 82) with language 'en'
Sample 83 (dataset index 82) processed successfully with 3 rephrasings.
Processing sample 84/600 (dataset index: 83)
Processing sample 84 (dataset index 83) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 17.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 505.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 84 (dataset index 83): CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 17.00 MiB is free. Including non-PyTorch memory, this process has 23.52 GiB memory in use. Of the allocated memory 22.77 GiB is allocated by PyTorch, and 505.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 85/600 (dataset index: 84)
Processing sample 85 (dataset index 84) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 111.00 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 536.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 85 (dataset index 84): CUDA out of memory. Tried to allocate 200.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 111.00 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.65 GiB is allocated by PyTorch, and 536.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 86/600 (dataset index: 85)
Processing sample 86 (dataset index 85) with language 'en'
Sample 86 (dataset index 85) processed successfully with 3 rephrasings.
Processing sample 87/600 (dataset index: 86)
Processing sample 87 (dataset index 86) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 319.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 87 (dataset index 86): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.94 GiB is allocated by PyTorch, and 319.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 88/600 (dataset index: 87)
Processing sample 88 (dataset index 87) with language 'en'
Sample 88 (dataset index 87) processed successfully with 3 rephrasings.
Processing sample 89/600 (dataset index: 88)
Processing sample 89 (dataset index 88) with language 'en'
Sample 89 (dataset index 88) processed successfully with 3 rephrasings.
Processing sample 90/600 (dataset index: 89)
Processing sample 90 (dataset index 89) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 300.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 90 (dataset index 89): CUDA out of memory. Tried to allocate 86.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 25.00 MiB is free. Including non-PyTorch memory, this process has 23.51 GiB memory in use. Of the allocated memory 22.96 GiB is allocated by PyTorch, and 300.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 91/600 (dataset index: 90)
Processing sample 91 (dataset index 90) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 105.00 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 376.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 91 (dataset index 90): CUDA out of memory. Tried to allocate 192.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 105.00 MiB is free. Including non-PyTorch memory, this process has 23.43 GiB memory in use. Of the allocated memory 22.81 GiB is allocated by PyTorch, and 376.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 92/600 (dataset index: 91)
Processing sample 92 (dataset index 91) with language 'en'
Error in completion_gradient: CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 81.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 336.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Error calculating gradient for sample 92 (dataset index 91): CUDA out of memory. Tried to allocate 80.00 MiB. GPU 0 has a total capacity of 23.56 GiB of which 81.00 MiB is free. Including non-PyTorch memory, this process has 23.46 GiB memory in use. Of the allocated memory 22.87 GiB is allocated by PyTorch, and 336.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Processing sample 93/600 (dataset index: 92)
Processing sample 93 (dataset index 92) with language 'en'
